<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>为什么MySQL使用B+树</title>
      <link href="/2021/07/27/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/other/%E4%B8%BA%E4%BB%80%E4%B9%88MySQL%E4%BD%BF%E7%94%A8B+%E6%A0%91/"/>
      <url>/2021/07/27/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/other/%E4%B8%BA%E4%BB%80%E4%B9%88MySQL%E4%BD%BF%E7%94%A8B+%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>首先需要澄清的一点是，MySQL跟B+树没有直接的关系，真正与B+树有关系的是MySQL的默认存储引擎InnoDB，MySQL中存储引擎的主要作用是负责数据的存储和提取，除了InnoDB之外，MySQL中也支持MyISAM作为表的底层存储引擎。</p><p>我们在使用 SQL 语句创建表时就可以为当前表指定使用的存储引擎，你能在 MySQL 的文档 Alternative Storage Engines 中找到它支持的全部存储引擎，例如：<code>MyISAM</code>、<code>CSV</code>、<code>MEMORY</code> 等，然而默认情况下，使用如下所示的 SQL 语句来创建表就会得到 InnoDB 存储引擎支撑的表：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t1 (</span><br><span class="line">    a <span class="type">INT</span>,</span><br><span class="line">    b <span class="type">CHAR</span> (<span class="number">20</span></span><br><span class="line">), <span class="keyword">PRIMARY</span> KEY (a)) ENGINE<span class="operator">=</span>InnoDB;</span><br></pre></td></tr></table></figure><blockquote><p>想要详细了解 MySQL 默认存储引擎的读者，可以通过之前的文章 『浅入浅出』MySQL 和 InnoDB 了解包括 InnoDB 存储方式、索引和锁等内容，我们在这里主要不会介绍 InnoDB 相关的过多内容。</p></blockquote><p>我们今天最终将要分析的问题其实还是，为什么 MySQL 默认的存储引擎 InnoDB 会使用 MySQL 来存储数据，相信对MySQL稍微有些了解的人都知道，无论是表中的数据（主键索引）还是辅助索引最终都会使用B+树来存储数据，其中前者在表中会以&lt;id,row&gt;的方式存储，而后者会以&lt;index,id&gt;的方式进行存储，这其实也比较好理解：</p><ul><li>在主键索引中，id是主键，我们能够通过id找到该行的全部列；</li><li>在辅助索引中，索引中的几个列构成了键，我们能够通过索引中的列找到id，如果有需要的话，可以再通过id找到当前数据行的全部内容；</li></ul><h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL如何使用Concat连接两列数据</title>
      <link href="/2021/07/27/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/other/concat%E7%BB%84%E5%90%88%E5%A4%9A%E4%B8%AA%E5%AD%97%E6%AE%B5/"/>
      <url>/2021/07/27/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/other/concat%E7%BB%84%E5%90%88%E5%A4%9A%E4%B8%AA%E5%AD%97%E6%AE%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="SQL如何使用Concat连接两列数据"><a href="#SQL如何使用Concat连接两列数据" class="headerlink" title="SQL如何使用Concat连接两列数据"></a>SQL如何使用Concat连接两列数据</h1><h2 id="方法-步骤"><a href="#方法-步骤" class="headerlink" title="方法/步骤"></a>方法/步骤</h2><h3 id="concat直接组合多个字段"><a href="#concat直接组合多个字段" class="headerlink" title="concat直接组合多个字段"></a>concat直接组合多个字段</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> concat(name,uid) <span class="keyword">as</span> name <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></figure><h3 id="concat不仅可以使用字段名，也可以使用字符串"><a href="#concat不仅可以使用字段名，也可以使用字符串" class="headerlink" title="concat不仅可以使用字段名，也可以使用字符串"></a>concat不仅可以使用字段名，也可以使用字符串</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> concat(name,<span class="string">&#x27;~&#x27;</span>,uid) <span class="keyword">as</span> name <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></figure><h3 id="concat嵌套使用"><a href="#concat嵌套使用" class="headerlink" title="concat嵌套使用"></a>concat嵌套使用</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> concat(name,concat(uid,sex)) <span class="keyword">as</span> name <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第5章 系统性能评价</title>
      <link href="/2021/07/26/SystemArchitect/%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E8%AF%84%E4%BB%B7/"/>
      <url>/2021/07/26/SystemArchitect/%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E8%AF%84%E4%BB%B7/</url>
      
        <content type="html"><![CDATA[<p>性能设计主要包含两方面的内容：一是作为未来计算机发展的参考和规划；另一个则是对现有系统进行性能上的调整已达到最优化。</p><span id="more"></span><h2 id="5-1-性能指标"><a href="#5-1-性能指标" class="headerlink" title="5.1 性能指标"></a>5.1 性能指标</h2><p>描述当前流行系统主要涉及的性能指标</p><h3 id="5-1-1-对计算机评价的主要性能指标"><a href="#5-1-1-对计算机评价的主要性能指标" class="headerlink" title="5.1.1 对计算机评价的主要性能指标"></a>5.1.1 对计算机评价的主要性能指标</h3><h4 id="1-时钟频率（主频）"><a href="#1-时钟频率（主频）" class="headerlink" title="1.时钟频率（主频）"></a>1.时钟频率（主频）</h4><p>主频是计算机的主要性能指标之一，在很大程度上决定了计算机的运算速度。CPU的工作节拍是由主时钟来控制的，主时钟不断产生固定频率的时钟脉冲，这个主时钟的评率即是CPU的主频。主频越高，意味着CPU的工作节拍就越快，运算速度也就越快。现在已经发展为多核心CPU，除了看时钟频率还得看单个CPU中的内核数。</p><h4 id="2-高速缓存"><a href="#2-高速缓存" class="headerlink" title="2.高速缓存"></a>2.高速缓存</h4><p>高速缓存可以提高CPU的运行效率。目前一般采用两级高速缓存技术，有些使用三层。高速缓冲存储器均由静态RAM（Random Access Memory，随机存取存储器）组成，结构较复杂，在 CPU 管芯面积不能太大的情况下，L1 级高速缓存的容量不可能做得太大。采用回写（WriteBack）结构的高速缓存。它对读和写操作均有可提供缓存。而采用写通（Write-through）结构的高速缓存，仅对读操作有效。L2 及 L3 高速缓存容量也会影响 CPU的性能，原则是越大越好。</p><h2 id="性能计算"><a href="#性能计算" class="headerlink" title="性能计算"></a>性能计算</h2><p>描述当前使用到的主要性能指标的计算方法</p><h2 id="性能设计"><a href="#性能设计" class="headerlink" title="性能设计"></a>性能设计</h2><p>描述如何对现有系统进行性能上的调整优化，并介绍几个已经成熟的设计规则和解决方案</p><h2 id="性能评估"><a href="#性能评估" class="headerlink" title="性能评估"></a>性能评估</h2><p>描述如何对当前取得的性能指标进行评价和改进</p>]]></content>
      
      
      <categories>
          
          <category> 系统架构师 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 系统架构师 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第10章：设计模式</title>
      <link href="/2021/07/21/SystemArchitect/%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
      <url>/2021/07/21/SystemArchitect/%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-设计模式概述"><a href="#1-设计模式概述" class="headerlink" title="1.设计模式概述"></a>1.设计模式概述</h2><h3 id="1-1设计模式的概念"><a href="#1-1设计模式的概念" class="headerlink" title="1.1设计模式的概念"></a>1.1设计模式的概念</h3><p>GoF设计模式：对被用来在特定场景下解决一般设计问题的类和互相通信的对象的描述。通俗地说，可以把设计模式理解为对某一类问题的通用解决方案。</p><h3 id="1-2设计模式的组成"><a href="#1-2设计模式的组成" class="headerlink" title="1.2设计模式的组成"></a>1.2设计模式的组成</h3><p>一般的，在描述一个设计模式时，至少需要包含四个方面：</p><ul><li>模式名称（Pattern name）</li><li>问题（Problem）</li><li>解决方案（Solution）</li><li>效果（Consequence）</li></ul><p>这四个方面就是设计模式的四要素。</p><h3 id="1-3GoF设计模式（模式介绍）"><a href="#1-3GoF设计模式（模式介绍）" class="headerlink" title="1.3GoF设计模式（模式介绍）"></a>1.3GoF设计模式（模式介绍）</h3><h4 id="创建型"><a href="#创建型" class="headerlink" title="创建型"></a>创建型</h4><h5 id="1-Factory-Method模式（工厂方法）"><a href="#1-Factory-Method模式（工厂方法）" class="headerlink" title="1.Factory Method模式（工厂方法）"></a>1.Factory Method模式（工厂方法）</h5><p>Factory Method</p><p>模式提供了一种延迟创建类的方法，使用这个方法可以在运行期由子类决定创建哪一个类的实例。</p><h5 id="2-Abstract-Factory模式（抽象工厂）"><a href="#2-Abstract-Factory模式（抽象工厂）" class="headerlink" title="2.Abstract Factory模式（抽象工厂）"></a>2.Abstract Factory模式（抽象工厂）</h5><p>Abstract Factory又称为抽象工厂模式，该模式主要为解决复杂系统中对象创建的问题。抽象工厂模式提供了一个一致的对象创建接口来创建一系列具有相似基类或相似接口的对象。</p><h5 id="3-Buider模式（建造器）"><a href="#3-Buider模式（建造器）" class="headerlink" title="3.Buider模式（建造器）"></a>3.Buider模式（建造器）</h5><p>Builder模式与Abstract Factory模式非常类似，但Builder模式是逐步地构造出一个复杂对象，并在最后返回对象的实例。Builder模式可以把复杂对象的创建与表示分离，使得同样的创建过程可以创建不同的表示。</p><h5 id="4-Prototype模式（原型）"><a href="#4-Prototype模式（原型）" class="headerlink" title="4.Prototype模式（原型）"></a>4.Prototype模式（原型）</h5><p>Prototype模式可以根据原型实例制定创建的对象的种类，并通过深复制这个原型来创建新的对象。Prototype模式有着同Abstract Factory模式和Builder模式相同的效果，不过当需要实例化的类是在运行期才被指定的而且要避免创建一个与产品曾是平行的工厂类层次时，可以使用Prototype模式。使用Prototype模式可以在运行时增加或减少原型，比Abstract Factory和Builder模式更加灵活。</p><h5 id="5-Singleton模式（单例）"><a href="#5-Singleton模式（单例）" class="headerlink" title="5.Singleton模式（单例）"></a>5.Singleton模式（单例）</h5><p>使用Singleton模式可以保证一个类仅有一个实例，从而可以提供一个单一的全局访问点。</p><h4 id="结构型"><a href="#结构型" class="headerlink" title="结构型"></a>结构型</h4><h5 id="6-Adapter模式（适配器）"><a href="#6-Adapter模式（适配器）" class="headerlink" title="6.Adapter模式（适配器）"></a>6.Adapter模式（适配器）</h5><p>Adapter模式可以解决系统间接口不相容的问题。通过Adapter可以把类的接口转化为客户程序所希望的接口，从而提高复用性。</p><h5 id="7-Bridge模式（桥接）"><a href="#7-Bridge模式（桥接）" class="headerlink" title="7.Bridge模式（桥接）"></a>7.Bridge模式（桥接）</h5><p>Bridge模式基于类的最小设计的原则，通过使用封装、聚合及继承等行为让不同的类承担不同的职责。它的主要特点是把抽象（Abstraction）与行为实现（Implementation）分离开来，从而可以保证各部分的独立性以及应对他们的功能拓展。</p><h5 id="8-Composite模式（组合）"><a href="#8-Composite模式（组合）" class="headerlink" title="8.Composite模式（组合）"></a>8.Composite模式（组合）</h5><p>Composite模式提供了一种以树形结构组合对象的方法，使用Composite可以使单个对象和组合后的对象具有一致性以提高软件的复用性。</p><h5 id="9-Decorator模式（装饰者）"><a href="#9-Decorator模式（装饰者）" class="headerlink" title="9.Decorator模式（装饰者）"></a>9.Decorator模式（装饰者）</h5><p>Decorator模式可以动态地为对象的某一个方法增加更多的功能。在更多时候，使用Decorator模式可以不必继承出新的子类从而维护简介的类继承结构。</p><h5 id="10-Facade模式（门面）"><a href="#10-Facade模式（门面）" class="headerlink" title="10.Facade模式（门面）"></a>10.Facade模式（门面）</h5><p>Facade模式为一组类提供了一致的访问接口。使用Facade可以封装内部具有不同接口的类，使其对外提供统一的访问方法。Facade模式在J2EE系统开发中发展为Session Facade模式。</p><h5 id="11-Flyweight模式（享元）"><a href="#11-Flyweight模式（享元）" class="headerlink" title="11.Flyweight模式（享元）"></a>11.Flyweight模式（享元）</h5><p>Flyweight模式可以共享大量的细粒度对象，从而节省创建对象所需要分配的空间，不过在时间上的开销会变大。</p><h5 id="12-Proxy模式（代理）"><a href="#12-Proxy模式（代理）" class="headerlink" title="12.Proxy模式（代理）"></a>12.Proxy模式（代理）</h5><p>顾名思义，Proxy模式为对象提供了一种访问代理，通过对象Proxy可以控制客户程序的访问。例如：访问权限的控制、访问地址的控制、访问方式的控制等，甚至可以通过Proxy将开销较大的访问化整为零，提高访问效率。</p><h4 id="行为型"><a href="#行为型" class="headerlink" title="行为型"></a>行为型</h4><h5 id="13-Interpreter模式（解释器）"><a href="#13-Interpreter模式（解释器）" class="headerlink" title="13.Interpreter模式（解释器）"></a>13.Interpreter模式（解释器）</h5><p>定义了一个解释器，来解释遵循给定语言和文法的句子。</p><h5 id="14-Template-Method模式（模板）"><a href="#14-Template-Method模式（模板）" class="headerlink" title="14.Template Method模式（模板）"></a>14.Template Method模式（模板）</h5><p>定义一个操作的模板，其中的一些步骤会在子类中实现，以适应不同的情况。</p><h5 id="15-Chain-of-Responsibility模式（责任链）"><a href="#15-Chain-of-Responsibility模式（责任链）" class="headerlink" title="15.Chain of Responsibility模式（责任链）"></a>15.Chain of Responsibility模式（责任链）</h5><p>Chain of Responsibility模式把可以响应请求的对象组织成一条链，并在这条对象链上传递对象，从而保证多个对象都有机会处理请求而且可以避免请求方和响应方的耦合。</p><h5 id="16-Command模式（命令）"><a href="#16-Command模式（命令）" class="headerlink" title="16.Command模式（命令）"></a>16.Command模式（命令）</h5><p>将请求封装为对象，从而增强请求的能力，如参数化、排队、记录日志等。</p><h5 id="17-Iterator模式（迭代器）"><a href="#17-Iterator模式（迭代器）" class="headerlink" title="17.Iterator模式（迭代器）"></a>17.Iterator模式（迭代器）</h5><p>Iterator模式提供了顺序访问一个对象集合的各元素的方法，使用Iterator可以避免暴露集合中对象的耦合关系。</p><h5 id="18-Mediator模式（中介者）"><a href="#18-Mediator模式（中介者）" class="headerlink" title="18.Mediator模式（中介者）"></a>18.Mediator模式（中介者）</h5><p>Mediator模式可以减少系统中对象间的耦合性。Mediator模式使用中介对象封装其他对象，从而使这些被封装的对象间的关系就成了松散耦合。</p><h5 id="19-Memento模式（备忘录）"><a href="#19-Memento模式（备忘录）" class="headerlink" title="19.Memento模式（备忘录）"></a>19.Memento模式（备忘录）</h5><p>Memento模式提供了一种捕获对象状态的方法，且不会破坏对象的封装，并且可以在对象外部保存对象的状态，并在需要的时候恢复对象状态。</p><h5 id="20-Observer模式（观察者）"><a href="#20-Observer模式（观察者）" class="headerlink" title="20.Observer模式（观察者）"></a>20.Observer模式（观察者）</h5><p>Observer模式提供了将对象的状态广播到一组观察者的方式，从而可以让每个观察者随时都可以得到对象更新的通知。</p><h5 id="21-State模式（状态）"><a href="#21-State模式（状态）" class="headerlink" title="21.State模式（状态）"></a>21.State模式（状态）</h5><p>State模式允许一个对象在其内部状态改变的时候改变他的行为。</p><h5 id="22-Strategy（策略）"><a href="#22-Strategy（策略）" class="headerlink" title="22.Strategy（策略）"></a>22.Strategy（策略）</h5><p>使用Strategy模式可以让对象中算法的变化独立于客户。</p><h5 id="23-Visitor模式（访问者）"><a href="#23-Visitor模式（访问者）" class="headerlink" title="23.Visitor模式（访问者）"></a>23.Visitor模式（访问者）</h5><p>表示对某对象结构中各元素的操作，使用Visitor模式可以在不改变各元素类的前提下定义作用于这些元素的新操作。</p><h3 id="1-5设计模式与软件架构"><a href="#1-5设计模式与软件架构" class="headerlink" title="1.5设计模式与软件架构"></a>1.5设计模式与软件架构</h3><h3 id="1-6设计模式分类"><a href="#1-6设计模式分类" class="headerlink" title="1.6设计模式分类"></a>1.6设计模式分类</h3><table>    <tr>        <th colspan="2"></th>        <th>创建型</th>        <th>结构型</th>        <th>行为型</th>      </tr>    <tr>        <td rowspan="2">应用范围</td>        <td>应用于类</td>        <td>Factory Method</td>        <td>Adapter</td>        <td>            Interpreter<br>            Template Method        </td>    </tr>    <tr>        <td>应用于对象</td>        <td>            Abstract Factory<br>            Builder<br>            Prototype<br>            Singleton        </td>        <td>            Adapter<br>            Bridege<br>            Composite<br>            Decorator<br>            Facade<br>            Flyweight<br>            Proxy        </td>        <td>            Chain of Responsiblity<br>            Command<br>            Interator<br>            Mediator<br>            Memento<br>            Observer<br>            State<br>            Strategy<br>            Visitor        </td>    </tr></table><h3 id="1-7设计模式的六大原则"><a href="#1-7设计模式的六大原则" class="headerlink" title="1.7设计模式的六大原则"></a>1.7设计模式的六大原则</h3><h4 id="开闭原则（Open-Close-Principle）"><a href="#开闭原则（Open-Close-Principle）" class="headerlink" title="开闭原则（Open Close Principle）"></a>开闭原则（Open Close Principle）</h4><p>开闭原则就是说对扩展开放，对修改关闭。在程序需要进行扩展的时候，不能去修改原有的代码，实现一个热拔插的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级，想要达到这样的效果，我们需要使用接口和抽象类。</p><h3 id="1-8模式具体分析"><a href="#1-8模式具体分析" class="headerlink" title="1.8模式具体分析"></a>1.8模式具体分析</h3><h4 id="5-Signleton模式"><a href="#5-Signleton模式" class="headerlink" title="5.Signleton模式"></a>5.Signleton模式</h4><h4 id="7-Bridge模式"><a href="#7-Bridge模式" class="headerlink" title="7.Bridge模式"></a>7.Bridge模式</h4><p>桥接模式的角色和职责：</p><p>1.Client调用端</p><p>这是Bridge模式的调用者。</p><p>2.抽象类（Abstraction）</p><p>抽象类接口（接口这货抽象类）维护对行为实现（implementation）的引用，他的角色就是桥接类。</p><p>3.Refined Abstraction</p><p>这是Abstraction的子类。</p><p>4.Implementor</p><p>行为实现类接口（Abstraction接口定义了基于Implementor接口的更高层次的操作）</p><p>5.ConcreteImplmentor</p><p>Implementor的子类。</p><p>桥接模式的UML图如下：</p><p><img src="../../img/683744-20160930102718453-1750189602.png" class="lazyload" data-srcset="../../img/683744-20160930102718453-1750189602.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><p>总结：</p><p>1.桥接模式的优点</p><p>（1）实现了抽象和实现部分的分离</p><p>桥接模式分离了抽象部分和实现部分，从而极大地提供了系统的灵活性，让抽象部分和实现部分独立开来，分别定义接口，这有助于系统进行分层设计，从而产生更好的结构化系统。对于系统的高层部分，只需要知道抽象部分和实现部分的接口就可以了。</p><p>（2）更好的可扩展性</p><p>由于桥接模式把抽象部分和实现部分分离了，从而分别定义接口，这就使得抽象部分和实现部分可以分别独立扩展，而不会相互影响，大大的提供了系统的可扩展性。</p><p>（3）可动态的切换实现</p><p>由于桥接模式实现了抽象和实现的分离，所以在实现桥接模式时，就可以实现动态的选择和使用具体的实现。</p><p>（4）实现细节对客户端透明，可以对用户隐藏实现细节。</p><p>2.桥接模式的缺点</p><p>（1）桥接模式的引入增加了系统的理解和设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计和编程。</p><p>（2）桥接模式要求正确识别出系统中两个独立变化的维度，因此其使用范围有一定的局限性。</p><p>3.桥接模式的使用场景</p><p>（1）如果一个系统需要在构建的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使他们在抽象层建立一个关联关系。</p><p>（2）抽象化角色和实现化角色可以继承的方式独立扩展而互不影响，在程序运行时可以动态将一个抽象化子类的对象和一个实现化子类的对象进行组合，即系统需要对抽象化角色和实现化角色进行动态耦合。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 系统架构师 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第9章：软件架构设计</title>
      <link href="/2021/07/21/SystemArchitect/%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
      <url>/2021/07/21/SystemArchitect/%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<div class="note quote"><p>软件架构设计的一个核心问题是否使用重复的软件架构模式，即能否达到架构级别的软件重用。也就是说，能否在不同的软件系统中，使用同一架构。</p></div><span id="more"></span><h2 id="3-软件架构风格"><a href="#3-软件架构风格" class="headerlink" title="3.软件架构风格"></a>3.软件架构风格</h2><p>软件架构设计的一个核心问题是否使用重复的软件架构模式，即能否达到架构级别的软件重用。也就是说，能否在不同的软件系统中，使用同一架构。</p><p>软件架构风格是描述某一特定应用领域中系统组织方式的惯用模式（idiomatic paradigm），定义了用于描述系统的术语表和一组指导构建系统的规则。</p><h3 id="3-1软件架构风格分类"><a href="#3-1软件架构风格分类" class="headerlink" title="3.1软件架构风格分类"></a>3.1软件架构风格分类</h3><p>（1）设计词汇表是什么？</p><p>（2）构建和连接件的类型是什么？</p><p>（3）可容许的结构模式是什么？</p><p>（4）基本的计算模型是什么？</p><p>（5）风格的基本不变性是什么？</p><p>（6）其使用的常见例子是什么？</p><p>（7）使用此风格的优缺点是什么？</p><p>（8）其常见的特例是什么？</p><h3 id="3-2数据流风格"><a href="#3-2数据流风格" class="headerlink" title="3.2数据流风格"></a>3.2数据流风格</h3><p>数据流风格的软件架构是一种最常见，结构最为简单的软件架构。<strong>这样的架构下，所有的数据按照流的形式在执行过程中前进，不存在结构的反复和重构</strong>，就像工厂中的汽车流水线一样，数据就像汽车零部件一样的流水线的各个节点上被加工，最终输出所需要的结果（一步完整的汽车）。在流动过程中，数据经过序列间的数据处理组件进行加工，然后将处理结果向后传送，最后进行输出。</p><h4 id="批处理序列"><a href="#批处理序列" class="headerlink" title="批处理序列"></a>批处理序列</h4><p>批处理风格的每一步处理都是独立的，并且每一步是顺序执行的。只有当前一步处理完，后一步处理才能开始。数据传送在步与步之间作为一个整体。（组件为一系列固定顺序的计算单元，组件间只通过数据传递交互。每个处理步骤是一个独立的程序，每一步必须在前一步结束后才能开始，数据必须是完整的，以整体的方式传递）。</p><p>批处理的典型应用：</p><p>（1）经典数据处理；</p><p>（2）程序开发； </p><p>（3）Windows 下的 BAT 程序就是这种应用的典型实例</p><h4 id="管道-过滤器"><a href="#管道-过滤器" class="headerlink" title="管道-过滤器"></a>管道-过滤器</h4><p>在管道/过滤器风格的软件架构中，每个构件都有一组输入和输出，构件读输入的数据流，经过内部处理，然后产生输出数据流。这个过程通常通过对输入流的变换及增量计算来完成，所以在输入被完全消费之前，输出便产生了。因此，这里的构件被称为<strong>过滤器</strong>，这种风格的连接件就像是数据流传输的管道，将一个过滤器的输出传到另一过滤器的输入。</p><blockquote><p><strong>此风格特别重要的过滤器必须是独立的实体，它不能与其他的过滤器共享数据，而且一个过滤器不知道它上游和下游的标识。一个管道/过滤器网络输出的正确性并不依赖于过滤器进行增量计算过程的顺序。</strong></p></blockquote><p> 典型应用：</p><p>（1）以UNIX Shell编写的程序。UNIX 既提供一种符号，以连接各组成部分（UNIX 的进程），又提供某种进程运行时机制以实现管道。</p><p>（2）传统的编译器。传统的编译器一直被认为是一种管道系统，在该系统中，一个阶段（包括词法分析、语法分析、语义分析和代码生成）的输出是另一个阶段的输入。</p><h5 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h5><h3 id="3-3调用-返回风格"><a href="#3-3调用-返回风格" class="headerlink" title="3.3调用/返回风格"></a>3.3调用/返回风格</h3><p>调用返回风格顾名思义，就是指在系统中采用了调用与返回机制。利用调用-返回实际上是一种分而治之的策略，其主要思想是将一个复杂的大系统分解为一些子系统，以便降低复杂度，并且增加可修改性。程序从其执行起点开始执行该构建的代码，程序执行结束，将控制返回给程序调用构件。</p><h4 id="主程序-子程序"><a href="#主程序-子程序" class="headerlink" title="主程序/子程序"></a>主程序/子程序</h4><p>主程序/子程序风格是结构化开发时期的经典架构风格。这种风格一般采用单线程控制，把问题划分为若干处理步骤，构件即为主程序和子程序。子程序通常可合成为模块。过程调用作为交互机制，即充当连接件。调用关系具有层次性，其语义逻辑表现为子程序的正确性，取决于它调用的子程序的正确性。</p><h4 id="面向对象风格"><a href="#面向对象风格" class="headerlink" title="面向对象风格"></a>面向对象风格</h4><p>抽象数据类型概念对软件系统有着重要作用，目前软件界已普遍使用面向对象系统。这种风格建立在数据抽象和面向对象的基础上，数据的表示方法和它们的相应操作封装在一个抽象数据类型或对象中。这种风格的构件是对象，或者说是抽象数据类型的实例。对象是一种被称作管理者的构件，因为它负责保持资源的完整性。对象是通过函数和过程的调用来交互的。</p><h5 id="特点："><a href="#特点：" class="headerlink" title="特点："></a>特点：</h5><p>（1）对象负责维护其表示的完整性；</p><h4 id="层次结构"><a href="#层次结构" class="headerlink" title="层次结构"></a>层次结构</h4><h2 id="5-面向服务的架构"><a href="#5-面向服务的架构" class="headerlink" title="5.面向服务的架构"></a>5.面向服务的架构</h2><p>SOA是一种在计算环境中设计、开发、部署和管理离散逻辑单元（服务）模型的方法。</p>]]></content>
      
      
      <categories>
          
          <category> 系统架构师 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 系统架构师 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第1章：计算机组成与体系结构</title>
      <link href="/2021/07/21/SystemArchitect/%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
      <url>/2021/07/21/SystemArchitect/%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h2 id="1-计算机系统"><a href="#1-计算机系统" class="headerlink" title="1.计算机系统"></a>1.计算机系统</h2><h3 id="1-3-复杂指令集系统与精简指令集系统"><a href="#1-3-复杂指令集系统与精简指令集系统" class="headerlink" title="1.3 复杂指令集系统与精简指令集系统"></a>1.3 复杂指令集系统与精简指令集系统</h3><table><thead><tr><th>指令系统类型</th><th align="left">指令</th><th>寻址方式</th><th>实现方式</th><th>其他</th></tr></thead><tbody><tr><td>CISC（复杂）</td><td align="left">数量多，使用频率差别大，可变长格式</td><td>支持多种</td><td>微程序控制技术</td><td>研制周期长</td></tr><tr><td>RISC（精简）</td><td align="left">数量少，使用频率接近，定长格式，大部分为单周期指令，操作寄存器，只有Load/Store</td><td>支持方式少</td><td>增加了通用寄存器；硬布线逻辑控制为主；适合采用流水线</td><td>优化编译，有效支持高级语言</td></tr></tbody></table><h2 id="2-存储器系统"><a href="#2-存储器系统" class="headerlink" title="2.存储器系统"></a>2.存储器系统</h2><h3 id="2-3-Cache存储器"><a href="#2-3-Cache存储器" class="headerlink" title="2.3 Cache存储器"></a>2.3 Cache存储器</h3><p>Cache的性能是计算机系统性能的重要方面。命中率是cache的一个重要指标，但不是最重要的指标。cache设计的主要目标是在成本允许的情况下达到较高的命中率，使存储系统具有最短的平均访问时间。cache的命中率和cache容量的关系是：cache容量越大，则命中率越高，随着容量的增加，其失效率接近0%（命中率接近100%）。但是，增加cache容量意味着增加cache的成本和增加cache的命中时间。</p><h2 id="3-流水线"><a href="#3-流水线" class="headerlink" title="3.流水线"></a>3.流水线</h2><p>流水线技术把一个任务分解为若干顺序执行的子任务，不同的子任务由不同的执行机构复杂执行，而这些机构可以同时并行工作。在任一时刻，任一任务只占用其中一个执行机构，这个就可以实现多个任务的重叠执行，以提高工作效率。</p><h3 id="3-1-流水线周期"><a href="#3-1-流水线周期" class="headerlink" title="3.1 流水线周期"></a>3.1 流水线周期</h3><p>流水线应用过程中，会将需要处理的工作分为 N 个阶段，最耗时的那一段所消耗的时间为流水线周期。</p><h3 id="3-2-计算流水线执行时间"><a href="#3-2-计算流水线执行时间" class="headerlink" title="3.2 计算流水线执行时间"></a>3.2 计算流水线执行时间</h3><p>以流水线的执行时间可通俗的表达为：</p><p>流水线执行时间=第 1 条指令的执行时间+（n-1）*流水线周期</p><blockquote><p>n 代表需要处理的任务数量。</p></blockquote><p>而实际上，真正做流水线处理时，考虑到处理的复杂性，会将指令的每个执行阶段的时<br> 间都统一为流水线周期，即 1 条指令的执行时间为：4ms+4ms+4ms=12ms。 </p><p>所以：实际流水线执行时间=4ms+4ms+4ms+(100-1)*4=408ms。</p><blockquote><p>考试时 80%以上的概率采用理论公式计算，所以考试时需要以理论公式计算，若计算的结果无正确选项才考虑采用实际公式计算。</p></blockquote><h3 id="3-3-流水线的吞吐率"><a href="#3-3-流水线的吞吐率" class="headerlink" title="3.3 流水线的吞吐率"></a>3.3 流水线的吞吐率</h3><p>流水线的吞吐率（Though Put rate，TP）是指在单位时间内流水线所完成的任务数量或输出的结果数量。有些文献也称为平均吞吐率、实际吞吐率。计算流水线吞吐率的最基本的公式如下：<br>$$<br>TP = \frac{n}{T_k}<br>$$<br>其中n为任务数，$T_k$是处理完成n个任务所用的时间。</p><p>流水线的最大吞吐率为：<br>$$<br>TP_{max} = \lim_{n\to\infty}\frac{n}{(k+n-1)\Delta{t}} = \frac{1}{\Delta{t}}<br>$$</p><h3 id="3-4-流水线的加速比"><a href="#3-4-流水线的加速比" class="headerlink" title="3.4 流水线的加速比"></a>3.4 流水线的加速比</h3><p>加速比：不使用流水线的执行时间/使用流水线的执行时间</p><p>如果不使用流水线，即顺序执行所用的时间为 $T_0$ ，使用流水线的执行时间为$T_k$，则计算流水线加速比的基本公式如下：<br>$$<br>S = \frac{T_0}{T_k}<br>$$<br>如果流水线各个流水段的执行时间都相等（设为Dt），则一条k段流水线完成n个连续任务所需要的时间为(k+n-1)Dt。如果不使用流水线，即顺序执行这 n 个任务，则所需要的时间为 nkDt。因此，各个流水段执行时间均相等的一条 k 段流水线完成 n 个连续任务 时的实际加速比为：<br>$$<br>S = \frac{nk\Delta{t}}{(k+n-1)\Delta{t}} = \frac{nk}{k+n-1}<br>$$<br>这种情况下的最大加速比为：<br>$$<br>S_{max} = \lim_{n\to\infty}\frac{nk}{k+n-1} = k<br>$$<br>效率：即流水线设备的利用率，指流水线中的设备实际使用时间与整个运行时间的比值</p>]]></content>
      
      
      <categories>
          
          <category> 系统架构师 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 系统架构师 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第3章：数据库系统</title>
      <link href="/2021/07/21/SystemArchitect/%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/"/>
      <url>/2021/07/21/SystemArchitect/%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h2 id="3-2-数据库模式与范式"><a href="#3-2-数据库模式与范式" class="headerlink" title="3.2 数据库模式与范式"></a>3.2 数据库模式与范式</h2><h3 id="3-2-4-数据的规范化"><a href="#3-2-4-数据的规范化" class="headerlink" title="3.2.4 数据的规范化"></a>3.2.4 数据的规范化</h3><p><strong>综合1NF、2NF和3NF、BCNF的内涵可概括如下</strong>：</p><p>（1）非主属性完全函数依赖于码（2NF的要求）</p><p>（2）非主属性不传递依赖于任何一个候选码（3NF的要求）</p><p>（3）主属性对不含它的码完全函数依赖（BCNF的要求）</p><p>（4）没有属性完全函数依赖于一组非主属性（BCNF的要求）</p><h2 id="3-3-数据库设计"><a href="#3-3-数据库设计" class="headerlink" title="3.3 数据库设计"></a>3.3 数据库设计</h2><h3 id="3-3-1-逻辑结构设计"><a href="#3-3-1-逻辑结构设计" class="headerlink" title="3.3.1 逻辑结构设计"></a>3.3.1 逻辑结构设计</h3><h4 id="1-基本E-R模型向关系模型转换"><a href="#1-基本E-R模型向关系模型转换" class="headerlink" title="1.基本E-R模型向关系模型转换"></a>1.基本E-R模型向关系模型转换</h4><h4 id="2-数据模型优化"><a href="#2-数据模型优化" class="headerlink" title="2.数据模型优化"></a>2.数据模型优化</h4><h5 id="（1）改善数据库的性能。"><a href="#（1）改善数据库的性能。" class="headerlink" title="（1）改善数据库的性能。"></a>（1）改善数据库的性能。</h5><ul><li>减少连接运算</li><li>减少关系大小和数据量（分表）</li></ul><blockquote><p>分表常用有<code>水平分割</code>与<code>垂直分割</code>。水平分割为分系建立关系，垂直分割为将常用数据与非常用数据分开。</p></blockquote><h5 id="（2）节约存储空间"><a href="#（2）节约存储空间" class="headerlink" title="（2）节约存储空间"></a>（2）节约存储空间</h5><ul><li>缩小每个属性占用的空间</li></ul><blockquote><p>通常可以有两种方法：即用编码和用缩写符号表示属性，但这两种方法的缺点是失去了属性值含义的直观性。</p></blockquote><ul><li>采用假属性</li></ul><h4 id="主要任务"><a href="#主要任务" class="headerlink" title="主要任务"></a>主要任务</h4><p>逻辑结构设计阶段的主要任务是确定数据模型、将ER图转换成指定数据模型、确定完整性约束、确定用户视图。</p><p><strong>超类实体</strong>：由多个实体中共有的属性组成</p><p><strong>派生属性</strong>：由其他属性计算获得，用于存储计算结果值。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 系统架构师 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第2章：操作系统</title>
      <link href="/2021/07/21/SystemArchitect/%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
      <url>/2021/07/21/SystemArchitect/%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 系统架构师 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 系统架构师 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第6章：开发方法</title>
      <link href="/2021/07/21/SystemArchitect/%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BC%80%E5%8F%91%E6%96%B9%E6%B3%95/"/>
      <url>/2021/07/21/SystemArchitect/%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BC%80%E5%8F%91%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="3-统一过程（Unified-Process-UP）"><a href="#3-统一过程（Unified-Process-UP）" class="headerlink" title="3.统一过程（Unified Process,UP）"></a>3.统一过程（Unified Process,UP）</h2><p>RUP软件开发生命周期是一个<code>二维</code>的软件开发模型，其中有9个核心工作流，分别为：</p><p>业务建模、需求</p><ul><li>分析设计</li><li>实施</li><li>测试</li><li>部署</li><li>配置与变更管理</li><li>项目管理</li><li>环境</li></ul><p>RUP把软件生命生存周期划分为多个循环，每个循环产生产品的一个新的版本，每个循环依次由4个连续的阶段组成，每个阶段完成确定的任务。这四个阶段分别为：</p><p>初始阶段：定义最终产品视图与业务模型，并确定系统范围。</p><p>细化阶段：设计及确定系统的体系结构，制定工作计划及资源要求。</p><p>构造阶段：构造产品并继续演进需求、体系构造、计划直至产品提交。</p><p>移交阶段：把产品提交给用户使用。</p><p>每个阶段都有一个或多人连续的迭代组成。迭代并不是重复得做相同的事，而是针对不同用例的细化和实现。每一个迭代都是一个完整的开发过程，它需要项目经理根据当前迭代所处的阶段以及上次迭代的结果，适当地对工作流中的行为进行裁剪。在每个阶段结束前都有一个里程碑评估该阶段的工作。如果未能通过该里程碑的评估，则决策者应该做出决定，是取消该项目还是继续该阶段的工作。</p><blockquote><p>与其他软件开发过程相比，RUP具有自己的特点，即RUP是用例驱动的、以体系结构为中心的、迭代和增量的软件开发过程。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 系统架构师 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%E8%AE%A1%E6%95%B0%E5%99%A8%E8%A7%A3%E5%86%B3%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%E8%AE%A1%E6%95%B0%E5%99%A8%E8%A7%A3%E5%86%B3%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis解决并发问题"><a href="#Redis解决并发问题" class="headerlink" title="Redis解决并发问题"></a>Redis解决并发问题</h2><p>用setnx替代set命令初始化计数器，这确保了一旦A初始化计数器成功，B就不会再去初始化计数器。</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 获取用户当前的排序</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> int</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="function"><span class="keyword">function</span> <span class="title">getCurrentOrder</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function">   </span>&#123;</span><br><span class="line">       <span class="variable">$redis</span> = <span class="keyword">new</span> R(<span class="string">&quot;game&quot;</span>);</span><br><span class="line">       <span class="variable">$order</span> = <span class="variable">$redis</span>-&gt;get(<span class="built_in">self</span>::<span class="variable">$hd_ename</span>);</span><br><span class="line">       <span class="variable">$number</span> = point_model::getPointLogByTips(<span class="built_in">self</span>::<span class="variable">$hd_ename</span>, <span class="string">&#x27;luckNumber&#x27;</span>);</span><br><span class="line">       <span class="keyword">if</span>(!<span class="variable">$order</span>)&#123;</span><br><span class="line">           <span class="keyword">if</span>(<span class="variable">$number</span>)&#123;</span><br><span class="line">               <span class="variable">$number</span> = <span class="variable">$number</span>[count(<span class="variable">$number</span>) - <span class="number">1</span>][<span class="string">&#x27;point&#x27;</span>];</span><br><span class="line">           &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">               <span class="variable">$number</span> = <span class="number">0</span>;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="variable">$redis</span>-&gt;setex(<span class="built_in">self</span>::<span class="variable">$hd_ename</span>,<span class="number">120</span>,<span class="variable">$number</span>);</span><br><span class="line">       &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">           <span class="variable">$number</span> = <span class="variable">$redis</span>-&gt;incr(<span class="built_in">self</span>::<span class="variable">$hd_ename</span>);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> <span class="variable">$number</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br></pre></td></tr></table></figure><p>我们都或多或少遇到过并发问题。家人因为看电视抢遥控器，这就是一种并发；两个孩子争着玩同一个玩具，这也是并发。在每一次“双11”购物节狂欢的背后，都有一群程序员在严阵以待，这不是一位数的并发，而是成千上万级别的并发。</p><p>说了什么是并发，接下来将向大家演示如何用Redis处理一个典型的并发问题。我们选择最常见的商品抢购场景，假定我们有100件商品，参与抢购的用户有成千上万，如何确保我们的商品不被多抢了？</p><p>聪明的你应该想到了，可以用计数器来控制，每卖出一件商品，计数器加1，当计数器到达100时，我们的商品就卖完了。程序的工作流程如下图。</p><p><img src="https://pic3.zhimg.com/80/v2-52e705a43600fb731c90c8d435414c02_720w.jpg" class="lazyload" data-srcset="https://pic3.zhimg.com/80/v2-52e705a43600fb731c90c8d435414c02_720w.jpg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><p>看起来很完美，但需要通过高并发场景的检验。我们假定有A、B两个进程同时在运行这段程序。</p><h3 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h3><p>初始化set计数器：A、B都发现计数器尚未初始化，在A执行“计数器加1”后，B去set计数器，此时计数器的值比正确值少1。（为什么时间差那么大？这在高并发场景中是完全可能存在的）</p><h3 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h3><p>计数器加1：A、B都读到计数器的值为99，不满足&gt;=100，两者都抢到了商品，但最终卖掉了101件，显然超卖了。</p><p>上面的流程存在两个问题，我们需要对程序流程做一点改进，新的流程如下图。</p><p><img src="https://pic2.zhimg.com/80/v2-9e9e1575fe948112e59fe808e02662f5_720w.jpg" class="lazyload" data-srcset="https://pic2.zhimg.com/80/v2-9e9e1575fe948112e59fe808e02662f5_720w.jpg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><h3 id="改进1"><a href="#改进1" class="headerlink" title="改进1"></a>改进1</h3><p>用setnx替代set命令初始化计数器，这确保了一旦A初始化计数器成功，B就不会再去初始化计数器。</p><h3 id="改进2"><a href="#改进2" class="headerlink" title="改进2"></a>改进2</h3><p>先对计数器加1，再判断计数器是否&gt;100，如果是，说明超卖了。这确保了即使A、B同时读到计数器的值为99，都去对计数器加1，两者至少有一个得到的结果&gt;100，不会超卖。</p><p>从以上的内容我们学习到，如何用Redis处理一个常见的并发场景，这背后还有更多的技术细节值得我们深入了解，期待在下一篇文章中与大家共同学习。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis的skiplist</title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-skiplist/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-skiplist/</url>
      
        <content type="html"><![CDATA[<h2 id="跳表的实现"><a href="#跳表的实现" class="headerlink" title="跳表的实现"></a>跳表的实现</h2><h2 id="从排行榜切入"><a href="#从排行榜切入" class="headerlink" title="从排行榜切入"></a>从排行榜切入</h2><p>懂行的老哥一看这个小标题，就知道我要以排行榜作为切入点，去讲 Redis 的 zset 了。</p><p>是的，经典面试题，请实现一个排行榜，大部分情况下就是在考验你知不知道 Redis 的 zset 结构，和其对应的操作。</p><p>当然了，排行榜我们也可以基于其他的解决方案。比如 mysql。</p><p>我曾经就基于 mysql 做过排行榜，一条 sql 就能搞定。但是仅限于数据量比较少，性能要求不高的场景（我当时只有 11 支队伍做排行榜，一分钟刷新一次排行榜）。</p><p>对于这种经典的面试八股文，网上一找一大把，所以本文就不去做相关解析了。</p><p>说好的只是一个切入点。</p><p>如果你不知道具体怎么实现，或者根本就不知道这题在问啥，那一定记得看完本文后要去看看相关的文章。最好自己实操一下。</p><p>相信我，八股文，得背，这题会考。</p><h2 id="zset的内部编码"><a href="#zset的内部编码" class="headerlink" title="zset的内部编码"></a>zset的内部编码</h2><p>众所周知，Redis 对外提供了五种基本数据类型。但是每一种基本类型的内部编码却是另外一番风景：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYboEKOkL1Zg0N9r5y8N6OkpicFXn33CRDQ3ziczW44BvAjr2m7Fl4t9Lw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYboEKOkL1Zg0N9r5y8N6OkpicFXn33CRDQ3ziczW44BvAjr2m7Fl4t9Lw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>其中 list 数据结构，在 Redis 3.2 版本中还提供了 quicklist 的内部编码。不是本文重点，我提一嘴就行，有兴趣的朋友自己去了解一下。</p><p>本文主要探讨的是上图中的 zset 数据结构。</p><p>zset 的内部编码有两种：ziplist 和 skiplist。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYmkuxp4btXyGicNm3MzUKftgJsk98iasvGxZMIRXTIfVcdRkFKRBBbGrg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYmkuxp4btXyGicNm3MzUKftgJsk98iasvGxZMIRXTIfVcdRkFKRBBbGrg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>其实你也别觉得这个东西有多神奇。因为对于这种对外一套，对内又是一套的“双标党”其实你已经很熟悉了。</p><p>它就是 JDK 的一个集合类，来朋友们，大胆的喊出它的名字：HashMap。</p><p>HashMap 除了基础的数组结构之外，还有另外两个数据结构：一个链表，一个红黑树。</p><p>这样一联想是不是就觉得也不过如此，心里至少有个底了。</p><p>当链表长度大于 8 且数组长度大于 64 的时候， HashMap 中的链表会转红黑数。</p><p>对于 zset 也是一样的，一定会有条件触发其内部编码 ziplist 和 skiplist 之间的变化？</p><p>这个问题的答案就藏在 redis.conf 文件中，其中有两个配置：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYSKxeMx9viclmXXInpcILfd0UjDLvCd4BiahoBLBmpHnYjwRWJ1Sgwh4w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYSKxeMx9viclmXXInpcILfd0UjDLvCd4BiahoBLBmpHnYjwRWJ1Sgwh4w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>上图中配置的含义是，当有序集合的元素个数小于 zset-max-ziplist-entries 配置的值，且每个元素的值的长度都小于 zset-max-ziplist-value 配置的值时，zset 的内部编码是 ziplist。</p><p>反之则用 skiplist。</p><p>理论铺垫上了，接下我给大家演示一波。</p><p>首先，我们给 memberscore 这个有序集合的 key 设置两个值，然后看看其内部编码：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYBubHhgphXIRItXPZRvXo7eULPrzKOANOQlf13YbbOKXYzsDsebCwfg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYBubHhgphXIRItXPZRvXo7eULPrzKOANOQlf13YbbOKXYzsDsebCwfg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>此时有序集合的元素个数是 2，可以看到，内部编码采用的是 ziplist 的结构。</p><p>为了大家方便理解这个储存，我给大家画个图：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYGiakfoo96w4EpxYP80ibia5wzCxrXkU0JibMwVNia0JTCaDjqIVXMI9yRvQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYGiakfoo96w4EpxYP80ibia5wzCxrXkU0JibMwVNia0JTCaDjqIVXMI9yRvQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>然后我们需要触发内部编码从 ziplist 到 skiplist 的变化。</p><p>先验证 zset-max-ziplist-value 配置，往 memberscore 元素中塞入一个长度大于 64字节（zset-max-ziplist-value默认配置）的值：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagY4ibibJIA3G5TkhtY6aNfvjWjIxg2yvVPG56B0En0o72mkCouYrDwFjcg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagY4ibibJIA3G5TkhtY6aNfvjWjIxg2yvVPG56B0En0o72mkCouYrDwFjcg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>这个时候 key 为 memberscore 的有序集合中有 3 个元素了，其中有一个元素的值特别长，超过了 64 字节。</p><p>此时的内部编码采用的是 skiplist。</p><p>接下来，我们往 zset 中多塞点值，验证一下元素个数大于 zset-max-ziplist-entries 的情况。</p><p>我们搞个新的 key，取值为 whytestkey。</p><p>首先，往 whytestkey 中塞两个元素，这是其内部编码还是 ziplist：</p><p><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="img"></p><p>那么问题来了，从配置来看 <code>zset-max-ziplist-entries 128</code>。</p><p>这个 128 是等于呢还是大于呢？</p><p>没关系，我也不知道，试一下就行了。</p><p>现在已经有两个元素了，再追加 126 个元素，看看：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYODSW4tgZ1SLcZedK5Kbj1g7gP6YdwLgiarLwzZmiaXJUfyo7myVDqsvg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYODSW4tgZ1SLcZedK5Kbj1g7gP6YdwLgiarLwzZmiaXJUfyo7myVDqsvg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>通过实验我们发现，当 whytestkey 中的元素个数是 128 的时候，其内部编码还是 ziplist。</p><p>那么触发其从 ziplist 转变为 skiplist 的条件是 元素个数大于 128，我们再加入一个试一试：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYCuhtkIJ9sric4IrfEtJ2nRRUcibO9iacz8oRMp1BaRqUyicXvE0AFGUnBA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYCuhtkIJ9sric4IrfEtJ2nRRUcibO9iacz8oRMp1BaRqUyicXvE0AFGUnBA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>果然，内部编码从 ziplist 转变为了 skiplist。</p><p>理论验证完毕，zset 确实是有两幅面孔。</p><p>本文主要探讨 skiplist 这个内部编码。</p><p><strong>它就是标题说的：基于运气的数据结构。</strong></p><h2 id="什么是-skiplist？"><a href="#什么是-skiplist？" class="headerlink" title="什么是 skiplist？"></a>什么是 skiplist？</h2><p>这个结构是一个叫做 William Pugh 的哥们在 1990 年发布的一篇叫做《Skip Lists: A Probabilistic Alternative to Balanced Trees》的论文中提出的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">论文地址：ftp://ftp.cs.umd.edu/pub/skipLists/skiplists.pdf</span><br></pre></td></tr></table></figure><p>摘要里面说：<strong>跳表是一种可以用来代替平衡树的数据结构，跳表使用概率平衡而不是严格的平衡，因此，与平衡树相比，跳表中插入和删除的算法要简单得多，并且速度要快得多。</strong></p><p>论文里面，在对跳表算法进行详细描述的地方他是这样说的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYSicUMOWRhTqj4ydKzAc2iaicosibwgWzbiaXq6ic0ruM1ge7wAibgic96eO6Lg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYSicUMOWRhTqj4ydKzAc2iaicosibwgWzbiaXq6ic0ruM1ge7wAibgic96eO6Lg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>首先火男大佬说，对于一个有序的链表来说，如果我们需要查找某个元素，必须对链表进行遍历。比如他给的示意图的 a 部分。</p><p>我单独截取一下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYbmljWXI3TGosN55nqlqTwebNhAj7m1m1WCicYlGePznBO18lzJ3xJBQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYbmljWXI3TGosN55nqlqTwebNhAj7m1m1WCicYlGePznBO18lzJ3xJBQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>这个时候，大家还能跟上，对吧。链表查找，逐个遍历是基本操作。</p><p>那么，如果这个链表是有序的，我们可以搞一个指针，这个指针指向的是该节点的下下个节点。</p><p>意思就是往上抽离一部分节点。</p><p>怎么抽离呢，每隔一个节点，就抽一个出来，和上面的 a 示意图比起来，变化就是这样的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagY5CYTFhkU3nPHctOlQGNP2libzhesOlg9kjC8CpuM6QYMFGwHA0ZxtAw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagY5CYTFhkU3nPHctOlQGNP2libzhesOlg9kjC8CpuM6QYMFGwHA0ZxtAw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>抽离出来有什么好处呢？</p><p>假设我们要查询的节点是 25 。</p><p>当就是普通有序链表的时候，我们从头节点开始遍历，需要遍历的路径是：</p><p>head -&gt; 3 -&gt; 6 -&gt; 7 -&gt; 9 -&gt; 12 -&gt; 17 -&gt; 19 -&gt; 21 -&gt; 25</p><p>需要 9 次查询才能找到 25 。</p><p>但是当结构稍微一变，变成了 b 示意图的样子之后，查询路径就是：</p><p>第二层的 head -&gt; 6 -&gt; 9 -&gt; 17 -&gt; 21 -&gt; 25。</p><p>5 次查询就找到了 25 。</p><p>这个情况下我们找到指定的元素，不会超过 (n/2)+1 个节点：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYA0WWThZZRrnYpmAEfBxnlNkibNbENGicLajUag8AEibPSoCBEnNrYTpkQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYA0WWThZZRrnYpmAEfBxnlNkibNbENGicLajUag8AEibPSoCBEnNrYTpkQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>那么这个时候有个小问题就来了：怎么从 21 直接到 25 的呢？</p><p>看论文中的图片，稍微有一点不容易明白。</p><p>所以，我给大家重新画个示意图：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYpdAT6CYksEql5Nyicld6EtjTbwMHY0FbtUsblVwjLQ7FKfaDaP4eVsg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYpdAT6CYksEql5Nyicld6EtjTbwMHY0FbtUsblVwjLQ7FKfaDaP4eVsg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>看到了吗？“多了”一个向下的指针。其实也不是多了，只是论文里面没有明示而已。</p><p>所以，查询 25 的路径是这样的，空心箭头指示的方向：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYeaWKF95FDUVeQgtm6E3qHBSLXmav6wZlchTGzTGLbk9TyvwicDHBtJw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYeaWKF95FDUVeQgtm6E3qHBSLXmav6wZlchTGzTGLbk9TyvwicDHBtJw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>在 21 到 26 节点之间，往下了一层，逻辑也很简单。</p><p>21 节点有一个右指针指向 26，先判断右指针的值大于查询的值了。</p><p>于是下指针就起到作用了，往下一层，再继续进行右指针的判断。</p><p>其实每个节点的判断逻辑都是这样，只是前面的判断结果是进行走右指针。</p><p>按照这个往上抽节点的思想，假设我们抽到第四层，也就是论文中的这个示意图：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYUicTC4kHOLTq5sE5FSuGYG3fjzS6pUuMfvzRLgdmUW5b3hLJnjTcicog/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYUicTC4kHOLTq5sE5FSuGYG3fjzS6pUuMfvzRLgdmUW5b3hLJnjTcicog/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>我们查询 25 的时候，只需要经过 2 次。</p><p>第一步就直接跳过了 21 之前的所有元素。</p><p>怎么样，爽不爽？</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYOyGaAhC7hkWxtibibARqs543wBl9MlyKl3vMibffug5oaUia8934jEjWCA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYOyGaAhC7hkWxtibibARqs543wBl9MlyKl3vMibffug5oaUia8934jEjWCA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>但是，它是有缺陷的。</p><p>火男的论文里面是这样说的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagY9awmWQTpic6f8n0ib4KfQUjOplM5PYtNwRjpvKiaOcwC9JmqVtosOrFOA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagY9awmWQTpic6f8n0ib4KfQUjOplM5PYtNwRjpvKiaOcwC9JmqVtosOrFOA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>This data structure could be used for fast searching, but insertion and deletion would be impractical.</p><p>查询确实飞快。但是对于插入和删除  would be impractical。</p><p>impractical 是什么意思？</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYH4fpODXHY3ukOpVDc3zVepCtUMVU6URtVGSlCblpxq8LZR6xscJjDA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYH4fpODXHY3ukOpVDc3zVepCtUMVU6URtVGSlCblpxq8LZR6xscJjDA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>你看，又学一个四级单词。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagY3UibWicbCbViaudEY5jBv470VQh5QEltBj9e8P5m590ZGM4W1kZZTbmWw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagY3UibWicbCbViaudEY5jBv470VQh5QEltBj9e8P5m590ZGM4W1kZZTbmWw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>对于插入和删除几乎是难以实现的。</p><p>你想啊，上面那个最底层的有序链表，我一开始就拿出来给你了。</p><p>然后我就说基于这个有序链表每隔一个节点抽离到上一层去，再构建一个链表。那么这样上下层节点比例应该是 2:1。巴拉巴拉的…..</p><p>但是实际情况应该是我们最开始的时候连这个有序链表都没有，需要自己去创建的。</p><p>就假设要在现有的这个跳表结构中插入一个节点，毋庸置疑，肯定是要插入到最底层的有序链表中的。</p><p>但是你破坏了上下层 2:1 的比例了呀？</p><p>怎么办，一层层的调整呗。</p><p>可以，但是请你考虑一下编码实现起来的难度和对应的时间复杂度？</p><p>要这样搞，直接就是一波劝退。</p><p>这就受不了了？</p><p>我还没说删除的事呢。</p><p>那怎么办？</p><p>看看论文里面怎么说到：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYL4NFA3AfHoykHGwIYUXg88MsrH6tuRKTd3qyMV1h47nnMpKJ2IU8WQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYL4NFA3AfHoykHGwIYUXg88MsrH6tuRKTd3qyMV1h47nnMpKJ2IU8WQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>首先我们关注一下第一段划红线的地方。</p><p>火男写到：50% 的节点在第一层，25% 的节点在第二层， 12.5% 的节点在第三层。</p><p>你以为他在给你说什么？</p><p>他要表达的意思除了每一层节点的个数之外，还说明了层级：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYE1EaPo5Hd1a6PKVPASmibDibcGNF4c4LDvwMLkDicbNkTJUpiaY130Uziag/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYE1EaPo5Hd1a6PKVPASmibDibcGNF4c4LDvwMLkDicbNkTJUpiaY130Uziag/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>没有第 0 层，至少论文里面没有说有第 0 层。</p><p>如果你非要说最下面那个有全部节点的有序链表叫做第 0 层，我觉得也可以。但是，我觉得叫它基础链表更加合适一点。</p><p>然后我再看第二段划线的地方。</p><p>火男提到了一个关键词：randomly，意思是随机。</p><p>说出来你可能不信，但是跳表是用随机的方式解决上面提出的插入（删除）之后调整结构的问题。</p><p>怎么随机呢？抛硬币。</p><p>是的，没有骗你，真的是“抛硬币”。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYVVCaA7eaFf74GcRRHbLmTnAgCyPicWefYwY81zMeTFteCTAW4a4U0Ew/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYVVCaA7eaFf74GcRRHbLmTnAgCyPicWefYwY81zMeTFteCTAW4a4U0Ew/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><h2 id="跳表中的“硬币”"><a href="#跳表中的“硬币”" class="headerlink" title="跳表中的“硬币”"></a>跳表中的“硬币”</h2><p>当跳表中插入一个元素的时候，火男表示我们上下层之间可以不严格遵循 1:2 的节点关系。</p><p>如果插入的这个元素需要建立索引，那么把索引建立在第几层，都是由抛硬币决定的。</p><p>或者说：由抛硬币的概率决定的。</p><p>我问你，一个硬币抛出去之后，是正面的概率有多大？</p><p>是不是 50%？</p><p>如果我们把这个概率记为 p，那么 50%，即 p=1/2。</p><p>上面我们提到的概率，到底是怎么用的呢？</p><p>火男的论文中有一小节是这样的写的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagY4IzBuF3t5kz9Xay9bx924ZXdN3ChDTEictfvJ9HOYIia1hVECsoic7pgw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagY4IzBuF3t5kz9Xay9bx924ZXdN3ChDTEictfvJ9HOYIia1hVECsoic7pgw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>随机选择一个层级。他说我们假设概率 p=1/2，然后叫我们看图 5。</p><p>图 5 是这样的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYgTgIuQwFv5sG1iaoc7VkCJWUfgxe01sNOkyadJkiaZcQ1xpy7s6OjPtA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYgTgIuQwFv5sG1iaoc7VkCJWUfgxe01sNOkyadJkiaZcQ1xpy7s6OjPtA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>非常关键的一张图啊。</p><p>短短几行代码，描述的是如何选择层级的随机算法。</p><p>首先定义初始层级为 1（lvl := 1）。</p><p>然后有一行注释：random() that returns a random value in [0…1)</p><p>random() 返回一个 [0…1) 之间的随机值。</p><p>接下来一个 while…do 循环。</p><p>循环条件两个。</p><p>第一个：random() &lt; p。由于 p = 1/2，那么该条件成立的概率也是 1/2。</p><p>如果每随机一次，满足 random() &lt; p，那么层级加一。</p><p>那假设你运气爆棚，接连一百次随机出来的数都是小于 p 的怎么办？岂不是层级也到 100 层了？</p><p>第二个条件 lvl &lt; MaxLevel，就是防止这种情况的。可以保证算出来的层级不会超过指定的 MaxLevel。</p><p>这样看来，虽然每次都是基于概率决定在那个层级，但是总体趋势是趋近于 1/2 的。</p><p>带来的好处是，每次插入都是独立的，只需要调整插入前后节点的指针即可。</p><p>一次插入就是一次查询加更新的操作，比如下面的这个示意图：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYtkyn4sLLQINCXmm28oTDhHB5Ka6WfnsYDxB54CvDuHiaqz20iag9dqPA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYtkyn4sLLQINCXmm28oTDhHB5Ka6WfnsYDxB54CvDuHiaqz20iag9dqPA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>对于这个概率，其实火男在论文专门写了一个小标题，还给出了一个图表：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYLDx8Bc6McY6bOzFavMGuus9bz0viaKUwgUwiaQs2YuBV1Wudh0jPFeZg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYLDx8Bc6McY6bOzFavMGuus9bz0viaKUwgUwiaQs2YuBV1Wudh0jPFeZg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>最终得出的结论是，火男建议 p 值取 1/4。如果你主要关心的是执行时间的变化，那么 p 就取值 1/2。</p><p>说一下我的理解。首先跳表这个是一个典型的空间换时间的例子。</p><p>一个有序的二维数组，查找指定元素，理论上是二分查找最快。而跳表就是在基础的链表上不断的抽节点（或者叫索引），形成新的链表。</p><p>所以，当 p=1/2 的时候，就近似于二分查找，查询速度快，但是层数比较高，占的空间就大。</p><p>当 p=1/4 的时候，元素升级层数的概率就低，总体层高就低，虽然查询速度慢一点，但是占的空间就小一点。</p><p>根据《Redis深度历险》一书里面的描述，在 Redis 中 p 的取值就是 1/4，MaxLevel 的取值是 64（视版本而定，有的Redis版本是32）。</p><p>论文里面还花了大量的篇幅去推理时间复杂度，有兴趣的可以去看着论文一起推理一下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYEoC5DIrWSNZvFARtL37QuSruy66abwiaib8x0DzYl1uZWzuJbLvFuM8w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYEoC5DIrWSNZvFARtL37QuSruy66abwiaib8x0DzYl1uZWzuJbLvFuM8w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><h2 id="跳表在Java中的应用"><a href="#跳表在Java中的应用" class="headerlink" title="跳表在Java中的应用"></a>跳表在Java中的应用</h2><p>跳表，虽然是一个接触比较少的数据结构。</p><p>其实在 java 中也有对应的实现。</p><p>先问个问题：Map 家族中大多都是无序的，那么请问你知道有什么 Map 是有序的呢？</p><p>TreeMap，LinkedHashMap 是有序的，对吧。</p><p>但是他们不是线程安全的。</p><p>那么既是线程安全的，又是有序的 Map 是什么？</p><p>那就是它，一个存在感也是低的不行的 ConcurrentSkipListMap。</p><p>你看它这个名字多吊，又有 list 又有 Map。</p><p>看一个测试用例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public class MainTest &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        ConcurrentSkipListMap&lt;Integer, String&gt; skipListMap = new ConcurrentSkipListMap&lt;&gt;();</span><br><span class="line">        skipListMap.put(3,&quot;3&quot;);</span><br><span class="line">        skipListMap.put(6,&quot;6&quot;);</span><br><span class="line">        skipListMap.put(7,&quot;7&quot;);</span><br><span class="line">        skipListMap.put(9,&quot;9&quot;);</span><br><span class="line">        skipListMap.put(12,&quot;12&quot;);</span><br><span class="line">        skipListMap.put(17,&quot;17&quot;);</span><br><span class="line">        skipListMap.put(19,&quot;19&quot;);</span><br><span class="line">        skipListMap.put(21,&quot;21&quot;);</span><br><span class="line">        skipListMap.put(25,&quot;25&quot;);</span><br><span class="line">        skipListMap.put(26,&quot;26&quot;);</span><br><span class="line">        System.out.println(&quot;skipListMap = &quot; + skipListMap);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果是这样的，确实是有序的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYMiaCibxs8ZjeVfAnFGD91tMT3X8gSZKt53YNJT4Vicy72bYb5H8UOburQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYMiaCibxs8ZjeVfAnFGD91tMT3X8gSZKt53YNJT4Vicy72bYb5H8UOburQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>稍微的剖析一下。首先看看它的三个关键结构。</p><p>第一个是 index：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYUdYUTrmaG0EbCUux2VzuNE0x919E8cyqiagltyeialdxR8GiajHuB3Imw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYUdYUTrmaG0EbCUux2VzuNE0x919E8cyqiagltyeialdxR8GiajHuB3Imw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>index 里面包含了一个节点 node、一个右指针（right）、一个下指针（down）。</p><p>第二个是 HeadIndex:</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYYbqjhtYdrJqjYiclEHTBSibRKjPEB5b9SUCmEZ5rwficialZnSshkE902A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYYbqjhtYdrJqjYiclEHTBSibRKjPEB5b9SUCmEZ5rwficialZnSshkE902A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>它是继承自 index 的，只是多了一个 level 属性，记录是位于第几层的索引。</p><p>第三个是 node：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYb40sYVj8dWwo6CmibTvQ4XelP6wtacn8DWsMelqZahB5auRwLQcUhZQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYb40sYVj8dWwo6CmibTvQ4XelP6wtacn8DWsMelqZahB5auRwLQcUhZQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>这个 node 没啥说的，一看就是个链表。</p><p>这三者之间的关系就是示意图这样的：</p><p><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="img"></p><p>我们就用前面的示例代码，先 debug 一下，把上面的示意图，用真实的值填充上。</p><p>debug 跑起来之后，可以看到当前是有两层索引的，需要注意的是这里的两层是不包含最底层的基础的有序链表的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYibibRmztLSpVMRhhEQnkxzDOWPEpled6nXCicQibPhPITxHWpo0UIueNdg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYibibRmztLSpVMRhhEQnkxzDOWPEpled6nXCicQibPhPITxHWpo0UIueNdg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>我们先看看第二层的链表是怎样的，也就是看第二层头节点的 right 属性：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYEeVnglicZwft6XDsiaqWy7TL8nuq4aezmic46NSsNd6plCgHibhR2Zl1Zg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYEeVnglicZwft6XDsiaqWy7TL8nuq4aezmic46NSsNd6plCgHibhR2Zl1Zg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>所以第二层的链表是这样的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYO7gxvrUqV5hNUJKhcBsGW7Ot63ICskbe0xmYJMQUvYDcFgIXkqiboyA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYO7gxvrUqV5hNUJKhcBsGW7Ot63ICskbe0xmYJMQUvYDcFgIXkqiboyA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>第二层的 HeadIndex 节点除了我们刚刚分析的 right 属性外，还有一个 down，指向的是下一层，也就是第一层的 HeadIndex：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYrdLcOqjmhaFq8DfRH2BIAjHLxab3JPWWlice8kW3esav6P01JCn2ibEQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYrdLcOqjmhaFq8DfRH2BIAjHLxab3JPWWlice8kW3esav6P01JCn2ibEQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>可以看到第一层的 HeadIndex 的 down 属性是 null。但是它的 right 属性是有值的，但 right 属性里面的 down 属性也是 null：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYORwyEeJHTqTPwKtRWlQXpxUSGeQt1KDCJoBO7sKHiaRKMOgPDEyCQSA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYORwyEeJHTqTPwKtRWlQXpxUSGeQt1KDCJoBO7sKHiaRKMOgPDEyCQSA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>可以画出第一层的链表结构是这样的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYibfXTOVMfa1iayasUhnQNX17xxKJwlSaa43MytibV3I0e7iaMovHtQRDhQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYibfXTOVMfa1iayasUhnQNX17xxKJwlSaa43MytibV3I0e7iaMovHtQRDhQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>同时我们可以看到其 node 属性里面其实是整个有序链表（其实每一层的 HeadIndex 里面都有，right 节点里面也有）：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYLQxgQsdrAkQu5Qnq7fPdlsv7YKAQykT1QAdWq2sGlhscMEwf3Az0IQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYLQxgQsdrAkQu5Qnq7fPdlsv7YKAQykT1QAdWq2sGlhscMEwf3Az0IQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>所以，整个跳表结构是这样的，需要注意的是最底层的有序链表和第一层之间是虚线连接的，它们之间是不存在 down 属性的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHdVtLJDJlcpphCKqfpx3icfrtbmNhISxwIUO5SvZm1UscKbV0A1vt2hbwZZkaFzkES74nyzpWEfLdQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHdVtLJDJlcpphCKqfpx3icfrtbmNhISxwIUO5SvZm1UscKbV0A1vt2hbwZZkaFzkES74nyzpWEfLdQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>但是当你拿着同样的程序，自己去调试的时候，你会发现，你的跳表不长这样啊？</p><p>当然不一样了，一样了才是撞了鬼了。</p><p>别忘了，索引的层级是随机产生的。</p><p>ConcurrentSkipListMap 是怎样随机的呢？</p><p>带大家看看 put 部分的源码。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYVuhMNAeDf8ic4F4oxmca1UrXtOiaoicoicQhBKYzm86N2nFVcUqrIx2rgg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYVuhMNAeDf8ic4F4oxmca1UrXtOiaoicoicQhBKYzm86N2nFVcUqrIx2rgg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>标号为 ① 的地方代码很多，但是核心思想是把指定元素维护进最底层的有序链表中。就不进行解读了，所以我把这块代码折叠起来了。</p><p>标号为 ② 的地方是 <code>(rnd &amp; 0x80000001) == 0</code>。</p><p>这个 rnd 是上一行代码随机出来的值。</p><p>而 0x80000001 对应的二进制是这样的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYVn3ehv3RlynCt1Zy6CXQXYR1las33hgaY2icR5vIzZf4dZbibE0y1ImA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYVn3ehv3RlynCt1Zy6CXQXYR1las33hgaY2icR5vIzZf4dZbibE0y1ImA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>一头一尾都是1，其他位都是 0。</p><p>那么只有 rnd 的一头一尾都是 0 的时候，才会满足 if 条件，<code>(rnd &amp; 0x80000001) == 0</code>。</p><p>二进制的一头一尾都是 0，说明是一个正偶数。</p><p>随机出来一个正偶数的时候，表明需要对其进行索引的维护。</p><p>负偶数，负奇数，正偶数，正奇数。而这里只要正偶数，说明这里的概率其实是 1/4。</p><p>标号为 ③ 的地方是判断当前元素要维护到第几层索引中。默认是第 1 层。</p><p><code>((rnd &gt;&gt;&gt;= 1) &amp; 1) != 0</code> ，已知 rnd 是一个正偶数，那么从其二进制的低位的第二位（第一位肯定是0嘛）开始，有几个连续的 1，就维护到第几层。</p><p>不明白？没关系，我举个例子。</p><p>假设随机出来的正偶数是 110，其二进制是 01101110。因为有 3 个连续的 1，那么 level 就是从 1 连续自增 3 次，最终的 level 就是 4。</p><p>那么问题就来了，如果我们当前最多只有 2 层索引呢？直接就把索引干到第 4 层吗？</p><p>这个时候标号为 ④ 的代码的作用就出来了。</p><p>如果新增的层数大于现有的层数，那么只是在现有的层数上进行加一。</p><p>这个时候我们再回过头去看看火男论文里面的随机算法：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYgTgIuQwFv5sG1iaoc7VkCJWUfgxe01sNOkyadJkiaZcQ1xpy7s6OjPtA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYgTgIuQwFv5sG1iaoc7VkCJWUfgxe01sNOkyadJkiaZcQ1xpy7s6OjPtA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>意思是一个意思，但是实现起来其实是两个不同的方案。但是核心实现都是随机。</p><p>所以，你现在知道了，由于有随机数的出现，所以即使是相同的参数，每次都可以构建出不一样的跳表结构。</p><p>比如还是前面演示的代码，我 debug 截图的时候有两层索引。</p><p>但是，其实有的时候我也会碰到 3 层索引的情况。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYwf0HQXgPRn5usM487UJtqAgInSl59FvibWhs58ibyiatbzrrnTmrOYIpw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYwf0HQXgPRn5usM487UJtqAgInSl59FvibWhs58ibyiatbzrrnTmrOYIpw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>别问为什么，用心去感受，你心里应该有数。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYvNRuOp3icVsMUGialIfnrQiboBWNJjLwDrGKUY2JeWOKxba0wY1grKBVQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYvNRuOp3icVsMUGialIfnrQiboBWNJjLwDrGKUY2JeWOKxba0wY1grKBVQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>另外，开篇用 redis 作为了切入点，其实 redis 的跳表整体思想是大同的，但是也是有小异的。</p><p>比如 Redis 在 skiplist 的 forward 指针（相当于 index）上，每个 forward 指针都增加了 span 属性。</p><p>在《Redis深度历险》一书里面对该属性进行了描述：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYe7GQbT167TysDH43JCwHRk0QBKNfLWZjPMzibEXMlbJTOkAaMCklmUQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_png/lnCqjsQ6QHesdTvK7xXGN5cLaYWzibiagYe7GQbT167TysDH43JCwHRk0QBKNfLWZjPMzibEXMlbJTOkAaMCklmUQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图片"></p><p>好了，那么这次的文章就到这里啦。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%E5%BA%94%E7%94%A8-%E4%BD%8D%E5%9B%BE/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%E5%BA%94%E7%94%A8-%E4%BD%8D%E5%9B%BE/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis应用-位图"><a href="#Redis应用-位图" class="headerlink" title="Redis应用-位图"></a>Redis应用-位图</h2><p>我们都知道8bit = 1b = 2^-10kb， <code>bitmap</code>就是通过最小的单位 <code>bit</code>来进行0或者1的设置，表示某个元素对应的值或者状态。</p><p>一个bit的值，或者是0，或者是1；也就是说一个bit能存储的最多信息是2。</p><p>位图并不是一种特殊的数据结构，其实本质上是二进制字符串，也可以看做是 byte 数组。可以使用普通的 get/set 直接获取和设置整个位图的内容，也可以使用位图操作 getbit/setbit 等将 byte 数组看成「位数组」来处理。</p><h3 id="位图的优势"><a href="#位图的优势" class="headerlink" title="位图的优势:"></a>位图的优势:</h3><ol><li>基于最小的单位bit进行存储，所以非常省空间。</li><li>设置时候时间复杂度O(1)、读取时候时间复杂度O(n)，操作是非常快的</li><li>二进制数据的存储，进行相关计算的时候非常快</li><li>方便扩容</li></ol><h3 id="一般可以在如下场景使用："><a href="#一般可以在如下场景使用：" class="headerlink" title="一般可以在如下场景使用："></a>一般可以在如下场景使用：</h3><ol><li>用户签到</li><li>用户在线状态</li><li>统计活跃用户</li><li>各种状态值</li></ol><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><h5 id="SETBIT"><a href="#SETBIT" class="headerlink" title="SETBIT"></a>SETBIT</h5><p>对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。<code>SETBIT key offset value</code>offset 参数必须大于或等于 0 ，小于 2^32 (bit 映射被限制在 512 MB 之内)。</p><h4 id="GETBIT"><a href="#GETBIT" class="headerlink" title="GETBIT"></a>GETBIT</h4><p>对 key 所储存的字符串值，获取指定偏移量上的位(bit)。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GETBIT key offset</span><br></pre></td></tr></table></figure><h4 id="BITCOUNT"><a href="#BITCOUNT" class="headerlink" title="BITCOUNT"></a>BITCOUNT</h4><p>计算给定字符串中，被设置为 1 的比特位的数量。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BITCOUNT key</span><br></pre></td></tr></table></figure><h4 id="BITPOS"><a href="#BITPOS" class="headerlink" title="BITPOS"></a>BITPOS</h4><p>返回位图中第一个值为 bit 的二进制位的位置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BITPOS key bit[start][end]</span><br></pre></td></tr></table></figure><h4 id="BITOP"><a href="#BITOP" class="headerlink" title="BITOP"></a>BITOP</h4><p>对一个或多个保存二进制位的字符串 key 进行位元操作，并将结果保存到 destkey 上。</p><p><code>BITOP operation destkey key[key…]</code>operation 可以是 AND 、 OR 、 NOT 、 XOR 这四种操作中的任意一种 <code>BITOP AND destkey key[key...]</code>，对一个或多个 key 求逻辑并，并将结果保存到 destkey 。</p><h4 id="BITFIELD"><a href="#BITFIELD" class="headerlink" title="BITFIELD"></a>BITFIELD</h4><p>bitfield 有三个子指令，分别是 get/set/incrby，它们都可以对指定位片段进行读写，但是最多只能处理 64 个连续的位，如果超过 64 位，就得使用多个子指令，bitfield 可以一次执行多个子指令。</p><h3 id="适用于各类统计应用"><a href="#适用于各类统计应用" class="headerlink" title="适用于各类统计应用"></a>适用于各类统计应用</h3><p>记录用户的签到，每日在线情况等，可以将当天或者当天的偏移量对应的bit位设置为1即可，使用 <code>BITCOUNT</code>可以轻松统计签到次数。</p><p>还有一种使用比较多的情况，就是设置各类状态值，例如商城的设置：是否可以评价订单，是否展示售罄商品，是否正常营业等状态值可以使用bitmap来存储</p><p>在性能方面，如前面提到的签到，即使运行 10 年，占用的空间也只是每个用户 10*365 比特位(bit)，也即是每个用户 456 字节。对于这种大小的数据来说， BITCOUNT key [start] [end] 的处理速度就像 GET key 和 INCR key 这种 O(1) 复杂度的操作一样快。</p><p>当然如果你的 bitmap 数据非常大，那么可以考虑使用以下两种方法：</p><ul><li>将一个大的 bitmap 分散到不同的 key 中，作为小的 bitmap 来处理。使用 Lua 脚本可以很方便地完成这一工作。</li><li>使用 BITCOUNT key [start] [end] 的 start 和 end 参数，每次只对所需的部分位进行计算，然后在进行累加。</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis常见问题</title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Redis雪崩、穿透、并发等5大难题解决方案"><a href="#一、Redis雪崩、穿透、并发等5大难题解决方案" class="headerlink" title="一、Redis雪崩、穿透、并发等5大难题解决方案"></a>一、Redis雪崩、穿透、并发等5大难题解决方案</h2><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>数据未加载到缓存中，或者缓存同一时间大面积的失效，从而导致所有请求都去查数据库，导致数据库CPU和内存负载过高，甚至宕机。</p><p><strong>雪崩的简单过程：</strong></p><ol><li>redis集群大面积故障</li><li>缓存失效，但依然大量请求访问缓存服务redis</li><li>redis大量失效后，大量请求转向到mysql数据库</li><li>mysql的调用量暴增，很快就扛不住了，甚至直接宕机</li><li>由于大量的应用服务依赖mysql和redis的服务，这个时候很快会演变成各服务器集群的雪崩，最后网站彻底崩溃。</li></ol><p><strong>如何预防缓存雪崩：</strong></p><p>缓存层设计成高可用，防止缓存大面积故障。即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务，例如 Redis Sentinel 和 Redis Cluster 都实现了高可用。</p><p><em>2.缓存降级</em></p><p>可以利用ehcache等本地缓存(暂时支持)，但主要还是对源服务访问进行<strong>限流</strong>、<strong>资源隔离（熔断）</strong>、<strong>降级</strong>等。</p><p>当访问量剧增、服务出现问题仍然需要保证服务还是可用的。系统可以根据一些关键数据进行<strong>自动降级</strong>，也可以配置开关实现<strong>人工降级</strong>，这里会涉及到运维的配合。</p><p><strong>降级的最终目的是保证核心服务可用，即使是有损的。</strong></p><p>比如推荐服务中，很多都是个性化的需求，假如个性化需求不能提供服务了，可以降级补充热点数据，不至于造成前端页面是个大空白。</p><p>在进行降级之前要对系统进行梳理，比如：哪些业务是核心(必须保证)，哪些业务可以容许暂时不提供服务(利用静态页面替换)等，以及配合服务器核心指标，来后设置整体预案，比如：</p><p>（1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</p><p>（2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；</p><p>（3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</p><p>（4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</p><p><em>3.Redis备份和快速预热</em></p><p>(1)Redis数据备份和恢复</p><p>(2)快速缓存预热</p><p><em>4.提前演练</em></p><p>最后，建议还是在项目上线前，演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，对高可用提前预演，提前发现问题。</p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>缓存穿透是指查询一个一不存在的数据。例如：从缓存redis没有命中，需要从mysql数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。</p><p>解决思路：</p><p>如果查询数据库也为空，直接设置一个默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库。设置一个过期时间或者当有值的时候将缓存中的值替换掉即可。</p><p>可以给key设置一些格式规则，然后查询之前先过滤掉不符合规则的Key。</p><h3 id="缓存并发"><a href="#缓存并发" class="headerlink" title="缓存并发"></a>缓存并发</h3><p>这里的并发指的是多个redis的client同时set key引起的并发问题。其实redis自身就是单线程操作，多个client并发操作，按照先到先执行的原则，先到的先执行，其余的阻塞。当然，另外的解决方案是把redis.set操作放在队列中使其串行化，必须的一个一个执行。</p><h3 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h3><p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。</p><p>这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！</p><p>解决思路：</p><ol><li><p>直接写个缓存刷新页面，上线时手工操作下；</p></li><li><p>数据量不大，可以在项目启动的时候自动进行加载；</p></li></ol><p>目的就是在系统上线前，将数据加载到缓存中。</p><h2 id="二、Redis为什么是单线程，高并发快的3大原因详解"><a href="#二、Redis为什么是单线程，高并发快的3大原因详解" class="headerlink" title="二、Redis为什么是单线程，高并发快的3大原因详解"></a>二、Redis为什么是单线程，高并发快的3大原因详解</h2><p><strong>Redis的高并发和快速原因</strong></p><ol><li>redis是基于内存的，内存的读写速度非常快；</li><li>redis是单线程的，省去了很多上下文切换线程的时间；</li><li>redis使用多路复用技术，可以处理并发的连接。非阻塞IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间。</li></ol><p>下面重点介绍单线程设计和IO多路复用核心设计快的原因。</p><h3 id="为什么Redis是单线程的？"><a href="#为什么Redis是单线程的？" class="headerlink" title="为什么Redis是单线程的？"></a>为什么Redis是单线程的？</h3><p><strong>1.官方答案</strong></p><p>因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。</p><p><strong>2.性能指标</strong></p><p>关于redis的性能，官方网站也有，普通笔记本轻松处理每秒几十万的请求。</p><p><strong>3.详细原因</strong></p><p><em>1.不需要各种锁的性能消耗</em></p><p>Redis的数据结构并不全是简单的Key-Value，还有list，hash等复杂的结构，这些结构有可能会进行很细粒度的操作，比如在很长的列表后面添加一个元素，在hash当中添加或者删除一个对象。这些操作可能就需要加非常多的锁，导致的结果是同步开销大大增加。</p><p>总之，在单线程的情况下，就不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。</p><p><em>2.单线程多进程集群方案</em></p><p>单线程的威力实际上非常强大，每核心效率也非常高，多线程自然是可以比单线程有更高的性能上限，但是在今天的计算环境中，即使是单机多线程的上限也往往不能满足需要了，需要进一步摸索的是多服务器集群化的方案，这些方案中多线程的技术照样是用不上的。</p><p><strong>所以单线程、多进程的集群不失为一个时髦的解决方案。</strong></p><p><em>3.CPU消耗</em></p><p>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU。但是如果CPU成为Redis瓶颈，或者不想让服务器其他CUP核闲置，那怎么办？</p><p>可以考虑多起几个Redis进程，Redis是key-value数据库，不是关系数据库，数据之间没有约束。只要客户端分清哪些key放在哪个Redis进程上就可以了。</p><h3 id="Redis单线程的优劣势"><a href="#Redis单线程的优劣势" class="headerlink" title="Redis单线程的优劣势"></a>Redis单线程的优劣势</h3><p><strong>单进程单线程优势</strong></p><p>代码更清晰，处理逻辑更简单不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗不存在多进程或者多线程导致的切换而消耗CPU</p><p><strong>单进程单线程弊端</strong></p><p>无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来完善；</p><p><strong>IO多路复用技术</strong></p><p>redis 采用网络IO多路复用技术来保证在多连接的时候， 系统的高吞吐量。</p><p>多路-指的是多个socket连接，复用-指的是复用一个线程。多路复用主要有三种技术：select，poll，epoll。epoll是最新的也是目前最好的多路复用技术。</p><p>这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。</p><h3 id="Redis高并发快总结"><a href="#Redis高并发快总结" class="headerlink" title="Redis高并发快总结"></a>Redis高并发快总结</h3><ol><li><p>Redis是纯内存数据库，一般都是简单的存取操作，线程占用的时间很多，时间的花费主要集中在IO上，所以读取速度快。</p></li><li><p>再说一下IO，Redis使用的是非阻塞IO，IO多路复用，使用了单线程来轮询描述符，将数据库的开、关、读、写都转换成了事件，减少了线程切换时上下文的切换和竞争。</p></li><li><p>Redis采用了单线程的模型，保证了每个操作的原子性，也减少了线程的上下文切换和竞争。</p></li><li><p>另外，数据结构也帮了不少忙，Redis全程使用hash结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化，如<strong>压缩表</strong>，对短数据进行压缩存储，再如，<strong>跳表</strong>，使用有序的数据结构加快读取的速度。</p></li><li><p>还有一点，Redis采用自己实现的事件分离器，效率比较高，内部采用非阻塞的执行方式，吞吐能力比较大。</p></li></ol><h2 id="三、Redis缓存和MySQL数据一致性方案详解"><a href="#三、Redis缓存和MySQL数据一致性方案详解" class="headerlink" title="三、Redis缓存和MySQL数据一致性方案详解"></a>三、Redis缓存和MySQL数据一致性方案详解</h2><p>  <strong>需求起因</strong></p><p>  在高并发的业务场景下，数据库大多数情况都是用户并发访问最薄弱的环节。所以，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问MySQL等数据库。<br><img src="https://imgkr2.cn-bj.ufileos.com/d2fdd2df-baf6-4ed8-80a1-fe1312580fa7.webp?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=NNgj%252B6rJGGpIlNEMPUIe2hK4NJc%253D&Expires=1608361901" class="lazyload" data-srcset="https://imgkr2.cn-bj.ufileos.com/d2fdd2df-baf6-4ed8-80a1-fe1312580fa7.webp?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=NNgj%252B6rJGGpIlNEMPUIe2hK4NJc%253D&Expires=1608361901" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>  这个业务场景，主要是解决读数据从Redis缓存，一般都是按照下图的流程来进行业务操作。</p><p><img src="https://imgkr2.cn-bj.ufileos.com/d27cc1ee-a94a-46f7-8d7d-61a93103ff82.webp?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=ihMJVORnZzvUDQhP6PnYFCrSn6E%253D&Expires=1608365871" class="lazyload" data-srcset="https://imgkr2.cn-bj.ufileos.com/d27cc1ee-a94a-46f7-8d7d-61a93103ff82.webp?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=ihMJVORnZzvUDQhP6PnYFCrSn6E%253D&Expires=1608365871" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>  读取缓存步骤一般没有什么问题，但是一旦涉及到数据更新：数据库和缓存更新，就容易出现<strong>缓存(Redis)和数据库（MySQL）间的数据一致性问题</strong>。</p><p>  不管是先写MySQL数据库，再删除Redis缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况。举一个例子：</p><ol><li><p>如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。</p></li><li><p>如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。</p></li></ol><p><strong>因为写和读是并发的，没法保证顺序,就会出现缓存和数据库的数据不一致的问题。</strong></p><p>如来解决？这里给出两个解决方案，先易后难，结合业务和技术代价选择使用。</p><h3 id="缓存和数据库一致性解决方案"><a href="#缓存和数据库一致性解决方案" class="headerlink" title="缓存和数据库一致性解决方案"></a>缓存和数据库一致性解决方案</h3><p><strong>1.第一种方案：采用延时双删策略</strong></p><p><img src="https://imgkr2.cn-bj.ufileos.com/bd309e8b-1890-428e-8fe0-b21d4b60c9b5.webp?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=30D7IY5Fy2JVu%252BX3JK9RSK0kq%252Bg%253D&Expires=1608371054" class="lazyload" data-srcset="https://imgkr2.cn-bj.ufileos.com/bd309e8b-1890-428e-8fe0-b21d4b60c9b5.webp?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=30D7IY5Fy2JVu%252BX3JK9RSK0kq%252Bg%253D&Expires=1608371054" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>  在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。</p><p>  伪代码如下：</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String key,Object data)</span></span>&#123;</span><br><span class="line">    redis.delKey(key);</span><br><span class="line">    db.updateData(data);</span><br><span class="line">    Thread.sleep(<span class="number">500</span>);</span><br><span class="line">    redis.delKey(key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  <strong>具体的步骤就是：</strong></p><p>  <em>先删除缓存；再写数据库；休眠500毫秒；再次删除缓存。</em></p><p><strong>那么，这个500毫秒怎么确定的，具体该休眠多久呢？</strong></p><p>  需要评估自己的项目的读数据业务逻辑的耗时。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。</p><p>  当然这种策略还要考虑redis和数据库主从同步的耗时。最后的的写数据的休眠时间：则在读数据业务逻辑的耗时基础上，加几百ms即可。比如：休眠1秒。</p><p>  <strong>设置缓存过期时间</strong></p><p>  从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。</p><p> <strong>该方案的弊端</strong></p><p>  结合双删策略+缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致，而且又增加了写请求的耗时。</p><p>  <strong>2、第二种方案：<em>异步更新缓存</em>(基于订阅binlog的同步机制)</strong></p><p>  <strong>技术整体思路：</strong></p><p>  MySQL binlog增量订阅消费+消息队列+增量数据更新到redis</p><p>  <strong>读Redis</strong>：热数据基本都在Redis</p><p>  <strong>写MySQL</strong>:增删改都是操作MySQL</p><p>  <strong>更新Redis数据</strong>：MySQL的数据操作binlog，来更新到Redis</p><p>  <strong>Redis更新</strong></p><p>  <strong>1）数据操作主要分为两大块：</strong></p><p>  一个是全量(将全部数据一次写入到redis)一个是增量（实时更新）</p><p>  这里说的是增量,指的是mysql的update、insert、delate变更数据。</p><p>  <strong>2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。</strong></p><p>  这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。</p><p>  其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。</p><p>  这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。</p><p>  当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ等来实现推送更新Redis。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis/</url>
      
        <content type="html"><![CDATA[<p><strong>Redis面试题大全含答案</strong></p><p><strong>1.什么是Redis？</strong><br>答：Remote Dictionary Server(Redis)是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。<br>它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。</p><p><strong>2.Redis的特点什么是？</strong><br>\1. 支持多种数据结构，如 string(字符串)、 list(双向链表)、dict(hash表)、set(集合)、zset(排序set)、hyperloglog(基数估算)<br>\2. 支持持久化操作，可以进行aof及rdb数据持久化到磁盘，从而进行数据备份或数据恢复等操作，较好的防止数据丢失的手段。<br>\3. 支持通过Replication进行数据复制，通过master-slave机制，可以实时进行数据的同步复制，支持多级复制和增量复制，master-slave机制是Redis进行HA的重要手段。<br>单进程请求，所有命令串行执行，并发情况下不需要考虑数据一致性问题。</p><p><strong>3.Redis数据类型有哪些？</strong><br>答：String(字符串)<br>Hash(hash表)<br>List(链表)<br>Set(集合)<br>SortedSet(有序集合zset)</p><p><strong>4.Redis中的常用命令哪些？</strong><br>incr 让当前键值以1的数量递增，并返回递增后的值<br>incrby 可以指定参数一次增加的数值，并返回递增后的值<br>incrby 可以指定参数一次增加的数值，并返回递增后的值<br>decrby 可以指定参数一次递减的数值，并返回递减后的值<br>incrbyfloat 可以递增一个双精度浮点数<br>append 作用是向键值的末尾追加value。如果键不存在则将该键的值设置为value。返回值是追加后字符串的总长度。<br>mget/mset 作用与get/set相似，不过mget/mset可以同时获得/设置多个键的键值<br>del 根据key来删除value<br>flushdb 清除当前库的所有数据<br>hset 存储一个哈希键值对的集合<br>hget获取一个哈希键的值<br>hmset 存储一个或多个哈希是键值对的集合<br>hmget 获取多个指定的键的值<br>hexists 判断哈希表中的字段名是否存在 如果存在返回1 否则返回0<br>hdel 删除一个或多个字段<br>hgetall 获取一个哈希是键值对的集合<br>hvals 只返回字段值<br>hkeys 只返回字段名<br>hlen 返回key的hash的元素个数<br>lpush key value向链表左侧添加<br>rpush key value向链表右侧添加<br>lpop key 从左边移出一个元素<br>rpop key 从右边移出一个元素<br>llen key 返回链表中元素的个数 相当于关系型数据库中 select count(<em>)<br>lrange key start end lrange命令将返回索引从start到stop之间的所有元素。Redis的列表起始索引为0。<br>lrange也支持负索引 lrange nn -2 -1 如 -1表示最右边第一个元素 -2表示最右边第二个元素，依次类推。<br>lindex key indexnumber 如果要将列表类型当做数组来用，lindex命令是必不可少的。lindex命令用来返回指定索引的元素，索引从0开始<br>如果是负数表示从右边开始计算的索引，最右边元素的索引是-1。<br>Lset key indexnumber value 是另一个通过索引操作列表的命令，它会将索引为index的元素赋值为value。<br>sadd key value 添加一个string元素到,key对应的set集合中，成功返回1,如果元素已经在集合中返回0<br>scard key 返回set的元素个数，如果set是空或者key不存在返回0<br>smembers key 返回key对应set的所有元素，结果是无序的<br>sismember key value 判断value 是否在set中，存在返回1，0表示不存在或者key不存在<br>srem key value 从key对应set中移除给定元素，成功返回1，如果value 在集合中不存在或者key不存在返回0<br>zadd key score value 将一个或多个value及其socre加入到set中<br>zrange key start end 0和-1表示从索引为0的元素到最后一个元素（同LRANGE命令相似）<br>zrange key 0 -1 withscores 也可以连同score一块输出，使用WITHSCORES参数<br>zremrangebyscore key start end 可用于范围删除操作<br>ping 测试redis是否链接 如果已链接返回 PONG<br>echo value测试redis是否链接 如果已链接返回 echo命令后给定的值<br>keys * 返回所有的key 可以加</em>通配<br>exists key判断string类型一个key是否存在 如果存在返回1 否则返回0<br>expire key time(s) 设置一个key的过期时间 单位秒。时间到达后会删除key及value<br>ttl key 查询已设置过期时间的key的剩余时间 如果返回-2表示该键值对已经被删除<br>persist 移除给定key的过期时间<br>select dbindex 选择数据库(0-15)<br>move key dbIndex 将当前数据库中的key转移到其他数据库中<br>dbsize 返回当前数据库中的key的数目<br>info 获取服务器的信息和统计<br>flushdb 删除当前选择的数据库中的key<br>flushall 删除所有数据库中的所有key<br>quit 退出连接</p><p><strong>5.Redis的配置以及持久化方案有几种？</strong><br>以下两种<br>RDB方式<br>AOF方式</p><p><strong>什么是RDB方式？</strong><br>是RDB是对内存中数据库状态进行快照<br>RDB方式：将Redis在内存中的数据库状态保存到磁盘里面，RDB文件是一个经过压缩的二进制文件，通过该文件可以还原生成RDB文件时的数据库状态（默认下，持久化到dump.rdb文件，并且在redis重启后，自动读取其中文件，据悉，通常情况下一千万的字符串类型键，1GB的快照文件，同步到内存中的 时间是20-30秒）<br>RDB的生成方式：<br>1、执行命令手动生成<br>有两个Redis命令可以用于生成RDB文件，一个是SAVE，另一个是BGSAVE SAVE命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求，BGSAVE命令会派生出一个子进程，然后由子进程负责创建RDB文件，服务器进程（父进程）继续处理命令请求，创建RDB文件结束之前，客户端发送的BGSAVE和SAVE命令会被服务器拒绝</p><p>2、通过配置自动生成<br>可以设置服务器配置的save选项，让服务器每隔一段时间自动执行一次BGSAVE命令，可以通过save选项设置多个保存条件，但只要其中任意一个条件被满足，服务器就会执行BGSAVE命令<br>例如：<br>save 900 1<br>save 300 10<br>save 60 10000<br>那么只要满足以下三个条件中的任意一个，BGSAVE命令就会被执行<br>服务器在900秒之内，对数据库进行了至少1次修改<br>服务器在300秒之内，对数据库进行了至少10次修改<br>服务器在60秒之内，对数据库进行了至少10000次修改</p><p><strong>什么是AOF方式？</strong><br>AOF持久化方式在redis中默认是关闭的，需要修改配置文件开启该方式。<br>AOF：把每条命令都写入文件，类似mysql的binlog日志<br>AOF方式：是通过保存Redis服务器所执行的写命令来记录数据库状态的文件。<br>AOF文件刷新的方式，有三种：<br>appendfsync always - 每提交一个修改命令都调用fsync刷新到AOF文件，非常非常慢，但也非常安全<br>appendfsync everysec - 每秒钟都调用fsync刷新到AOF文件，很快，但可能会丢失一秒以内的数据<br>appendfsync no - 依靠OS进行刷新，redis不主动刷新AOF，这样最快，但安全性就差<br>默认并推荐每秒刷新，这样在速度和安全上都做到了兼顾<br>AOF数据恢复方式<br>服务器在启动时，通过载入和执行AOF文件中保存的命令来还原服务器关闭之前的数据库状态，具体过程：<br>载入AOF文件<br>创建模拟客户端<br>从AOF文件中读取一条命令<br>使用模拟客户端执行命令<br>循环读取并执行命令，直到全部完成<br>如果同时启用了RDB和AOF方式，AOF优先，启动时只加载AOF文件恢复数据</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h3 id="1-Redis是什么"><a href="#1-Redis是什么" class="headerlink" title="1.Redis是什么"></a>1.Redis是什么</h3><p>Redis是C语言开发的一个开源的（遵从BSD协议）高性能键值对（key-value）的内存数据库，可以用做数据库、缓存、消息中间件等</p><p>它是一种NoSQL（not-only sql，泛指非关系型数据库）的数据库。</p><p>Redis作为一个内存数据库：</p><ul><li>性能优秀，数据在内存中，读写速度非常快，支持并发10w QPS</li><li>单进程单线程，是线程安全的，采用IO多路复合机制</li><li>丰富的数据类型，支持字符串（strings）、散列（hashes）、列表（lists）、集合（sets）、有序集合（sorted sets）等</li><li>支持数据持久化，可以将内存中数据保存在磁盘中，重启时加载</li><li>主从复制，哨兵，高可用</li><li>可以用作分布式锁</li><li>可以作为消息中间件使用，支持发布订阅</li></ul><h3 id="Redis为何这么快，还是单线程"><a href="#Redis为何这么快，还是单线程" class="headerlink" title="Redis为何这么快，还是单线程"></a>Redis为何这么快，还是单线程</h3><p>Redis确实是单进程单线程的模型，因为Redis完全是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。</p><p>既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章的采用单线程的方案了，毕竟采用多线程会有很多麻烦。</p><p>为什么单线程这么快：</p><ul><li>Redis是完全基于内存，绝大部分请求是纯粹的内存操作，非常迅速，数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度是O（1）。</li><li>数据结构简单，对数据操作也简单</li><li>采用单线程，避免了不必要的上下文切换和竞争条件，不存在多线程导致的CPU切换，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有死锁问题导致的性能消耗。</li><li>使用多路复用IO模型，非阻塞IO</li></ul><h3 id="Redis和Memcached的区别"><a href="#Redis和Memcached的区别" class="headerlink" title="Redis和Memcached的区别"></a>Redis和Memcached的区别</h3><ul><li>存储方式上：Memcached会把数据全部存储在内存之中，断电之后会挂掉，数据不能超过内存大小。Redis有部分数据存在硬盘上，这样能保证数据的持久性。</li><li>数据支持类型上：Memcached对数据类型的支持简单，只支持简单的key-value，而Redis支持五种数据类型。</li><li>使用底层模型不同：它们之间底层实现方式以及与客户端之间通信的应用协议不一样。Redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。</li><li>Value的大小：Redis可以达到1GB，而Memached只有1MB。</li></ul><h3 id="淘汰策略"><a href="#淘汰策略" class="headerlink" title="淘汰策略"></a>淘汰策略</h3><p>Redis有六种淘汰策略：</p><table><thead><tr><th>策略</th><th>描述</th></tr></thead><tbody><tr><td>volatile-lru</td><td>从已设置过期时间的KV集合中有限对最近最好使用（less recently used）的数据淘汰</td></tr><tr><td>volatile-ttl</td><td>从已设置过期时间的KV集合中优先对剩余时间短（time to live）的数据淘汰</td></tr><tr><td>volatile-random</td><td>从已设置过期时间的KV集合中随机选择数据淘汰</td></tr><tr><td>allkeys-lru</td><td>从所有KV集合中优先对最近最少使用（less recently used）的数据淘汰</td></tr><tr><td>allkeys-random</td><td>从所有KV集合中随机选择数据淘汰</td></tr><tr><td>noeviction</td><td>不淘汰策略，若超过最大内存，返回错误信息</td></tr></tbody></table><blockquote><p>Redis 4.0加入了LFU（least frequently use）淘汰策略，包括volatile-lfu和allkeys-lfu，通过统计访问频率，将访问频率最少，即最不经常使用的KV淘汰</p></blockquote><h3 id="持久化机制"><a href="#持久化机制" class="headerlink" title="持久化机制"></a>持久化机制</h3><p>Redis为了保证效率，数据缓存在内存中，但是会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件中，以保证数据的持久化。</p><p>Redis的持久化策略有两种：</p><ul><li>RDB：快照形式是直接把内存中的数据保存到一个dump的文件中，定时保存策略</li><li>AOF：把所有的对Redis的服务器进行修改的命令都存到一个文件里，命令集合。</li></ul><p>Redis默认是快照RDB的持久化方式。</p><p>当Redis重启的时候，它会优先使用AOF文件来还原数据集，因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整，你甚至可以关闭持久化功能，让数据只在服务器运行时存。</p><h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-%E9%9B%86%E7%BE%A4%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E6%90%AD%E5%BB%BA/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-%E9%9B%86%E7%BE%A4%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<p><strong>前言</strong></p><p>Redis 是我们目前大规模使用的缓存中间件，由于它强大高效而又便捷的功能，得到了广泛的使用。单节点的Redis已经就达到了很高的性能，为了提高可用性我们可以使用Redis集群。本文参考了Rdis的官方文档和使用Redis官方提供的Redis Cluster工具搭建Rdis集群。</p><p><em>注意 ：Redis的版本要在3.0以上,截止今天，Redis的版本是3.2.9，本教程也使用3.2.9作为教程</em> </p><p><strong>Redis集群的概念</strong></p><p><strong>介绍</strong></p><p>Redis 集群是一个可以在多个 Redis 节点之间进行数据共享的设施（installation）。</p><p>Redis 集群不支持那些需要同时处理多个键的 Redis 命令， 因为执行这些命令需要在多个 Redis 节点之间移动数据， 并且在高负载的情况下， 这些命令将降低 Redis 集群的性能， 并导致不可预测的错误。</p><p>Redis 集群通过分区（partition）来提供一定程度的可用性（availability）： 即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求。</p><p><strong>Redis 集群提供了以下两个好处：</strong></p><ol><li>将数据自动切分（split）到多个节点的能力。</li><li>当集群中的一部分节点失效或者无法进行通讯时， 仍然可以继续处理命令请求的能力。</li></ol><p><strong>数据分片</strong></p><p>Redis 集群使用数据分片（sharding）而非一致性哈希（consistency hashing）来实现： 一个 Redis 集群包含 16384 个哈希槽（hash slot）， 数据库中的每个键都属于这 16384 个哈希槽的其中一个， 集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和 。</p><p>集群中的每个节点负责处理一部分哈希槽。 举个例子， 一个集群可以有三个哈希槽， 其中：</p><ul><li>节点 A 负责处理 0 号至 5500 号哈希槽。</li><li>节点 B 负责处理 5501 号至 11000 号哈希槽。</li><li>节点 C 负责处理 11001 号至 16384 号哈希槽。</li></ul><p>这种将哈希槽分布到不同节点的做法使得用户可以很容易地向集群中添加或者删除节点。 比如说： </p><p>我现在想设置一个key，叫my_name:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set my_name zhangguoji</span><br></pre></td></tr></table></figure><p>按照Redis Cluster的哈希槽算法，CRC16(‘my_name’)%16384 = 2412 那么这个key就被分配到了节点A上 。</p><p>同样的，当我连接(A,B,C)的任意一个节点想获取my_name这个key,都会转到节点A上 ，再比如 ，如果用户将新节点 D 添加到集群中， 那么集群只需要将节点 A 、B 、 C 中的某些槽移动到节点 D 就可以了。 </p><p>增加一个D节点的结果可能如下： </p><ul><li>节点A覆盖1365-5460 </li><li>节点B覆盖6827-10922 </li><li>节点C覆盖12288-16383 </li><li>节点D覆盖0-1364,5461-6826,10923-1228</li></ul><p>与此类似， 如果用户要从集群中移除节点 A ， 那么集群只需要将节点 A 中的所有哈希槽移动到节点 B 和节点 C ， 然后再移除空白（不包含任何哈希槽）的节点 A 就可以了。 </p><p>因为将一个哈希槽从一个节点移动到另一个节点不会造成节点阻塞， 所以无论是添加新节点还是移除已存在节点， 又或者改变某个节点包含的哈希槽数量， 都不会造成集群下线。 </p><p>所以,Redis Cluster的模型大概是这样的形状 </p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/JfTPiahTHJhody17bouCGDons86NN123ia1JNJsYnecoOZMJwN9NVarGt4hsmHibk5NoqrCXdIysoTAtrJEgzRU4g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" class="lazyload" data-srcset="https://mmbiz.qpic.cn/mmbiz_jpg/JfTPiahTHJhody17bouCGDons86NN123ia1JNJsYnecoOZMJwN9NVarGt4hsmHibk5NoqrCXdIysoTAtrJEgzRU4g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><p><strong>主从复制模型</strong></p><p>为了使得集群在一部分节点下线或者无法与集群的大多数（majority）节点进行通讯的情况下， 仍然可以正常运作， Redis 集群对节点使用了主从复制功能： 集群中的每个节点都有 1 个至 N 个复制品（replica）， 其中一个复制品为主节点（master）， 而其余的 N-1 个复制品为从节点（slave）。</p><p>在之前列举的节点 A 、B 、C 的例子中， 如果节点 B 下线了， 那么集群将无法正常运行， 因为集群找不到节点来处理 5501 号至 11000号的哈希槽。</p><p>另一方面， 假如在创建集群的时候（或者至少在节点 B 下线之前）， 我们为主节点 B 添加了从节点 B1 ， 那么当主节点 B 下线的时候， 集群就会将 B1 设置为新的主节点， 并让它代替下线的主节点 B ， 继续处理 5501 号至 11000 号的哈希槽， 这样集群就不会因为主节点 B 的下线而无法正常运作了。</p><p>不过如果节点 B 和 B1 都下线的话， Redis 集群还是会停止运作。</p><p><strong>Redis一致性保证</strong></p><p>Redis 并不能保证数据的强一致性. 这意味这在实际中集群在特定的条件下可能会丢失写操作： </p><p>第一个原因是因为集群是用了异步复制. 写操作过程: </p><ol><li>客户端向主节点B写入一条命令. </li><li>主节点B向客户端回复命令状态. </li><li>主节点将写操作复制给他得从节点 B1, B2 和 B3</li></ol><p>主节点对命令的复制工作发生在返回命令回复之后， 因为如果每次处理命令请求都需要等待复制操作完成的话， 那么主节点处理命令请求的速度将极大地降低 —— 我们必须在性能和一致性之间做出权衡。 </p><p>*<br>*</p><p><em>注意：Redis 集群可能会在将来提供同步写的方法。 Redis 集群另外一种可能会丢失命令的情况是集群出现了网络分区， 并且一个客户端与至少包括一个主节点在内的少数实例被孤立。</em> </p><p>举个例子 假设集群包含 A 、 B 、 C 、 A1 、 B1 、 C1 六个节点， 其中 A 、B 、C 为主节点， A1 、B1 、C1 为A，B，C的从节点， 还有一个客户端 Z1 假设集群中发生网络分区，那么集群可能会分为两方，大部分的一方包含节点 A 、C 、A1 、B1 和 C1 ，小部分的一方则包含节点 B 和客户端 Z1 . </p><p>Z1仍然能够向主节点B中写入, 如果网络分区发生时间较短,那么集群将会继续正常运作,如果分区的时间足够让大部分的一方将B1选举为新的master，那么Z1写入B中得数据便丢失了. </p><p><em>注意， 在网络分裂出现期间， 客户端 Z1 可以向主节点 B 发送写命令的最大时间是有限制的， 这一时间限制称为节点超时时间（node timeout）， 是 Redis 集群的一个重要的配置选项</em></p><p><strong>搭建Redis集群</strong></p><p>要让集群正常工作至少需要3个主节点，在这里我们要创建6个redis节点，其中三个为主节点，三个为从节点，对应的redis节点的ip和端口对应关系如下（为了简单演示都在同一台机器上面）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:7000</span><br><span class="line">127.0.0.1:7001</span><br><span class="line">127.0.0.1:7002</span><br><span class="line">127.0.0.1:7003</span><br><span class="line">127.0.0.1:7004</span><br><span class="line">127.0.0.1:7005</span><br></pre></td></tr></table></figure><p><strong>安装和启动Redis</strong></p><p>下载安装包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.redis.io/releases/redis-3.2.9.tar.gz</span><br></pre></td></tr></table></figure><p>解压安装</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf redis-3.2.9.tar.gz</span><br><span class="line">cd redis-3.2.9</span><br><span class="line">make &amp;&amp; make PREFIX=/usr/local/redis install</span><br></pre></td></tr></table></figure><p>这里如果失败的自行yum安装gcc和tcl </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install gcc </span><br><span class="line">yum install tcl</span><br></pre></td></tr></table></figure><p>创建目录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/redis</span><br><span class="line">mkdir cluster</span><br><span class="line">cd cluster</span><br><span class="line">mkdir 7000 7001 7002 7003 7004 7005</span><br></pre></td></tr></table></figure><p>复制和修改配置文件</p><p>将redis目录下的配置文件复制到对应端口文件夹下,6个文件夹都要复制一份</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp redis-3.2.9/redis.conf /usr/local/redis/cluster/7000</span><br></pre></td></tr></table></figure><p>修改配置文件redis.conf，将下面的选项修改</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 端口号</span><br><span class="line">port 7000</span><br><span class="line"># 后台启动</span><br><span class="line">daemonize yes</span><br><span class="line"># 开启集群</span><br><span class="line">cluster-enabled yes</span><br><span class="line">#集群节点配置文件</span><br><span class="line">cluster-config-file nodes-7000.conf</span><br><span class="line"># 集群连接超时时间</span><br><span class="line">cluster-node-timeout 5000</span><br><span class="line"># 进程pid的文件位置</span><br><span class="line">pidfile /var/run/redis-7000.pid</span><br><span class="line"># 开启aof</span><br><span class="line">appendonly yes</span><br><span class="line"># aof文件路径</span><br><span class="line">appendfilename &quot;appendonly-7005.aof&quot;</span><br><span class="line"># rdb文件路径</span><br><span class="line">dbfilename dump-7000.rdb</span><br></pre></td></tr></table></figure><p>6个配置文件安装对应的端口分别修改配置文件</p><p>创建启动脚本</p><p>在/usr/local/redis目录下创建一个start.sh</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">bin/redis-server cluster/7000/redis.conf</span><br><span class="line">bin/redis-server cluster/7001/redis.conf</span><br><span class="line">bin/redis-server cluster/7002/redis.conf</span><br><span class="line">bin/redis-server cluster/7003/redis.conf</span><br><span class="line">bin/redis-server cluster/7004/redis.conf</span><br><span class="line">bin/redis-server cluster/7005/redis.conf</span><br></pre></td></tr></table></figure><p>这个时候我们查看一下进程看启动情况</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep redis</span><br></pre></td></tr></table></figure><p>进程状态如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root      1731     1  1 18:21 ?        00:00:49 bin/redis-server *:7000 [cluster]       </span><br><span class="line">root      1733     1  0 18:21 ?        00:00:29 bin/redis-server *:7001 [cluster]       </span><br><span class="line">root      1735     1  0 18:21 ?        00:00:08 bin/redis-server *:7002 [cluster]       </span><br><span class="line">root      1743     1  0 18:21 ?        00:00:26 bin/redis-server *:7003 [cluster]       </span><br><span class="line">root      1745     1  0 18:21 ?        00:00:13 bin/redis-server *:7004 [cluster]       </span><br><span class="line">root      1749     1  0 18:21 ?        00:00:08 bin/redis-server *:7005 [cluster]</span><br></pre></td></tr></table></figure><p>有6个redis进程在开启，说明我们的redis就启动成功了</p><p>开启集群</p><p>这里我们只是开启了6个redis进程而已，它们都还只是独立的状态，还么有组成集群 </p><p>这里我们使用官方提供的工具redis-trib，不过这个工具是用ruby写的，要先安装ruby的环境</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install ruby rubygems -y</span><br></pre></td></tr></table></figure><p>执行，报错</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@centos]# redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005</span><br><span class="line">/usr/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require&#x27;: no such file to load -- redis (LoadError)</span><br><span class="line">   from /usr/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `require&#x27;</span><br><span class="line">   from /usr/local/bin/redis-trib.rb:25</span><br><span class="line">[root@centos]#</span><br></pre></td></tr></table></figure><p>原来是ruby和redis的连接没安装好 </p><p>安装gem-redis</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem install redis</span><br></pre></td></tr></table></figure><p>安装到这里的时候突然卡住很久不动，网上搜了下，这里需要翻墙或者换镜像</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem source -a https://gems.ruby-china.org</span><br></pre></td></tr></table></figure><p>这里可以将镜像换成ruby-china的镜像，不过我好像更换失败，最终还是翻墙下载了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@centos]# gem install redis</span><br><span class="line">Successfully installed redis-3.2.1</span><br><span class="line">1 gem installed</span><br><span class="line">Installing ri documentation for redis-3.2.1...</span><br><span class="line">Installing RDoc documentation for redis-3.2.1...</span><br></pre></td></tr></table></figure><p>等下载好后我们就可以使用了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@centos]# gem install redis</span><br><span class="line">Successfully installed redis-3.2.1</span><br><span class="line">1 gem installed</span><br><span class="line">Installing ri documentation for redis-3.2.1...</span><br><span class="line">Installing RDoc documentation for redis-3.2.1...</span><br></pre></td></tr></table></figure><p>将redis-3.2.9的src目录下的trib复制到相应文件夹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp redis-3.2.9/src/redis-trib.rb /usr/local/redis/bin/redis-trib</span><br></pre></td></tr></table></figure><p>创建集群：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-trib create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005</span><br></pre></td></tr></table></figure><p><strong>命令的意义如下：</strong> </p><ul><li>给定 redis-trib.rb 程序的命令是 create ， 这表示我们希望创建一个新的集群。 </li><li>选项 –replicas 1 表示我们希望为集群中的每个主节点创建一个从节点。 </li></ul><p>之后跟着的其他参数则是实例的地址列表， 我们希望程序使用这些地址所指示的实例来创建新集群。 </p><p>简单来说，以上的命令的意思就是让redis-trib程序帮我们创建三个主节点和三个从节点的集群，</p><p>接着， redis-trib 会打印出一份预想中的配置给你看， 如果你觉得没问题的话， 就可以输入 yes ， redis-trib 就会将这份配置应用到集群当中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; Creating cluster</span><br><span class="line">&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...</span><br><span class="line">Using 3 masters:</span><br><span class="line">127.0.0.1:7000</span><br><span class="line">127.0.0.1:7001</span><br><span class="line">127.0.0.1:7002</span><br><span class="line">Adding replica 127.0.0.1:7003 to 127.0.0.1:7000</span><br><span class="line">Adding replica 127.0.0.1:7004 to 127.0.0.1:7001</span><br><span class="line">Adding replica 127.0.0.1:7005 to 127.0.0.1:7002</span><br><span class="line">M: bdcddddd3d78a866b44b68c7ae0e5ccf875c446a 127.0.0.1:7000</span><br><span class="line">  slots:0-5460 (5461 slots) master</span><br><span class="line">M: b85519795fa42aa33d4e88d25104cbae895933a6 127.0.0.1:7001</span><br><span class="line">  slots:5461-10922 (5462 slots) master</span><br><span class="line">M: b681e1a151890cbf957d1ff08352ee48f6ae39e6 127.0.0.1:7002</span><br><span class="line">  slots:10923-16383 (5461 slots) master</span><br><span class="line">S: d403713ab9db48aeac5b5393b69e1201026ef479 127.0.0.1:7003</span><br><span class="line">  replicates bdcddddd3d78a866b44b68c7ae0e5ccf875c446a</span><br><span class="line">S: b7ec92919e5bcffa76c8eee338f8ca5155293c64 127.0.0.1:7004</span><br><span class="line">  replicates b85519795fa42aa33d4e88d25104cbae895933a6</span><br><span class="line">S: 8a0d2a3f271b349744a971e1b0a545405de2742e 127.0.0.1:7005</span><br><span class="line">  replicates b681e1a151890cbf957d1ff08352ee48f6ae39e6</span><br><span class="line">Can I set the above configuration? (type &#x27;yes&#x27; to accept):</span><br></pre></td></tr></table></figure><p>按下yes，集群就会将配置应用到各个节点，并连接起（join)各个节点，也即是，让各个节点开始通讯</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; Nodes configuration updated</span><br><span class="line">&gt;&gt;&gt; Assign a different config epoch to each node</span><br><span class="line">&gt;&gt;&gt; Sending CLUSTER MEET messages to join the cluster</span><br><span class="line">Waiting for the cluster to join...</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)</span><br><span class="line">M: bdcddddd3d78a866b44b68c7ae0e5ccf875c446a 127.0.0.1:7000</span><br><span class="line">  slots:0-5460 (5461 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: d403713ab9db48aeac5b5393b69e1201026ef479 127.0.0.1:7003</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates bdcddddd3d78a866b44b68c7ae0e5ccf875c446a</span><br><span class="line">S: 8a0d2a3f271b349744a971e1b0a545405de2742e 127.0.0.1:7005</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b681e1a151890cbf957d1ff08352ee48f6ae39e6</span><br><span class="line">M: b85519795fa42aa33d4e88d25104cbae895933a6 127.0.0.1:7001</span><br><span class="line">  slots:5461-10922 (5462 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: b7ec92919e5bcffa76c8eee338f8ca5155293c64 127.0.0.1:7004</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b85519795fa42aa33d4e88d25104cbae895933a6</span><br><span class="line">M: b681e1a151890cbf957d1ff08352ee48f6ae39e6 127.0.0.1:7002</span><br><span class="line">  slots:10923-16383 (5461 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><p><strong>Redis集群的使用</strong></p><p><strong>连接集群</strong></p><p>这里我们使用reids-cli连接集群，使用时加上-c参数，就可以连接到集群 </p><p>连接7000端口的节点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1 redis]# ./redis-cli -c -p 7000</span><br><span class="line">127.0.0.1:7000&gt; set name zgj</span><br><span class="line">-&gt; Redirected to slot [5798] located at 127.0.0.1:7001</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7001&gt; get name</span><br><span class="line">&quot;zgj&quot;</span><br></pre></td></tr></table></figure><p>前面的理论知识我们知道了，分配key的时候，它会使用CRC16算法，这里将keyname分配到了7001节点上</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Redirected to slot [5798] located at 127.0.0.1:7001</span><br></pre></td></tr></table></figure><p>redis cluster 采用的方式很直接，它直接跳转到7001 节点了，而不是还在自身的7000节点。</p><p>好，现在我们连接7003这个从节点进入</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1 redis]# ./redis-cli -c -p 7003</span><br><span class="line">127.0.0.1:7003&gt; get name</span><br><span class="line">-&gt; Redirected to slot [5798] located at 127.0.0.1:7001</span><br><span class="line">&quot;zgj&quot;</span><br></pre></td></tr></table></figure><p>这里获取name的值，也同样跳转到了7001上 </p><p>我们再测试一下其他数据</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:7001&gt; set age 20</span><br><span class="line">-&gt; Redirected to slot [741] located at 127.0.0.1:7000</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7000&gt; set message helloworld</span><br><span class="line">-&gt; Redirected to slot [11537] located at 127.0.0.1:7002</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7002&gt; set height 175</span><br><span class="line">-&gt; Redirected to slot [8223] located at 127.0.0.1:7001</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>我们发现数据会在7000-7002这3个节点之间来回跳转</p><p><strong>测试集群中的节点挂掉</strong></p><p>上面我们建立了一个集群，3个主节点和3个从节点，7000-7002负责存取数据，7003-7005负责把7000-7005的数据同步到自己的节点上来。 </p><p>我们现在来模拟一下一台matser服务器宕机的情况</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1 redis]# ps -ef | grep redis</span><br><span class="line">root      1731     1  0 18:21 ?        00:01:02 bin/redis-server *:7000 [cluster]       </span><br><span class="line">root      1733     1  0 18:21 ?        00:00:43 bin/redis-server *:7001 [cluster]       </span><br><span class="line">root      1735     1  0 18:21 ?        00:00:22 bin/redis-server *:7002 [cluster]       </span><br><span class="line">root      1743     1  0 18:21 ?        00:00:40 bin/redis-server *:7003 [cluster]       </span><br><span class="line">root      1745     1  0 18:21 ?        00:00:27 bin/redis-server *:7004 [cluster]       </span><br><span class="line">root      1749     1  0 18:21 ?        00:00:22 bin/redis-server *:7005 [cluster]       </span><br><span class="line">root     23988     1  0 18:30 ?        00:00:42 ./redis-server *:6379    </span><br><span class="line">root     24491  1635  0 21:55 pts/1    00:00:00 grep redis</span><br><span class="line">[root@centos1 redis]# kill 1731</span><br><span class="line">[root@centos1 redis]# bin/redis-trib check 127.0.0.1:7001</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7001)</span><br><span class="line">M: b85519795fa42aa33d4e88d25104cbae895933a6 127.0.0.1:7001</span><br><span class="line">  slots:5461-10922 (5462 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">M: b681e1a151890cbf957d1ff08352ee48f6ae39e6 127.0.0.1:7002</span><br><span class="line">  slots:10923-16383 (5461 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: b7ec92919e5bcffa76c8eee338f8ca5155293c64 127.0.0.1:7004</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b85519795fa42aa33d4e88d25104cbae895933a6</span><br><span class="line">S: 8a0d2a3f271b349744a971e1b0a545405de2742e 127.0.0.1:7005</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b681e1a151890cbf957d1ff08352ee48f6ae39e6</span><br><span class="line">M: d403713ab9db48aeac5b5393b69e1201026ef479 127.0.0.1:7003</span><br><span class="line">  slots:0-5460 (5461 slots) master</span><br><span class="line">  0 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><p>这里看得出来，现在已经有了3个节点了，7003被选取成了替代7000成为主节点了。 </p><p>我们再来模拟 7000节点重新启动了的情况，那么它还会自动加入到集群中吗？那么，7000这个节点上充当什么角色呢？ 我们试一下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1 redis]# bin/redis-server cluster/7000/redis.conf</span><br><span class="line">[root@centos1 redis]# bin/redis-trib check 127.0.0.1:7000</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)</span><br><span class="line">S: bdcddddd3d78a866b44b68c7ae0e5ccf875c446a 127.0.0.1:7000</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates d403713ab9db48aeac5b5393b69e1201026ef479</span><br><span class="line">S: b7ec92919e5bcffa76c8eee338f8ca5155293c64 127.0.0.1:7004</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b85519795fa42aa33d4e88d25104cbae895933a6</span><br><span class="line">S: 8a0d2a3f271b349744a971e1b0a545405de2742e 127.0.0.1:7005</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b681e1a151890cbf957d1ff08352ee48f6ae39e6</span><br><span class="line">M: b681e1a151890cbf957d1ff08352ee48f6ae39e6 127.0.0.1:7002</span><br><span class="line">  slots:10923-16383 (5461 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">M: b85519795fa42aa33d4e88d25104cbae895933a6 127.0.0.1:7001</span><br><span class="line">  slots:5461-10922 (5462 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">M: d403713ab9db48aeac5b5393b69e1201026ef479 127.0.0.1:7003</span><br><span class="line">  slots:0-5460 (5461 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><p>这里我们可以看到7000节点变成了7003节点的从节点 </p><p>我们试着将7000和7003两个节点都关掉</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1 redis]# ps -ef | grep redis</span><br><span class="line">root      1733     1  0 18:21 ?        00:00:45 bin/redis-server *:7001 [cluster]       </span><br><span class="line">root      1735     1  0 18:21 ?        00:00:24 bin/redis-server *:7002 [cluster]       </span><br><span class="line">root      1743     1  0 18:21 ?        00:00:42 bin/redis-server *:7003 [cluster]       </span><br><span class="line">root      1745     1  0 18:21 ?        00:00:29 bin/redis-server *:7004 [cluster]       </span><br><span class="line">root      1749     1  0 18:21 ?        00:00:24 bin/redis-server *:7005 [cluster]       </span><br><span class="line">root     23988     1  0 18:30 ?        00:00:43 ./redis-server *:6379    </span><br><span class="line">root     24527     1  0 22:04 ?        00:00:00 bin/redis-server *:7000 [cluster]       </span><br><span class="line">root     24541  1635  0 22:07 pts/1    00:00:00 grep redis</span><br><span class="line">[root@centos1 redis] kill 1743</span><br><span class="line">[root@centos1 redis] kill 24527</span><br><span class="line"></span><br><span class="line">[root@centos1 redis]# bin/redis-trib check 127.0.0.1:7001</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7001)</span><br><span class="line">M: b85519795fa42aa33d4e88d25104cbae895933a6 127.0.0.1:7001</span><br><span class="line">  slots:5461-10922 (5462 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">M: b681e1a151890cbf957d1ff08352ee48f6ae39e6 127.0.0.1:7002</span><br><span class="line">  slots:10923-16383 (5461 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: b7ec92919e5bcffa76c8eee338f8ca5155293c64 127.0.0.1:7004</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b85519795fa42aa33d4e88d25104cbae895933a6</span><br><span class="line">S: 8a0d2a3f271b349744a971e1b0a545405de2742e 127.0.0.1:7005</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b681e1a151890cbf957d1ff08352ee48f6ae39e6</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[ERR] Not all 16384 slots are covered by nodes.</span><br></pre></td></tr></table></figure><p>这里我们的集群就不能工作了，因为两个节点主节点和从节点都挂掉了，原来7001分配的slot现在无节点接管，需要人工介入重新分配slots。</p><p><strong>集群中加入新的主节点</strong></p><p>这里在cluster目录下再新建一个7006并修改对应的配置文件，然后启动这个这个redis进程 </p><p>然后再使用redis-trib的add node指令加入节点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/redis-trib add-node 127.0.0.1:7006 127.0.0.1:7000</span><br></pre></td></tr></table></figure><p>这里前面的节点表示要加入的节点，第二个节点表示要加入的集群中的任意一个节点，用来标识这个集群</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1 redis]# bin/redis-trib add-node 127.0.0.1:7006 127.0.0.1:7000</span><br><span class="line">&gt;&gt;&gt; Adding node 127.0.0.1:7006 to cluster 127.0.0.1:7000</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)</span><br><span class="line">M: bdcddddd3d78a866b44b68c7ae0e5ccf875c446a 127.0.0.1:7000</span><br><span class="line">  slots:0-5460 (5461 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: d403713ab9db48aeac5b5393b69e1201026ef479 127.0.0.1:7003</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates bdcddddd3d78a866b44b68c7ae0e5ccf875c446a</span><br><span class="line">S: b7ec92919e5bcffa76c8eee338f8ca5155293c64 127.0.0.1:7004</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b85519795fa42aa33d4e88d25104cbae895933a6</span><br><span class="line">M: b85519795fa42aa33d4e88d25104cbae895933a6 127.0.0.1:7001</span><br><span class="line">  slots:5461-10922 (5462 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: 8a0d2a3f271b349744a971e1b0a545405de2742e 127.0.0.1:7005</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b681e1a151890cbf957d1ff08352ee48f6ae39e6</span><br><span class="line">M: b681e1a151890cbf957d1ff08352ee48f6ae39e6 127.0.0.1:7002</span><br><span class="line">  slots:10923-16383 (5461 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">&gt;&gt;&gt; Send CLUSTER MEET to node 127.0.0.1:7006 to make it join the cluster.</span><br><span class="line">[OK] New node added correctly.</span><br><span class="line">[root@centos1 redis]# bin/redis-trib check 127.0.0.1:7006</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)</span><br><span class="line">M: bdcddddd3d78a866b44b68c7ae0e5ccf875c446a 127.0.0.1:7000</span><br><span class="line">  slots:0-5460 (5461 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: d403713ab9db48aeac5b5393b69e1201026ef479 127.0.0.1:7003</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates bdcddddd3d78a866b44b68c7ae0e5ccf875c446a</span><br><span class="line">S: b7ec92919e5bcffa76c8eee338f8ca5155293c64 127.0.0.1:7004</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b85519795fa42aa33d4e88d25104cbae895933a6</span><br><span class="line">M: e55599320dabfb31bd22a01407e66121f075e7d3 127.0.0.1:7006</span><br><span class="line">  slots: (0 slots) master</span><br><span class="line">  0 additional replica(s)</span><br><span class="line">M: b85519795fa42aa33d4e88d25104cbae895933a6 127.0.0.1:7001</span><br><span class="line">  slots:5461-10922 (5462 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: 8a0d2a3f271b349744a971e1b0a545405de2742e 127.0.0.1:7005</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b681e1a151890cbf957d1ff08352ee48f6ae39e6</span><br><span class="line">M: b681e1a151890cbf957d1ff08352ee48f6ae39e6 127.0.0.1:7002</span><br><span class="line">  slots:10923-16383 (5461 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><p>这里我们可以看到7006节点已经变成了一个主节点，然鹅，等等，好像发现了有什么地方不对</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">M: e55599320dabfb31bd22a01407e66121f075e7d3 127.0.0.1:7006</span><br><span class="line">  slots: (0 slots) master</span><br></pre></td></tr></table></figure><p>里面0 slots,也就是说节点6没有分配哈希槽，即不能进行数据的存取，拿我加上去干嘛。</p><p>原来redis cluster 不是在新加节点的时候帮我们做好了迁移工作，需要我们手动对集群进行重新分片迁移，也是这个命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/redis-trib reshard 127.0.0.1:7000</span><br></pre></td></tr></table></figure><p>这个命令是用来迁移slot节点的，后面的127.0.0.1:7000是表示哪个集群的，7000-7006都是可以的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1]# redis-trib.rb reshard 127.0.0.1:7000</span><br><span class="line">Connecting to node 127.0.0.1:7006: OK</span><br><span class="line">Connecting to node 127.0.0.1:7001: OK</span><br><span class="line">Connecting to node 127.0.0.1:7004: OK</span><br><span class="line">Connecting to node 127.0.0.1:7000: OK</span><br><span class="line">Connecting to node 127.0.0.1:7002: OK</span><br><span class="line">Connecting to node 127.0.0.1:7005: OK</span><br><span class="line">Connecting to node 127.0.0.1:7003: OK</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7006)</span><br><span class="line">M: efc3131fbdc6cf929720e0e0f7136cae85657481 127.0.0.1:7006</span><br><span class="line">  slots: (0 slots) master</span><br><span class="line">  0 additional replica(s)</span><br><span class="line">M: cb5c04b6160c3b7e18cad5d49d8e2987b27e0d6c 127.0.0.1:7001</span><br><span class="line">  slots:5461-10922 (5462 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: 4b4aef8b48c427a3c903518339d53b6447c58b93 127.0.0.1:7004</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates cb5c04b6160c3b7e18cad5d49d8e2987b27e0d6c</span><br><span class="line">S: 3707debcbe7be66d4a1968eaf3a5ffaf4308efa4 127.0.0.1:7000</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates d2237fdcfbba672de766b913d1186cebcb6e1761</span><br><span class="line">M: dfa0754c7854a874a6ebd2613b86140ad97701fc 127.0.0.1:7002</span><br><span class="line">  slots:10923-16383 (5461 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: 30858dbf483b61b9838d5c1f853a60beaa4e7afd 127.0.0.1:7005</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates dfa0754c7854a874a6ebd2613b86140ad97701fc</span><br><span class="line">M: d2237fdcfbba672de766b913d1186cebcb6e1761 127.0.0.1:7003</span><br><span class="line">  slots:0-5460 (5461 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">How many slots do you want to move (from 1 to 16384)?</span><br></pre></td></tr></table></figure><p>它提示我们需要迁移多少slot到7006上，我们可以算一下：16384/4 = 4096，也就是说，为了平衡分配起见，我们需要移动4096个槽点到7006上。</p><p>好，那输入4096: </p><p>它又提示我们，接受的node ID是多少，7006的id 我们通过上面就可以看到是efc3131fbdc6cf929720e0e0f7136cae85657481:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">What is the receiving node ID? efc3131fbdc6cf929720e0e0f7136cae85657481</span><br><span class="line">Please enter all the source node IDs.</span><br><span class="line"> Type &#x27;all&#x27; to use all the nodes as source nodes for the hash slots.</span><br><span class="line"> Type &#x27;done&#x27; once you entered all the source nodes IDs.</span><br><span class="line">Source node #1:</span><br></pre></td></tr></table></figure><p>接着， redis-trib 会向你询问重新分片的源节点（source node）， 也即是， 要从哪个节点中取出 4096 个哈希槽， 并将这些槽移动到7006节点上面。</p><p>如果我们不打算从特定的节点上取出指定数量的哈希槽， 那么可以向 redis-trib 输入 all ， 这样的话， 集群中的所有主节点都会成为源节点， redis-trib 将从各个源节点中各取出一部分哈希槽， 凑够 4096 个， 然后移动到7006节点上：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Source node #1:all</span><br></pre></td></tr></table></figure><p>接下来就开始迁移了，并且会询问你是否确认：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Moving slot 1359 from d2237fdcfbba672de766b913d1186cebcb6e1761</span><br><span class="line">   Moving slot 1360 from d2237fdcfbba672de766b913d1186cebcb6e1761</span><br><span class="line">   Moving slot 1361 from d2237fdcfbba672de766b913d1186cebcb6e1761</span><br><span class="line">   Moving slot 1362 from d2237fdcfbba672de766b913d1186cebcb6e1761</span><br><span class="line">   Moving slot 1363 from d2237fdcfbba672de766b913d1186cebcb6e1761</span><br><span class="line">   Moving slot 1364 from d2237fdcfbba672de766b913d1186cebcb6e1761</span><br><span class="line">Do you want to proceed with the proposed reshard plan (yes/no)?</span><br></pre></td></tr></table></figure><p>输入yes并回车后，redis-trib就会正式执行重新分片操作，将制定的哈希槽从源节点一个个移动到7006节点上 。</p><p>迁移结束之后，我们来检查一下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">M: bdcddddd3d78a866b44b68c7ae0e5ccf875c446a 127.0.0.1:7000</span><br><span class="line">  slots:1365-5460 (4096 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: d403713ab9db48aeac5b5393b69e1201026ef479 127.0.0.1:7003</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates bdcddddd3d78a866b44b68c7ae0e5ccf875c446a</span><br><span class="line">S: b7ec92919e5bcffa76c8eee338f8ca5155293c64 127.0.0.1:7004</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b85519795fa42aa33d4e88d25104cbae895933a6</span><br><span class="line">M: e55599320dabfb31bd22a01407e66121f075e7d3 127.0.0.1:7006</span><br><span class="line">  slots:0-1364,5461-6826,10923-12287 (4096 slots) master</span><br><span class="line">  0 additional replica(s)</span><br><span class="line">M: b85519795fa42aa33d4e88d25104cbae895933a6 127.0.0.1:7001</span><br><span class="line">  slots:6827-10922 (4096 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: 8a0d2a3f271b349744a971e1b0a545405de2742e 127.0.0.1:7005</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates b681e1a151890cbf957d1ff08352ee48f6ae39e6</span><br><span class="line">M: b681e1a151890cbf957d1ff08352ee48f6ae39e6 127.0.0.1:7002</span><br><span class="line">  slots:12288-16383 (4096 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><p>我们可以看到 </p><p>slots:0-1364,5461-6826,10923-12287 (4096 slots) </p><p>这些原来在其他节点上的哈希槽都迁移到了7006上</p><p><strong>增加一个从节点</strong></p><p>新建一个 7007从节点，作为7006的从节点</p><p>我们再新建一个节点7007，步骤类似，就先省略了。建好后，启动起来，我们看如何把它加入到集群中的从节点中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1]# redis-trib.rb add-node --slave 127.0.0.1:7007 127.0.0.1:7000</span><br></pre></td></tr></table></figure><p>add-node的时候加上–slave表示是加入到从节点中，但是这样加，是随机的。这里的命令行完全像我们在添加一个新主服务器时使用的一样，所以我们没有指定要给哪个主服 务器添加副本。这种情况下，redis-trib会将7007作为一个具有较少副本的随机的主服务器的副本。</p><p>那么，你猜，它会作为谁的从节点，应该是7006，因为7006还没有从节点。我们运行下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@web3 7007]# redis-trib.rb add-node --slave 127.0.0.1:7007 127.0.0.1:7000</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">Automatically selected master 127.0.0.1:7006</span><br><span class="line">Connecting to node 127.0.0.1:7007: OK</span><br><span class="line">&gt;&gt;&gt; Send CLUSTER MEET to node 127.0.0.1:7007 to make it join the cluster.</span><br><span class="line">Waiting for the cluster to join.</span><br><span class="line">&gt;&gt;&gt; Configure node as replica of 127.0.0.1:7006.</span><br><span class="line">[OK] New node added correctly.</span><br></pre></td></tr></table></figure><p>上面提示说，自动选择了7006作为master节点。并且成功了。我们检查下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1]# redis-trib.rb check 127.0.0.1:7000</span><br><span class="line">Connecting to node 127.0.0.1:7000: OK</span><br><span class="line">Connecting to node 127.0.0.1:7006: OK</span><br><span class="line">Connecting to node 127.0.0.1:7004: OK</span><br><span class="line">Connecting to node 127.0.0.1:7005: OK</span><br><span class="line">Connecting to node 127.0.0.1:7003: OK</span><br><span class="line">Connecting to node 127.0.0.1:7001: OK</span><br><span class="line">Connecting to node 127.0.0.1:7007: OK</span><br><span class="line">Connecting to node 127.0.0.1:7002: OK</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)</span><br><span class="line">S: 3707debcbe7be66d4a1968eaf3a5ffaf4308efa4 127.0.0.1:7000</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates d2237fdcfbba672de766b913d1186cebcb6e1761</span><br><span class="line">M: efc3131fbdc6cf929720e0e0f7136cae85657481 127.0.0.1:7006</span><br><span class="line">  slots:0-1364,5461-6826,10923-12287 (4096 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: 4b4aef8b48c427a3c903518339d53b6447c58b93 127.0.0.1:7004</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates cb5c04b6160c3b7e18cad5d49d8e2987b27e0d6c</span><br><span class="line">S: 30858dbf483b61b9838d5c1f853a60beaa4e7afd 127.0.0.1:7005</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates dfa0754c7854a874a6ebd2613b86140ad97701fc</span><br><span class="line">M: d2237fdcfbba672de766b913d1186cebcb6e1761 127.0.0.1:7003</span><br><span class="line">  slots:1365-5460 (4096 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">M: cb5c04b6160c3b7e18cad5d49d8e2987b27e0d6c 127.0.0.1:7001</span><br><span class="line">  slots:6827-10922 (4096 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">S: 86d05e7c2b197dc182b5e71069e791d033cf899e 127.0.0.1:7007</span><br><span class="line">  slots: (0 slots) slave</span><br><span class="line">  replicates efc3131fbdc6cf929720e0e0f7136cae85657481</span><br><span class="line">M: dfa0754c7854a874a6ebd2613b86140ad97701fc 127.0.0.1:7002</span><br><span class="line">  slots:12288-16383 (4096 slots) master</span><br><span class="line">  1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><p>果然，7007加入到了7006的从节点当中。</p><p>你说，我如果想指定一个主节点行不行？当然可以。我们再建一个7008节点。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/redis-trib.rb add-node --slave --master-id efc3131fbdc6cf929720e0e0f7136cae85657481 127.0.0.1:7008 127.0.0.1:7000</span><br></pre></td></tr></table></figure><p>–master-id 表示指定的主节点node id。这里指定的是 7006 这个主节点。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Waiting for the cluster to join.</span><br><span class="line">&gt;&gt;&gt; Configure node as replica of 127.0.0.1:7006.</span><br><span class="line">[OK] New node added correctly.</span><br></pre></td></tr></table></figure><p>提示我们已经作为7006的从节点了，也就是加入到7006的从节点来了，照这么说，7006就有2个从节点了，我们看一下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/redis-cli -c -p 7008 cluster nodes |grep efc3131fbdc6cf929720e0e0f7136cae85657481</span><br><span class="line">86d05e7c2b197dc182b5e71069e791d033cf899e 127.0.0.1:7007 slave efc3131fbdc6cf929720e0e0f7136cae85657481 0 1445089507786 8 connected</span><br><span class="line">efc3131fbdc6cf929720e0e0f7136cae85657481 127.0.0.1:7006 master - 0 1445089508289 8 connected 0-1364 5461-6826 10923-12287</span><br><span class="line">44321e7d619410dc4e0a8745366610a0d06d2395 127.0.0.1:7008 myself,slave efc3131fbdc6cf929720e0e0f7136cae85657481 0 0 0 connected</span><br></pre></td></tr></table></figure><p>我们过滤了下看结果，果真，7007和7008是7006的从节点了。</p><p>刚好，我们再做一个实验，我把7006的进程杀掉，看7007和7008谁会变成主节点：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1]# ps -ef|grep redis</span><br><span class="line">root     11384     1  0 09:56 ?        00:00:16 redis-server *:7001 [cluster]</span><br><span class="line">root     11388     1  0 09:56 ?        00:00:16 redis-server *:7002 [cluster]</span><br><span class="line">root     11392     1  0 09:56 ?        00:00:16 redis-server *:7003 [cluster]</span><br><span class="line">root     11396     1  0 09:56 ?        00:00:15 redis-server *:7004 [cluster]</span><br><span class="line">root     11400     1  0 09:56 ?        00:00:15 redis-server *:7005 [cluster]</span><br><span class="line">root     12100     1  0 11:01 ?        00:00:11 redis-server *:7000 [cluster]</span><br><span class="line">root     12132     1  0 11:28 ?        00:00:11 redis-server *:7006 [cluster]</span><br><span class="line">root     12202     1  0 13:14 ?        00:00:02 redis-server *:7007 [cluster]</span><br><span class="line">root     12219     1  0 13:39 ?        00:00:00 redis-server *:7008 [cluster]</span><br><span class="line">root     12239  8259  0 13:49 pts/0    00:00:00 grep redis</span><br><span class="line">[root@centos1]# kill 12132</span><br><span class="line">[root@centos1]# redis-cli -c -p 7008</span><br><span class="line">127.0.0.1:7008&gt; get ss5rtr</span><br><span class="line">-&gt; Redirected to slot [1188] located at 127.0.0.1:7007</span><br><span class="line">&quot;66&quot;</span><br><span class="line">127.0.0.1:7007&gt; cluster nodes</span><br><span class="line">efc3131fbdc6cf929720e0e0f7136cae85657481 127.0.0.1:7006 master,fail - 1445089780668 1445089779963 8 disconnected</span><br><span class="line">d2237fdcfbba672de766b913d1186cebcb6e1761 127.0.0.1:7003 master - 0 1445089812195 7 connected 1365-5460</span><br><span class="line">30858dbf483b61b9838d5c1f853a60beaa4e7afd 127.0.0.1:7005 slave dfa0754c7854a874a6ebd2613b86140ad97701fc 0 1445089813710 3 connected</span><br><span class="line">86d05e7c2b197dc182b5e71069e791d033cf899e 127.0.0.1:7007 myself,master - 0 0 10 connected 0-1364 5461-6826 10923-12287</span><br><span class="line">cb5c04b6160c3b7e18cad5d49d8e2987b27e0d6c 127.0.0.1:7001 master - 0 1445089814214 2 connected 6827-10922</span><br><span class="line">4b4aef8b48c427a3c903518339d53b6447c58b93 127.0.0.1:7004 slave cb5c04b6160c3b7e18cad5d49d8e2987b27e0d6c 0 1445089812701 2 connected</span><br><span class="line">44321e7d619410dc4e0a8745366610a0d06d2395 127.0.0.1:7008 slave 86d05e7c2b197dc182b5e71069e791d033cf899e 0 1445089814214 10 connected</span><br><span class="line">3707debcbe7be66d4a1968eaf3a5ffaf4308efa4 127.0.0.1:7000 slave d2237fdcfbba672de766b913d1186cebcb6e1761 0 1445089813204 7 connected</span><br><span class="line">dfa0754c7854a874a6ebd2613b86140ad97701fc 127.0.0.1:7002 master - 0 1445089813204 3 connected 12288-16383</span><br><span class="line">127.0.0.1:7007&gt;</span><br></pre></td></tr></table></figure><p>这里7007获得了成为主节点的机会，7008就变成了7007的从节点。</p><p>那么这个时候，重启7006节点，那么他就会变成了一个7007的从节点了。</p><p><strong>移除一个节点</strong></p><p>上面是增加一个节点，接下来就是移除一个节点了，移除节点的命令是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/redis-trib del-node 127.0.0.1:7000 `&lt;node-id&gt;`</span><br></pre></td></tr></table></figure><p>没我们尝试下输入以下命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@centos]# bin/redis-trib.rb del-node 127.0.0.1:7000 86d05e7c2b197dc182b5e71069e791d033cf899e</span><br><span class="line">&gt;&gt;&gt; Removing node 86d05e7c2b197dc182b5e71069e791d033cf899e from cluster 127.0.0.1:7000</span><br><span class="line">Connecting to node 127.0.0.1:7000: OK</span><br><span class="line">Connecting to node 127.0.0.1:7006: OK</span><br><span class="line">Connecting to node 127.0.0.1:7004: OK</span><br><span class="line">Connecting to node 127.0.0.1:7001: OK</span><br><span class="line">Connecting to node 127.0.0.1:7003: OK</span><br><span class="line">Connecting to node 127.0.0.1:7007: OK</span><br><span class="line">Connecting to node 127.0.0.1:7008: OK</span><br><span class="line">Connecting to node 127.0.0.1:7005: OK</span><br><span class="line">Connecting to node 127.0.0.1:7002: OK</span><br><span class="line">[ERR] Node 127.0.0.1:7007 is not empty! Reshard data away and try again.</span><br></pre></td></tr></table></figure><p>这里报错了，提示我们7007节点里面有数据，让我们把7007节点里的数据移除出去，也就是说需要重新分片，这个和上面增加节点的方式一样，我们再来一遍</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/redis-trib.rb reshard 127.0.0.1:7000</span><br></pre></td></tr></table></figure><p>省去中间内容，原来7007节点上已经有了4096个哈希槽，这里我们也移动4096个哈希槽 </p><p>然后将这些哈希槽移动到7001节点上</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Source node #1:86d05e7c2b197dc182b5e71069e791d033cf899e</span><br><span class="line">Source node #2:done</span><br><span class="line">Do you want to proceed with the proposed reshard plan (yes/no)? yes</span><br></pre></td></tr></table></figure><p>然后我们再继续执行移除命令，结果如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1]# redis-trib.rb del-node 127.0.0.1:7000 86d05e7c2b197dc182b5e71069e791d033cf899e</span><br><span class="line">&gt;&gt;&gt; Removing node 86d05e7c2b197dc182b5e71069e791d033cf899e from cluster 127.0.0.1:7000</span><br><span class="line">Connecting to node 127.0.0.1:7000: OK</span><br><span class="line">Connecting to node 127.0.0.1:7006: OK</span><br><span class="line">Connecting to node 127.0.0.1:7004: OK</span><br><span class="line">Connecting to node 127.0.0.1:7001: OK</span><br><span class="line">Connecting to node 127.0.0.1:7003: OK</span><br><span class="line">Connecting to node 127.0.0.1:7007: OK</span><br><span class="line">Connecting to node 127.0.0.1:7008: OK</span><br><span class="line">Connecting to node 127.0.0.1:7005: OK</span><br><span class="line">Connecting to node 127.0.0.1:7002: OK</span><br><span class="line">&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...</span><br><span class="line">&gt;&gt;&gt; 127.0.0.1:7006 as replica of 127.0.0.1:7001</span><br><span class="line">&gt;&gt;&gt; 127.0.0.1:7008 as replica of 127.0.0.1:7001</span><br><span class="line">&gt;&gt;&gt; SHUTDOWN the node.</span><br></pre></td></tr></table></figure><p>删除成功，而且还很人性化的将7006和7008这2个原来7007的附属节点送给了7001。考虑的真周到~</p><p><strong>移除一个从节点</strong></p><p>移除一个从节点就比较简单了，因为从节点没有哈希槽，也不需要考虑数据迁移，直接移除就行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1]# redis-trib.rb del-node 127.0.0.1:7005 44321e7d619410dc4e0a8745366610a0d06d2395</span><br><span class="line">&gt;&gt;&gt; Removing node 44321e7d619410dc4e0a8745366610a0d06d2395 from cluster 127.0.0.1:7005</span><br><span class="line">Connecting to node 127.0.0.1:7005: OK</span><br><span class="line">Connecting to node 127.0.0.1:7001: OK</span><br><span class="line">Connecting to node 127.0.0.1:7002: OK</span><br><span class="line">Connecting to node 127.0.0.1:7004: OK</span><br><span class="line">Connecting to node 127.0.0.1:7000: OK</span><br><span class="line">Connecting to node 127.0.0.1:7006: OK</span><br><span class="line">Connecting to node 127.0.0.1:7008: OK</span><br><span class="line">Connecting to node 127.0.0.1:7003: OK</span><br><span class="line">&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...</span><br><span class="line">&gt;&gt;&gt; SHUTDOWN the node.</span><br><span class="line">[root@centos1]# redis-trib.rb check 127.0.0.1:7008</span><br><span class="line">Connecting to node 127.0.0.1:7008: [ERR] Sorry, can&#x27;t connect to node 127.0.0.1:7008</span><br></pre></td></tr></table></figure><p>表示移除成功</p><p><strong>Redis性能测试</strong></p><p>Redis自带了性能测试工具redis-benchmark </p><p>使用说明如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Usage: redis-benchmark [-h &lt;host&gt;] [-p &lt;port&gt;] [-c &lt;clients&gt;] [-n &lt;requests]&gt; [-k &lt;boolean&gt;]</span><br><span class="line"></span><br><span class="line">-h &lt;hostname&gt;      Server hostname (default 127.0.0.1)</span><br><span class="line">-p &lt;port&gt;          Server port (default 6379)</span><br><span class="line">-s &lt;socket&gt;        Server socket (overrides host and port)</span><br><span class="line">-c &lt;clients&gt;       Number of parallel connections (default 50)</span><br><span class="line">-n &lt;requests&gt;      Total number of requests (default 10000)</span><br><span class="line">-d &lt;size&gt;          Data size of SET/GET value in bytes (default 2)</span><br><span class="line">-k &lt;boolean&gt;       1=keep alive 0=reconnect (default 1)</span><br><span class="line">-r &lt;keyspacelen&gt;   Use random keys for SET/GET/INCR, random values for SADD</span><br><span class="line"> Using this option the benchmark will get/set keys</span><br><span class="line"> in the form mykey_rand:000000012456 instead of constant</span><br><span class="line"> keys, the &lt;keyspacelen&gt; argument determines the max</span><br><span class="line"> number of values for the random number. For instance</span><br><span class="line"> if set to 10 only rand:000000000000 - rand:000000000009</span><br><span class="line"> range will be allowed.</span><br><span class="line">-P &lt;numreq&gt;        Pipeline &lt;numreq&gt; requests. Default 1 (no pipeline).</span><br><span class="line">-q                 Quiet. Just show query/sec values</span><br><span class="line">--csv              Output in CSV format</span><br><span class="line">-l                 Loop. Run the tests forever</span><br><span class="line">-t &lt;tests&gt;         Only run the comma-separated list of tests. The test</span><br><span class="line">                   names are the same as the ones produced as output.</span><br><span class="line">-I                 Idle mode. Just open N idle connections and wait.</span><br></pre></td></tr></table></figure><p><strong>基准测试</strong></p><p>基准的测试命令： </p><p>redis-benchmark -q -n 100000 </p><p>结果入下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">root@centos1 bin]# redis-benchmark -q -n 100000</span><br><span class="line">-bash: redis-benchmark: command not found</span><br><span class="line">[root@centos1 bin]# ./redis-benchmark -q -n 100000</span><br><span class="line">PING_INLINE: 61576.36 requests per second</span><br><span class="line">PING_BULK: 60277.28 requests per second</span><br><span class="line">SET: 61349.69 requests per second</span><br><span class="line">GET: 60459.49 requests per second</span><br><span class="line">INCR: 58858.15 requests per second</span><br><span class="line">LPUSH: 59066.75 requests per second</span><br><span class="line">RPUSH: 57339.45 requests per second</span><br><span class="line">LPOP: 55586.44 requests per second</span><br><span class="line">RPOP: 56465.27 requests per second</span><br><span class="line">SADD: 57045.07 requests per second</span><br><span class="line">SPOP: 53734.55 requests per second</span><br><span class="line">LPUSH (needed to benchmark LRANGE): 57012.54 requests per second</span><br><span class="line">LRANGE_100 (first 100 elements): 55803.57 requests per second</span><br><span class="line">LRANGE_300 (first 300 elements): 54914.88 requests per second</span><br><span class="line">LRANGE_500 (first 450 elements): 53333.33 requests per second</span><br><span class="line">LRANGE_600 (first 600 elements): 56529.11 requests per second</span><br><span class="line">MSET (10 keys): 59276.82 requests per second</span><br></pre></td></tr></table></figure><p>这里可以看出，单机版的redis每秒可以处理6万个请求，这已经是一个非常厉害的数据了，不得不佩服 </p><p>我们再来看下集群情况下是是什么情况</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@centos1 bin]# ./redis-benchmark -q -n 100000 -p 7000</span><br><span class="line">PING_INLINE: 64599.48 requests per second</span><br><span class="line">PING_BULK: 64184.85 requests per second</span><br><span class="line">SET: 66800.27 requests per second</span><br><span class="line">GET: 65616.80 requests per second</span><br><span class="line">INCR: 66269.05 requests per second</span><br><span class="line">LPUSH: 40273.86 requests per second</span><br><span class="line">RPUSH: 40355.12 requests per second</span><br><span class="line">LPOP: 43421.62 requests per second</span><br><span class="line">RPOP: 45187.53 requests per second</span><br><span class="line">SADD: 62539.09 requests per second</span><br><span class="line">SPOP: 61538.46 requests per second</span><br><span class="line">LPUSH (needed to benchmark LRANGE): 38182.51 requests per second</span><br><span class="line">LRANGE_100 (first 100 elements): 25555.84 requests per second</span><br><span class="line">LRANGE_300 (first 300 elements): 9571.21 requests per second</span><br><span class="line">LRANGE_500 (first 450 elements): 7214.49 requests per second</span><br><span class="line">LRANGE_600 (first 600 elements): 5478.85 requests per second</span><br><span class="line">MSET (10 keys): 41893.59 requests per second</span><br></pre></td></tr></table></figure><p>这里看出大部分和单机版的性能查不多，主要是lrange命令的差别是很大的</p><p><strong>流水线测试</strong></p><p>使用流水线 </p><p>默认情况下，每个客户端都是在一个请求完成之后才发送下一个请求（基准会模拟50个客户端除非使用-c指定特别的数量），这意味着服务器几乎是按顺序读取每个客户端的命令。RTT也加入了其中。 </p><p>真实世界会更复杂，Redis支持/topics/pipelining，使得可以一次性执行多条命令成为可能。Redis流水线可以提高服务器的TPS </p><p>redis-benchmark -n 1000000 -t set,get -P 16 -q 加入-P选项使用管道技术，一次执行多条命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./redis-benchmark -n 1000000 -t set,get -P 16 -q</span><br><span class="line">SET: 515198.34 requests per second</span><br><span class="line">GET: 613873.56 requests per second</span><br></pre></td></tr></table></figure><p>每秒处理get/sret请求达到了60/50W,真的厉害！</p><p><strong>遇到的问题</strong></p><p>安装redis集群的时候遇到了挺多问题，踩了很多坑，单单是修改配置文件就出了不少问题，那些配置文件的内容都要一一修改，有些配置不修改就会出现无法创建进程的错误</p><p>注意配置集群的时候不要加密码，否则会出现无法连接的情况</p><p>gem install的时候需要修改镜像或者翻墙</p><p>昨天启动成功，今天启动的时候报错</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ERR] Node 172.168.63.202:7001 is not empty. Either the nodealready knows other nodes (check with CLUSTER NODES) or contains some key in database 0</span><br></pre></td></tr></table></figure><p><strong>解决方法：</strong> </p><ol><li>将需要新增的节点下aof、rdb等本地备份文件删除； </li><li>同时将新Node的集群配置文件删除,即：删除你redis.conf里面cluster-config-file所在的文件； </li><li>再次添加新节点如果还是报错，则登录新Node,执行bin/redis-cli–h x –p对数据库进行清除：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:7001&gt;  flushdb      #清空当前数据库</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><p>之间对了Redis的了解并不是说非常多，只是简单的会用，因为现在企业里也很多都在用，刚好老大说接下来的项目可能会用到Redis集群，让我先去了解下，所以最近就在回头看，一边看文档，博客，一边实践，踩了很多的坑，出问题的时候的确是让人感到很痛苦很郁闷的，可是当运行成功的那一刻心情却是无比激动和开心的，可能这就是编程的魅力吧。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>为什么禁止使用外键</title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/other/%E4%B8%BA%E4%BB%80%E4%B9%88%E7%A6%81%E6%AD%A2%E4%BD%BF%E7%94%A8%E5%A4%96%E9%94%AE/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/other/%E4%B8%BA%E4%BB%80%E4%B9%88%E7%A6%81%E6%AD%A2%E4%BD%BF%E7%94%A8%E5%A4%96%E9%94%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="外键的优点"><a href="#外键的优点" class="headerlink" title="外键的优点"></a>外键的优点</h2><h4 id="一、数据一致性"><a href="#一、数据一致性" class="headerlink" title="一、数据一致性"></a>一、数据一致性</h4><p>由数据库自身保证数据一致性、完整性会更可靠，程序很难100％保证数据的一致性、完整性</p><h3 id="二、ER图可靠性"><a href="#二、ER图可靠性" class="headerlink" title="二、ER图可靠性"></a>二、ER图可靠性</h3><p>有主外键的数据库设计可以增加ER图的可读性</p><h2 id="外键的缺点"><a href="#外键的缺点" class="headerlink" title="外键的缺点"></a>外键的缺点</h2><h3 id="一、级联问题"><a href="#一、级联问题" class="headerlink" title="一、级联问题"></a>一、级联问题</h3><p>阿里巴巴的开发手册中，就曾指出强制要求不允许使用外键，一切外键概念必须在应用层解决。 因为每次级联delete或update的时候，都要级联操作相关的外键表，不论有没有这个必要，由其在高并发的场景下，这会导致性能瓶颈</p><h3 id="二、增加数据库压力"><a href="#二、增加数据库压力" class="headerlink" title="二、增加数据库压力"></a>二、增加数据库压力</h3><p>外键等于把数据的一致性事务实现，全部交给数据库服务器完成，并且有了外键，当做一些涉及外键字段的增，删，更新操作之后，需要触发相关操作去检查，而不得不消耗资源</p><h3 id="三、死锁问题"><a href="#三、死锁问题" class="headerlink" title="三、死锁问题"></a>三、死锁问题</h3><p>若是高并发大流量事务场景，使用外键还可能容易造成死锁</p><h3 id="四、开发不方便"><a href="#四、开发不方便" class="headerlink" title="四、开发不方便"></a>四、开发不方便</h3><p>有外键时，无论开发还是维护，需要手工维护数据时，都不太方便，要考虑级联因素</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>一、如是单机且低并发，也不需要性能调优，再或者不能用程序保证数据的一致性，完整性，可以使用外键<br>二、如果为了高并发，分布式，使系统性能更优，以及更好维护，则一定不能使用外键</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>其实这个话题是老生常谈，很多人在工作中确实也不会使用外键。包括在阿里的JAVA规范中也有下面这一条</p><blockquote><p>**【强制】不得使用外键与级联，一切外键概念必须在应用层解决。 **</p></blockquote><p>但是呢，询问他们原因，大多是这么回答的</p><blockquote><p><strong>每次做DELETE 或者UPDATE都必须考虑外键约束，会导致开发的时候很痛苦,测试数据极为不方便。</strong></p></blockquote><p>坦白说，这么说也是对的。但是呢，不够全面，所以开一文来详细说明。</p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>首先我们明确一点，外键约束是一种约束，这个约束的存在，会保证表间数据的关系“始终完整”。因此，外键约束的存在，并非全然没有优点。<br>比如使用外键，可以</p><ul><li>保证数据的完整性和一致性</li><li>级联操作方便</li><li>将数据完整性判断托付给了数据库完成，减少了程序的代码量</li></ul><p>然而，鱼和熊掌不可兼得。外键是能够保证数据的完整性，但是会给系统带来很多缺陷。正是因为这些缺陷，才导致我们不推荐使用外键，具体如下</p><h3 id="性能问题"><a href="#性能问题" class="headerlink" title="性能问题"></a>性能问题</h3><p>假设一张表名为user_tb。那么这张表里有两个外键字段，指向两张表。那么，每次往user_tb表里插入数据，就必须往两个外键对应的表里查询是否有对应数据。如果交由程序控制，这种查询过程就可以控制在我们手里，可以省略一些不必要的查询过程。但是如果由数据库控制，则是必须要去这两张表里判断。</p><h3 id="并发问题"><a href="#并发问题" class="headerlink" title="并发问题"></a>并发问题</h3><p>在使用外键的情况下，每次修改数据都需要去另外一个表检查数据,需要获取额外的锁。若是在高并发大流量事务场景，使用外键更容易造成死锁。</p><h3 id="扩展性问题"><a href="#扩展性问题" class="headerlink" title="扩展性问题"></a>扩展性问题</h3><p>这里主要是分为两点</p><ul><li>做平台迁移方便，比如你从<code>Mysql</code>迁移到<code>Oracle</code>，像触发器、外键这种东西，都可以利用框架本身的特性来实现，而不用依赖于数据库本身的特性，做迁移更加方便。</li><li>分库分表方便，在水平拆分和分库的情况下，外键是无法生效的。将数据间关系的维护，放入应用程序中，为将来的分库分表省去很多的麻烦。</li></ul><h3 id="技术问题"><a href="#技术问题" class="headerlink" title="技术问题"></a>技术问题</h3><p>使用外键，其实将应用程序应该执行的判断逻辑转移到了数据库上。那么这意味着一点，数据库的性能开销变大了，那么这就对DBA的要求就更高了。很多中小型公司由于资金问题，并没有聘用专业的DBA，因此他们会选择不用外键，降低数据库的消耗。<br>相反的，如果该约束逻辑在应用程序中，发现应用服务器性能不够，可以加机器，做水平扩展。如果是在数据库服务器上，数据库服务器会成为性能瓶颈，做水平扩展比较困难。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> 外键 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/other/mysql%20count()%20%E5%87%BD%E6%95%B0%20%E5%AD%97%E6%AE%B5%E6%8C%89%E6%9D%A1%E4%BB%B6%E7%BB%9F%E8%AE%A1%E6%95%B0%E9%87%8F%E5%B9%B6%E6%8E%92%E9%99%A4%E6%9F%90%E4%B8%AA%E5%AD%97%E6%AE%B5%E9%87%8D%E5%A4%8D%E5%80%BC/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/other/mysql%20count()%20%E5%87%BD%E6%95%B0%20%E5%AD%97%E6%AE%B5%E6%8C%89%E6%9D%A1%E4%BB%B6%E7%BB%9F%E8%AE%A1%E6%95%B0%E9%87%8F%E5%B9%B6%E6%8E%92%E9%99%A4%E6%9F%90%E4%B8%AA%E5%AD%97%E6%AE%B5%E9%87%8D%E5%A4%8D%E5%80%BC/</url>
      
        <content type="html"><![CDATA[<h2 id="mysql-count-函数-字段按条件统计数量并排除某个字段重复值"><a href="#mysql-count-函数-字段按条件统计数量并排除某个字段重复值" class="headerlink" title="mysql count() 函数 字段按条件统计数量并排除某个字段重复值"></a>mysql count() 函数 字段按条件统计数量并排除某个字段重复值</h2><p><img src="https://img-blog.csdnimg.cn/20190527151716675.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20190527151716675.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><p><img src="https://img-blog.csdnimg.cn/2019052715190010.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/2019052715190010.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><p><img src="https://img-blog.csdnimg.cn/20190527151912967.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20190527151912967.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line"><span class="operator">*</span>, <span class="built_in">count</span>(c.recruit_info_id) <span class="keyword">AS</span> apply_number,</span><br><span class="line"><span class="built_in">count</span>(</span><br><span class="line">IF (c.approval_status<span class="operator">=</span> <span class="number">5</span>, <span class="number">1</span>, <span class="keyword">NULL</span>)</span><br><span class="line">) <span class="keyword">AS</span> s_number</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">`sh_further_position_posting` `a`</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> `sh_student_keshi` `b` <span class="keyword">ON</span> `a`.`student_keshi_id` <span class="operator">=</span> `b`.`student_keshi_id`</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> `sh_further_recruit_info` `c` <span class="keyword">ON</span> `c`.`post_id` <span class="operator">=</span> `a`.`post_id`</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line"><span class="number">1</span> <span class="operator">=</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span></span><br><span class="line">`a`.`post_id`</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span></span><br><span class="line">`a`.`create_time` <span class="keyword">DESC</span></span><br><span class="line">LIMIT <span class="number">10</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/other/left%20join%E3%80%81right%20join%E5%92%8Cjoin%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/other/left%20join%E3%80%81right%20join%E5%92%8Cjoin%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<p><img src="https://segmentfault.com/img/bVbk2mR?w=966&h=760" class="lazyload" data-srcset="https://segmentfault.com/img/bVbk2mR?w=966&h=760" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="clipboard.png"></p><p>真的是一张图道清所有join的区别啊，可惜我还是看不懂，可能人比较懒，然后基本一个left join给我就是够用的了，所以就没怎么去仔细研究了，但是现实还是逼我去搞清楚，索性自己动手，总算理解图中的含义了，下面就听我一一道来。</p><p>首先，我们先来建两张表，第一张表命名为kemu，第二张表命名为score：</p><p><img src="https://segmentfault.com/img/bVbk2or?w=118&h=92" class="lazyload" data-srcset="https://segmentfault.com/img/bVbk2or?w=118&h=92" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="clipboard.png"><img src="https://segmentfault.com/img/bVbk2oz?w=128&h=94" class="lazyload" data-srcset="https://segmentfault.com/img/bVbk2oz?w=128&h=94" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="clipboard.png"></p><p><strong>一、left join</strong><br>顾名思义，就是“左连接”，表1左连接表2，以左为主，表示以表1为主，关联上表2的数据，查出来的结果显示左边的所有数据，然后右边显示的是和左边有交集部分的数据。如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">   *</span><br><span class="line">from</span><br><span class="line">   kemu</span><br><span class="line">left join score on kemu.id = score.id</span><br></pre></td></tr></table></figure><p>结果集：<br><img src="https://segmentfault.com/img/bVbk2uE?w=205&h=144" class="lazyload" data-srcset="https://segmentfault.com/img/bVbk2uE?w=205&h=144" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="clipboard.png"><img src="https://segmentfault.com/img/bVbk2qQ?w=238&h=103" class="lazyload" data-srcset="https://segmentfault.com/img/bVbk2qQ?w=238&h=103" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="clipboard.png"></p><p><strong>二、right join</strong></p><p>“右连接”，表1右连接表2，以右为主，表示以表2为主，关联查询表1的数据，查出表2所有数据以及表1和表2有交集的数据，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">   *</span><br><span class="line">from</span><br><span class="line">   kemu</span><br><span class="line">right join score on kemu.id = score.id</span><br></pre></td></tr></table></figure><p>结果集：</p><p><img src="https://segmentfault.com/img/bVbk2uI?w=222&h=143" class="lazyload" data-srcset="https://segmentfault.com/img/bVbk2uI?w=222&h=143" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="clipboard.png"><img src="https://segmentfault.com/img/bVbk2uP?w=228&h=104" class="lazyload" data-srcset="https://segmentfault.com/img/bVbk2uP?w=228&h=104" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="clipboard.png"></p><p><strong>三、join</strong><br>join，其实就是“inner join”，为了简写才写成join，两个是表示一个的，内连接，表示以两个表的交集为主，查出来是两个表有交集的部分，其余没有关联就不额外显示出来，这个用的情况也是挺多的，如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">   *</span><br><span class="line">from</span><br><span class="line">   kemu</span><br><span class="line">join score on kemu.id = score.id</span><br></pre></td></tr></table></figure><p>结果集：</p><p><img src="https://segmentfault.com/img/bVbk2v1?w=227&h=145" class="lazyload" data-srcset="https://segmentfault.com/img/bVbk2v1?w=227&h=145" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="clipboard.png"><img src="https://segmentfault.com/img/bVbk2MW?w=231&h=69" class="lazyload" data-srcset="https://segmentfault.com/img/bVbk2MW?w=231&h=69" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="clipboard.png"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/other/Find_in_set/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/other/Find_in_set/</url>
      
        <content type="html"><![CDATA[<p>Returns a value in the range of 1 to <em><code>N</code></em> if the string <em><code>str</code></em> is in the string list <em><code>strlist</code></em> consisting of <em><code>N</code></em> substrings. A string list is a string composed of substrings separated by <code>,</code> characters. If the first argument is a constant string and the second is a column of type <a href="https://dev.mysql.com/doc/refman/8.0/en/set.html"><code>SET</code></a>, the <a href="https://dev.mysql.com/doc/refman/8.0/en/string-functions.html#function_find-in-set"><code>FIND_IN_SET()</code></a> function is optimized to use bit arithmetic. Returns <code>0</code> if <em><code>str</code></em> is not in <em><code>strlist</code></em> or if <em><code>strlist</code></em> is the empty string. Returns <code>NULL</code> if either argument is <code>NULL</code>. This function does not work properly if the first argument contains a comma (<code>,</code>) character.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> FIND_IN_SET(<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;a,b,c,d&#x27;</span>);</span><br><span class="line">        <span class="operator">-</span><span class="operator">&gt;</span> <span class="number">2</span></span><br></pre></td></tr></table></figure><p>mysql中FIND_IN_SET函数用来比较是不是包含，不管‘list’字段是变量或给定的字符串常量都能很好的工作。<strong>MySQL中原型为：FIND_IN_SET(str,strlist)。 假如字符串str 在由N 子链组成的字符串列表strlist 中，则返回值的范围在 1 到 N 之间。</strong> </p><p>一个字符串列表就是一个由一些被‘,’符号分开的子链组成的字符串。如果第一个参数是一个常数字符串，而第二个是type SET列，则  FIND_IN_SET() 函数被优化，使用比特计算。 如果str不在strlist 或strlist 为空字符串，则返回值为 0 。如任意一个参数为NULL，则返回值为 NULL。这个函数在第一个参数包含一个逗号(‘,’)时将无法正常运行。</p><p>str也可以是变量，比如表中的一个字段。</p><p>虽然这样很好用，但问题是如果数据量大的情况下怎么办，性能会是问题么，手册上有说对find_in_set 做的优化，但在没有索引的情况下他的性能应该是个问题。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E9%9D%A2%E8%AF%95/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E9%9D%A2%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<ol><li>为什么在写SQL语句时遵守最左前缀原则才能用到索引？不遵守就用不到索引？其底层工作机制是怎样的？</li><li>MySQL中写缓冲区为什么能优化写入的速度？如何做到的？</li><li>MySQL在执行一个SQL语句时会经过哪些步骤？这每个步骤可以如何优化？</li><li>写了一个很长的SQL，这个SQL最终的执行顺序是怎样的？如何优化复杂SQL？</li><li>到底多大数据的表才是大表？500万条？2000万条？5000万条？</li><li>如果一个表中数据量很大，这个时候如何建立索引，如何优化索引？</li><li>高并发场景下，使用MySQL事务时应该要注意哪些方面，如何进行优化？</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E5%BC%80%E7%AF%87/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E5%BC%80%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="基础篇"><a href="#基础篇" class="headerlink" title="基础篇"></a>基础篇</h2><h3 id="1-基础架构：一条SQL查询语句是如何执行的？"><a href="#1-基础架构：一条SQL查询语句是如何执行的？" class="headerlink" title="1.基础架构：一条SQL查询语句是如何执行的？"></a>1.基础架构：一条SQL查询语句是如何执行的？</h3><p><img src="../images/20210114104738.png" class="lazyload" data-srcset="../images/20210114104738.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数字和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</p><p><strong>连接器</strong></p><p>连接器负责跟客户端建立链接、获取权限、维持和管理链接。</p><p>如果长时间没有动静，连接器默认8小时会自动断开，再次发送请求需要进行重连。</p><p>数据库中长连接指的是连接成功后，如果客户端持续有请求，则一直使用同一个连接，短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。</p><p>全部使用长连接，会非常占用内存，导致内存占用太大，被系统强行杀掉（OOM），导致MySQL异常重启。</p><p>解决方案：</p><p>1.定期断开连接，使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</p><p>2.MySQL5.7及以上版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源，这个过程不需要重连和重新做权限验证，但是会将连接回复到刚刚创建完的状态。</p><p><strong>查询缓存</strong></p><p>不建议使用查询缓存：</p><p>因为查询缓存往往弊大于利。</p><p>查询缓存的失效非常频繁，只要对一个表的更新，这个表上所有的查询花奴才能都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低，除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。</p><p>MySQL8.0已经移除该功能。</p><p><strong>分析器</strong></p><p>分析器会先做”词法分析”。你输入的是由多个字符喜欢和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。</p><p>然后是“语法分析”，根据词法分析的结果，语法分析器会根据语法规则，判断你输入的额这个NySQL语句是否满足MySQL语法。</p><p><strong>优化器</strong></p><p>优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。</p><p><strong>执行器</strong></p><p>开始执行的时候，会先判断你对这个表T哟没有执行查询的权限，如果没有，就会返回没有权限的错误（在工程上实现，如果命中查询缓存，就会在查询缓存返回结果的时候，做权限验证，查询也会在优化器之前调用precheck权限验证）。</p><p>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。</p><h3 id="2-日志系统：一条SQL更新语句是如何执行的？"><a href="#2-日志系统：一条SQL更新语句是如何执行的？" class="headerlink" title="2.日志系统：一条SQL更新语句是如何执行的？"></a>2.日志系统：一条SQL更新语句是如何执行的？</h3><p>MySQL的逻辑架构图和查询一直，执行语句前要先连接数据库，这是连接器的工作。</p><p>一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表T上所有缓存结果都清空，这也就是我们一般不建议使用查询缓存的原因。</p><p>接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用ID这个索引，然后，执行器负责具体执行，找到这一行，然后更新。</p><p>与查询流程不一样的是，更新流程还涉及两个重要的日志模块:redo log(重做日志)和bin log(归档日志)。</p><h4 id="redo-log-重做日志"><a href="#redo-log-重做日志" class="headerlink" title="redo log(重做日志)"></a>redo log(重做日志)</h4><p>在MySQL有一个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高，为了解决这个问题，MySQL的设计者采用WAL技术，全称 Write-Ahead Logging。它的关键点就是先写日志，再写磁盘。</p><p>具体俩说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。</p><p>于此类似，InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么总共就可以自己录4GB操作。从头开始写，写到末尾就又回到开头循环写，如图所示。</p><p><img src="../images/20210118104528.png" class="lazyload" data-srcset="../images/20210118104528.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。</p><p>write pos和checkpoint之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示“粉板”满了，这时候不能再执行新的操作，得停下来先擦掉一些记录，把checkpoint推进一下。</p><p>有了redo log，InnoDB就可以保存即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为<strong>crash-safe</strong>。</p><h4 id="binlog-归档日志"><a href="#binlog-归档日志" class="headerlink" title="binlog(归档日志)"></a>binlog(归档日志)</h4><p>MySQL整体来看，分为两块：一块是Server层，它主要做的是MySQL功能层面的事情；还有一块就是引擎层，负责存储相关的具体事宜。redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog(归档日志)。</p><p><em>为什么会有两个日志</em></p><p>因为最开始MySQL里并没有InnoDB引擎。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档，而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统-也就是redo log来实现crash-safe能力。</p><p><em>两种日志的区别</em></p><p>1.redo log是InnoDB引擎特有的；binlog是MySQL的server层实现的，所有引擎都可以使用。</p><p>2.redo log是物理日志，记录的是“在某个数据页上做了什么修改”;binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2 这一行的c字段加 1”。</p><p>3.redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p><p><em>执行器和InnoDB引擎在执行这个简单Update语句时的内部流程</em></p><p>1.执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在是的数据项本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</p><p>2.执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</p><p>3.引擎将这行新数据更新到内存中，同时将这个更新数据操作记录到redo log里面，此时redo log处于prepare状态，然后告知执行器执行完成了，随时可以提交事务。</p><p>4.执行器生成这个操作的binlog，并把binlog写入磁盘。</p><p>5.执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。</p><p><img src="../images/20210118174909.png" class="lazyload" data-srcset="../images/20210118174909.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><h4 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h4><p>为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：</p><p><em>怎样让数据库恢复到半个月内任意一秒的状态？</em></p><p>前面我们说过了，binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。</p><p>当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：</p><p>这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。</p><p>好了，说完了数据恢复过程，我们回来说说，为什么日志需要“两阶段提交”。这里不妨用反证法来进行解释。</p><p>由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。</p><p>仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？</p><ol><li><p><strong>先写 redo log 后写 binlog。</strong>假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。 但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。 然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。</p></li><li><p><strong>先写 binlog 后写 redo log。</strong>如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。</p></li></ol><p>可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。</p><p>你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？</p><p>其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。</p><p>简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。</p><h3 id="3-事务隔离：为什么你改了我还看不见？"><a href="#3-事务隔离：为什么你改了我还看不见？" class="headerlink" title="3.事务隔离：为什么你改了我还看不见？"></a>3.事务隔离：为什么你改了我还看不见？</h3><p>简单来说，事务就是保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。你现在知道，MySQL是一个支持多引擎的系统，但并不是所有的引擎都支持事务。MyISAM就不支持事务，InnoDB支持。</p><h4 id="隔离性与隔离级别"><a href="#隔离性与隔离级别" class="headerlink" title="隔离性与隔离级别"></a>隔离性与隔离级别</h4><p>提到事务，你肯定会想到 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），今天我们就来说说其中 I，也就是“隔离性”。</p><p>当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。</p><p>在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：读未提交（readuncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。下面我逐一为你解释：</p><p>1.<strong>读未提交</strong>是指，一个事务还没提交时，它做的变更就能被别的事务看到。</p><p>2.<strong>读提交</strong>是指，一个事务提交之后，它做的变更才会被其他事务看到。</p><p>3.<strong>可重复读</strong>是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</p><p>4.<strong>串行化</strong>，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</p><p>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。</p><p>在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。</p><p>我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”。</p><p>配置的方式是，将启动参数tranaction-isolation的值设置成READ-COMMITTED。你可以用show variables来查看当前的值。</p><p>总结来说，哪个隔离级别都有它自己的使用场景，要根据业务情况来定。</p><h4 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h4><p>在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作，记录上的最新值，通过回滚操作，都可以得到前一个状态的值。</p><p>你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。</p><p>什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。</p><p>基于上面的说明，建议不要使用长事务。</p><p>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p><p>在MySQL5.5及以前的版本，回滚日志是跟数据字典一起放在ibdata文件里，即使长事务最终提交，回滚段被清理，文件也不会变小。有数据只有20GB，而回滚段有200GB的库，最终只好为了清理回滚段，重建整个库。</p><p>除了对回滚段的印象，长事务还占用锁资源，也可能拖垮整个库。</p><h4 id="事务的启动方式"><a href="#事务的启动方式" class="headerlink" title="事务的启动方式"></a>事务的启动方式</h4><p>如前面所述，长事务有这些潜在风险，建议尽量避免，其实很多时候业务开发不是有意使用长事务，而是由于误用所致。</p><p>MySQL的事务启动方式有一下几种：</p><p>1.显示启动事务语句，begin或start transaction。配套的提交语句是commit，回滚语句是rollback。</p><p>2.set autocommit=0，这命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会主动提交，这个事务持续存到知道你主动执行commit或rollback语句，或者断开连接。</p><p>有些客户端连接框架会默认连接成功后先执行一个set autocommit=0命令，这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。</p><p><strong>因此，建议总是使用set autocommit=1，通过显式语句的方式来启动事务。</strong></p><p>在autocommit=1的情况下，用begin显式启动的事务。</p><p>但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。</p><p>如果你也有这个顾虑，我建议你使用 commit work and chain 语法。</p><p>在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。</p><p>你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。</p><h4 id="如何避免长事务对业务的影响？"><a href="#如何避免长事务对业务的影响？" class="headerlink" title="如何避免长事务对业务的影响？"></a>如何避免长事务对业务的影响？</h4><p><strong>首先，从应用开发端来看：</strong></p><p>1.确认是否使用了set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志 来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它 改成 1。</p><p>2.确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框 起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。 这种只读事务可以去掉。</p><p>3.业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命 令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。</p><p><strong>其次，从数据库端来看：</strong></p><p>1.监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；</p><p>2.Percona 的 pt-kill 这个工具不错，推荐使用；</p><p>3.在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；</p><p>4.如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方 便。</p><h3 id="4-深入浅出索引（上）"><a href="#4-深入浅出索引（上）" class="headerlink" title="4.深入浅出索引（上）"></a>4.深入浅出索引（上）</h3><p>索引的出现其实是为了提高数据查询的效率，就像书的目录一样。</p><h4 id="索引的常见模型"><a href="#索引的常见模型" class="headerlink" title="索引的常见模型"></a>索引的常见模型</h4><p>索引的出现是为了提高查询效率，但是实现索引的方式却又很多种，所以这里也就引入了索引模型的概念，可以用于提高读写效率的数据结构很多，比较常见、简单的数据结构分别是<strong>哈希表、有序数组和索引树。</strong></p><p>从使用的角度，简单分析这三种模型的区别。</p><p><em>哈希表</em>是一种以键-值（key-value）存储数据的结构，我们只要输入待查找的值即key，就可以找到其对应的值即value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。</p><p>不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个<em>链表</em>。</p><p>假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：</p><p><img src="../images/20210119192606.png" class="lazyload" data-srcset="../images/20210119192606.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>图中，User2 和 User4 根据身份证号算出来的值都是 N，但没关系，后面还跟了一个链 表。假设，这时候你要查 ID_card_n2 对应的名字是什么，处理步骤就是：首先，将 ID_card_n2 通过哈希函数算出 N；然后，按顺序遍历，找到 User2。</p><p>需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询 的速度是很慢的。</p><p>你可以设想下，如果你现在要找身份证号在 [ID_card_X, ID_card_Y] 这个区间的所有用 户，就必须全部扫描一遍了。</p><p>所以，<strong>哈希表这种结构适用于只有等值查询的场景</strong>，比如 Memcached 及其他一些 NoSQL 引擎。 </p><p>而有<strong>序数组在等值查询和范围查询场景中的性能就都非常优秀</strong>。还是上面这个根据身份证 号查名字的例子，如果我们使用有序数组来实现的话，示意图如下所示：</p><p><img src="../images/20210119192844.png" class="lazyload" data-srcset="../images/20210119192844.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>这里我们假设身份证号没有重复，这个数组就是按照身份证号递增的顺序保存的。这时候 如果你要查 ID_card_n2 对应的名字，用二分法就可以快速得到，这个时间复杂度是 O(log(N))。</p><p>同时很显然，这个索引结构支持范围查询。你要查身份证号在 [ID_card_X, ID_card_Y] 区 间的 User，可以先用二分法找到 ID_card_X（如果不存在 ID_card_X，就找到大于 ID_card_X 的第一个 User），然后向右遍历，直到查到第一个大于 ID_card_Y 的身份证 号，退出循环。</p><p>如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就 麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。</p><p>所以，<strong>有序数组索引只适用于静态存储引擎</strong>，比如你要保存的是 2017 年某个城市的所有 人口信息，这类不会再修改的数据。</p><p>二叉搜索树也是课本里的经典数据结构了。还是上面根据身份证号查名字的例子，如果我 们用二叉搜索树来实现的话，示意图如下所示：</p><p><img src="../images/20210119193056.png" class="lazyload" data-srcset="../images/20210119193056.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你 要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -&gt; UserC -&gt; UserF -&gt; User2 这个路径得到。这个时间复杂度是 O(log(N))。</p><p>当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个 保证，更新的时间复杂度也是 O(log(N))。</p><p>树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从 左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉 树。其原因是，索引不止存在内存中，还要写到磁盘上。</p><p><strong>为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就 不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块 的大小</strong>。</p><p>N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引 擎中了。</p><p>在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引 擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实 现也可能不同。由于 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛，所以下面我就 以 InnoDB 为例，和你分析一下其中的索引模型。</p><h4 id="InnoDB-的索引模型"><a href="#InnoDB-的索引模型" class="headerlink" title="InnoDB 的索引模型"></a>InnoDB 的索引模型</h4><p>在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组 织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。</p><p>每一个索引在 InnoDB 里面对应一棵 B+ 树。</p><p>假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。<br>表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树 的示例示意图如下。</p><p><img src="../images/20210119193814.png" class="lazyload" data-srcset="../images/20210119193814.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。</p><p>主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引 （clustered index）。</p><p>非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引 （secondary index）。</p><p><strong>基于主键索引和普通索引的查询有什么 区别？</strong></p><p>如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树； 如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引 树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。</p><p>也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量 使用主键查询。</p><h4 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a>索引维护</h4><p>B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例， 如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。</p><p>而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请 一个新的数据页，然后挪动部分数据过去。这个过程称为<strong>页分裂</strong>。在这种情况下，性能自然会受影响。</p><p>除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。</p><p>当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合 并。合并的过程，可以认为是分裂过程的逆过程。</p><p>基于上面的索引维护过程说明，我们来讨论一个案例：</p><blockquote><p>你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自 增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而 哪些场景下不应该。</p></blockquote><p>自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。</p><p>插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。</p><p>也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插 入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂</p><p>而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。</p><p>除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字 段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？</p><p>由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级 索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整 型（bigint）则是 8 个字节。</p><p><strong>显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。</strong></p><p>所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。</p><p>有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求 是这样的：</p><ol><li>只有一个索引； </li><li>该索引必须是唯一索引。</li></ol><p>你一定看出来了，这就是典型的 KV 场景。</p><p>由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。</p><p>这时候我们就要优先考虑上一段提到的“<strong>尽量使用主键查询</strong>”原则，直接将这个索引设置 为主键，可以避免每次查询需要搜索两棵树。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>InnoDB采用B+树结构，因为B+树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问数。</p><p>由于InnoDB是索引组织表，一般情况下建议创建一个自增组件，这样非主键索引占用的空间最小，但是事无绝对，根据业务场景也可以使用业务逻辑字段做主键。</p><h3 id="5-深入浅出索引（下）"><a href="#5-深入浅出索引（下）" class="headerlink" title="5.深入浅出索引（下）"></a>5.深入浅出索引（下）</h3><h3 id="6-全局锁和表锁：给表加个字段怎么有这么多阻碍？"><a href="#6-全局锁和表锁：给表加个字段怎么有这么多阻碍？" class="headerlink" title="6.全局锁和表锁：给表加个字段怎么有这么多阻碍？"></a>6.全局锁和表锁：给表加个字段怎么有这么多阻碍？</h3><p>数据库锁设计的初衷是处理并发问题，作为多用户共享的资源，当出现并发访问的时候，数据需要合理地控制资源的访问规则，而锁就是用来实现这些访问规则的重要数据结构。</p><p><strong>根据加锁的范围，MySQL里面的锁大致可以分为全局锁、表级锁和行锁三类。</strong></p><h4 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h4><p>顾名思义，全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是Flush tables with read lock(FTWRL)。当你需要整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。</p><p><strong>全局锁的典型使用场景是，做全库逻辑备份。</strong>也就是把整库每个表都select出来存成文本。</p><p>以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做 备份。注意，在备份过程中整个库完全处于只读状态。</p><p>但是让整库都只读，听上去就很危险：</p><blockquote><p>如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；</p><p>如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从 延迟。</p></blockquote><p>不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑 不一致的。其实是有一个方法能够拿到一 致性视图的，就是在可重复读隔离级别下开启一个事务。</p><p>官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持， 这个过程中数据是可以正常更新的。</p><p>你一定在疑惑，有了这个功能，为什么还需要 FTWRL 呢？<strong>一致性读是好，但前提是引擎 要支持这个隔离级别</strong>。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有 更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。</p><p>所以，<strong>single-transaction 方法只适用于所有的表使用事务引擎的库</strong>。如果有的表使用了 不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员 使用 InnoDB 替代 MyISAM 的原因之一。</p><p>你也许会问，<strong>既然要全库只读，为什么不使用 set global readonly=true 的方式呢？</strong>确 实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要 有两个原因：</p><blockquote><p>1.在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库 还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。</p><p>2.在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个 库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状 态，这样会导致整个库长时间处于不可写状态，风险较高。</p></blockquote><p>业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作 （DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操 作，都是会被锁住的。</p><p>但是，即使没有被全局锁住，加字段也不是就能一帆风顺的，因为你还会碰到接下来我们 要介绍的表级锁。</p><h4 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h4><p>MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock， MDL)。</p><p>**表锁的语法是lock tables…read/write.**与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放，需要注意，lock tables语法除了会限制别的线程的读写外，也限制了本线程接下来的操作对象。</p><p>举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。</p><p>在还没出现更细粒度的锁的时候，表锁是最常用的处理并发的方式，而对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。</p><p><strong>另一类表级的锁MDL（metadata lock）。</strong>DML不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性，你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果更表结构对不上，肯定是不行的。</p><p>因此，在MySQL5.5版本中引入了MDL，当对一个表做增删查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。</p><blockquote><p>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</p><p>读写锁之间、写锁之间是互斥的，用来保证变成表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</p></blockquote><p>虽然MDL锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。</p><p>你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响，而实际上，即使是小表，操作不慎也会出问题。</p><p><img src="../images/20210126114811.png" class="lazyload" data-srcset="../images/20210126114811.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需 要的也是 MDL 读锁，因此可以正常执行。 </p><p>之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。</p><p>如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读 锁的请求也会被 session C 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。</p><p>如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。</p><p>你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会 马上释放，而会等到整个事务提交后再释放。</p><p>基于上面的分析，我们来讨论一个问题，<strong>如何安全地给小表加字段？</strong></p><p>首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。</p><p>但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请 求很频繁，而你不得不加个字段，你该怎么做呢？</p><p>这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不 到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这 个过程。</p><p>MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> tbl_name NOWAIT <span class="keyword">add</span> <span class="keyword">column</span> ...</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> tbl_name WAIT N <span class="keyword">add</span> <span class="keyword">column</span> ...</span><br></pre></td></tr></table></figure><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，我建议你选择使用– single-transaction 参数，对应用会更友好。</p><p>表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是：</p><blockquote><p>要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；</p><p>要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。</p></blockquote><p>MDL 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。</p><p>最后，我给你留一个问题吧。备份一般都会在备库上执行，你在用–single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一 列。这时候，从备库上会看到什么现象呢？</p><p><strong>online ddl</strong></p><p>Online DDL的过程是这样的：</p><ol><li>拿MDL写锁 </li><li>降级成MDL读锁 </li><li>真正做DDL </li><li>升级成MDL写锁 </li><li>释放MDL锁 </li></ol><p>1、2、4、5如果没有锁冲突，执行时间非常短。第3步占用了DDL绝大部分时间，这期间这个表 可以正常读写数据，是因此称为“online ” 我们文中的例子，是在第一步就堵住了</p><h3 id="7-行锁功过：怎么减少行锁对性能的影响？"><a href="#7-行锁功过：怎么减少行锁对性能的影响？" class="headerlink" title="7.行锁功过：怎么减少行锁对性能的影响？"></a>7.行锁功过：怎么减少行锁对性能的影响？</h3><h3 id="8-事务到底是隔离还是不隔离的？"><a href="#8-事务到底是隔离还是不隔离的？" class="headerlink" title="8.事务到底是隔离还是不隔离的？"></a>8.事务到底是隔离还是不隔离的？</h3>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E5%AE%9E%E8%B7%B5%E7%AF%873/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E5%AE%9E%E8%B7%B5%E7%AF%873/</url>
      
        <content type="html"><![CDATA[<h3 id="33-我查这么多数据，会不会把数据内存打爆？"><a href="#33-我查这么多数据，会不会把数据内存打爆？" class="headerlink" title="33.我查这么多数据，会不会把数据内存打爆？"></a>33.我查这么多数据，会不会把数据内存打爆？</h3><h3 id="34-到底可不可以使用join"><a href="#34-到底可不可以使用join" class="headerlink" title="34.到底可不可以使用join?"></a>34.到底可不可以使用join?</h3><p>在实际生产中，关于 join 语句使用的问题，一般会集中在以下两类：</p><ol><li>我们 DBA 不让使用 join，使用 join 有什么问题呢？</li><li>如果有两个大小不同的表做 join，应该用哪个表做驱动表呢？</li></ol><h4 id="Index-Nested-Loop-Join"><a href="#Index-Nested-Loop-Join" class="headerlink" title="Index Nested-Loop Join"></a>Index Nested-Loop Join</h4><p>这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。</p><h3 id="35-join语句怎么优化？"><a href="#35-join语句怎么优化？" class="headerlink" title="35.join语句怎么优化？"></a>35.join语句怎么优化？</h3><h3 id="36-为什么临时表可以重名？"><a href="#36-为什么临时表可以重名？" class="headerlink" title="36.为什么临时表可以重名？"></a>36.为什么临时表可以重名？</h3><h3 id="37-什么时候会使用内部临时表？"><a href="#37-什么时候会使用内部临时表？" class="headerlink" title="37.什么时候会使用内部临时表？"></a>37.什么时候会使用内部临时表？</h3><h3 id="38-都说InnoDB好，那还要不要使用Memory引擎？"><a href="#38-都说InnoDB好，那还要不要使用Memory引擎？" class="headerlink" title="38.都说InnoDB好，那还要不要使用Memory引擎？"></a>38.都说InnoDB好，那还要不要使用Memory引擎？</h3><h3 id="39-自增主键为什么不是连续的？"><a href="#39-自增主键为什么不是连续的？" class="headerlink" title="39.自增主键为什么不是连续的？"></a>39.自增主键为什么不是连续的？</h3><h3 id="40-insert语句的锁为什么这么多？"><a href="#40-insert语句的锁为什么这么多？" class="headerlink" title="40.insert语句的锁为什么这么多？"></a>40.insert语句的锁为什么这么多？</h3><h3 id="41-怎么最快地复制一张表？"><a href="#41-怎么最快地复制一张表？" class="headerlink" title="41.怎么最快地复制一张表？"></a>41.怎么最快地复制一张表？</h3><h3 id="42-grant之后要跟着flush-privileges吗？"><a href="#42-grant之后要跟着flush-privileges吗？" class="headerlink" title="42.grant之后要跟着flush privileges吗？"></a>42.grant之后要跟着flush privileges吗？</h3><h3 id="43-要不要使用分区表？"><a href="#43-要不要使用分区表？" class="headerlink" title="43.要不要使用分区表？"></a>43.要不要使用分区表？</h3><h3 id="44"><a href="#44" class="headerlink" title="44."></a>44.</h3><h3 id="45-递增id用完了怎么办？"><a href="#45-递增id用完了怎么办？" class="headerlink" title="45.递增id用完了怎么办？"></a>45.递增id用完了怎么办？</h3>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E5%AE%9E%E8%B7%B5%E7%AF%872/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E5%AE%9E%E8%B7%B5%E7%AF%872/</url>
      
        <content type="html"><![CDATA[<h3 id="21-为什么我只查一行的语句，锁这么多？"><a href="#21-为什么我只查一行的语句，锁这么多？" class="headerlink" title="21.为什么我只查一行的语句，锁这么多？"></a>21.为什么我只查一行的语句，锁这么多？</h3><h3 id="22-MySQL有哪些“饮鸩止渴”提高性能的方法？"><a href="#22-MySQL有哪些“饮鸩止渴”提高性能的方法？" class="headerlink" title="22.MySQL有哪些“饮鸩止渴”提高性能的方法？"></a>22.MySQL有哪些“饮鸩止渴”提高性能的方法？</h3><h3 id="23-MySQL是怎么保证数据不丢的？"><a href="#23-MySQL是怎么保证数据不丢的？" class="headerlink" title="23.MySQL是怎么保证数据不丢的？"></a>23.MySQL是怎么保证数据不丢的？</h3><p>只要redo log和binlog保证持久化到磁盘，就能确保MySQL异常重启后，数据可以恢复。</p><h4 id="binlog的写入机制"><a href="#binlog的写入机制" class="headerlink" title="binlog的写入机制"></a>binlog的写入机制</h4><p>其实，binlog的写入逻辑比较简单：事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。</p><p>一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了binlog cache的保存问题。</p><p>系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。</p><p>事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空binlog cache。状态如图 1 所示。</p><h3 id="24-MySQL是怎么保证主备一致的？"><a href="#24-MySQL是怎么保证主备一致的？" class="headerlink" title="24.MySQL是怎么保证主备一致的？"></a>24.MySQL是怎么保证主备一致的？</h3><h3 id="25-MySQL是怎么保证高可用的？"><a href="#25-MySQL是怎么保证高可用的？" class="headerlink" title="25.MySQL是怎么保证高可用的？"></a>25.MySQL是怎么保证高可用的？</h3><h3 id="26-备库为什么会延迟好几个小时？"><a href="#26-备库为什么会延迟好几个小时？" class="headerlink" title="26.备库为什么会延迟好几个小时？"></a>26.备库为什么会延迟好几个小时？</h3><h3 id="27-主库出问题了，从库怎么办？"><a href="#27-主库出问题了，从库怎么办？" class="headerlink" title="27.主库出问题了，从库怎么办？"></a>27.主库出问题了，从库怎么办？</h3><h3 id="28-读写分离有哪些坑？"><a href="#28-读写分离有哪些坑？" class="headerlink" title="28.读写分离有哪些坑？"></a>28.读写分离有哪些坑？</h3><h3 id="29-如何判断一个数据库是不是出问题了"><a href="#29-如何判断一个数据库是不是出问题了" class="headerlink" title="29.如何判断一个数据库是不是出问题了?"></a>29.如何判断一个数据库是不是出问题了?</h3><h3 id="30-答疑文章（二）：用动态的观点看加锁"><a href="#30-答疑文章（二）：用动态的观点看加锁" class="headerlink" title="30.答疑文章（二）：用动态的观点看加锁"></a>30.答疑文章（二）：用动态的观点看加锁</h3><h3 id="31-误删数据后除了跑路，还能怎么办？"><a href="#31-误删数据后除了跑路，还能怎么办？" class="headerlink" title="31.误删数据后除了跑路，还能怎么办？"></a>31.误删数据后除了跑路，还能怎么办？</h3><h3 id="32-为什么还有kill不掉的语句？"><a href="#32-为什么还有kill不掉的语句？" class="headerlink" title="32.为什么还有kill不掉的语句？"></a>32.为什么还有kill不掉的语句？</h3>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E5%AE%9E%E8%B7%B5%E7%AF%871/"/>
      <url>/2021/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E5%AE%9E%E8%B7%B5%E7%AF%871/</url>
      
        <content type="html"><![CDATA[<h2 id="实践篇"><a href="#实践篇" class="headerlink" title="实践篇"></a>实践篇</h2><h3 id="9-普通索引和唯一索引，应该怎么选择？"><a href="#9-普通索引和唯一索引，应该怎么选择？" class="headerlink" title="9.普通索引和唯一索引，应该怎么选择？"></a>9.普通索引和唯一索引，应该怎么选择？</h3><h3 id="10-MySQL为什么有时候会选错索引？"><a href="#10-MySQL为什么有时候会选错索引？" class="headerlink" title="10.MySQL为什么有时候会选错索引？"></a>10.MySQL为什么有时候会选错索引？</h3><h3 id="11-怎么给字符串字段加索引？"><a href="#11-怎么给字符串字段加索引？" class="headerlink" title="11.怎么给字符串字段加索引？"></a>11.怎么给字符串字段加索引？</h3><h3 id="12-为什么我的MySQL会“抖”一下？"><a href="#12-为什么我的MySQL会“抖”一下？" class="headerlink" title="12.为什么我的MySQL会“抖”一下？"></a>12.为什么我的MySQL会“抖”一下？</h3><h3 id="13-为什么表数据删除一半，表文件大小不变？"><a href="#13-为什么表数据删除一半，表文件大小不变？" class="headerlink" title="13.为什么表数据删除一半，表文件大小不变？"></a>13.为什么表数据删除一半，表文件大小不变？</h3><h3 id="14-count-这么慢，我改怎么办？"><a href="#14-count-这么慢，我改怎么办？" class="headerlink" title="14.count(*)这么慢，我改怎么办？"></a>14.count(*)这么慢，我改怎么办？</h3><h4 id="count-的实现方式"><a href="#count-的实现方式" class="headerlink" title="count(*)的实现方式"></a>count(*)的实现方式</h4><p>你首先要明确的是，在不同的 MySQL 引擎中，count(*) 有不同的实现方式。</p><p>MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；</p><p>而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。</p><h3 id="15-日志和索引相关问题"><a href="#15-日志和索引相关问题" class="headerlink" title="15.日志和索引相关问题"></a>15.日志和索引相关问题</h3><h3 id="16-“order-by”是怎么工作的？"><a href="#16-“order-by”是怎么工作的？" class="headerlink" title="16.“order by”是怎么工作的？"></a>16.“order by”是怎么工作的？</h3><h3 id="17-如何正确地显示随机消息？"><a href="#17-如何正确地显示随机消息？" class="headerlink" title="17.如何正确地显示随机消息？"></a>17.如何正确地显示随机消息？</h3><h3 id="18-为什么这些SQL语句逻辑相同，性能却差异巨大？"><a href="#18-为什么这些SQL语句逻辑相同，性能却差异巨大？" class="headerlink" title="18.为什么这些SQL语句逻辑相同，性能却差异巨大？"></a>18.为什么这些SQL语句逻辑相同，性能却差异巨大？</h3><h3 id="19-为什么我只查一行的语句，也执行这么慢？"><a href="#19-为什么我只查一行的语句，也执行这么慢？" class="headerlink" title="19.为什么我只查一行的语句，也执行这么慢？"></a>19.为什么我只查一行的语句，也执行这么慢？</h3><h3 id="20-幻读是什么，幻读有什么问题？"><a href="#20-幻读是什么，幻读有什么问题？" class="headerlink" title="20.幻读是什么，幻读有什么问题？"></a>20.幻读是什么，幻读有什么问题？</h3>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis常见问题</title>
      <link href="/2020/12/19/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-%E9%9B%AA%E5%B4%A9%E3%80%81%E7%A9%BF%E9%80%8F%E3%80%81%E5%B9%B6%E5%8F%91%E7%AD%895%E5%A4%A7%E9%9A%BE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
      <url>/2020/12/19/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-%E9%9B%AA%E5%B4%A9%E3%80%81%E7%A9%BF%E9%80%8F%E3%80%81%E5%B9%B6%E5%8F%91%E7%AD%895%E5%A4%A7%E9%9A%BE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Redis雪崩、穿透、并发等5大难题解决方案"><a href="#一、Redis雪崩、穿透、并发等5大难题解决方案" class="headerlink" title="一、Redis雪崩、穿透、并发等5大难题解决方案"></a>一、Redis雪崩、穿透、并发等5大难题解决方案</h2><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>数据未加载到缓存中，或者缓存同一时间大面积的失效，从而导致所有请求都去查数据库，导致数据库CPU和内存负载过高，甚至宕机。</p><p><strong>雪崩的简单过程：</strong></p><ol><li><p>redis集群大面积故障</p></li><li><p>缓存失效，但依然大量请求访问缓存服务redis</p></li><li><p>redis大量失效后，大量请求转向到mysql数据库</p></li><li><p>mysql的调用量暴增，很快就扛不住了，甚至直接宕机</p></li><li><p>由于大量的应用服务依赖mysql和redis的服务，这个时候很快会演变成各服务器集群的雪崩，最后网站彻底崩溃。</p><p><img src="https://upload-images.jianshu.io/upload_images/17159472-6af7a954878442db?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/17159472-6af7a954878442db?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p></li></ol><p><strong>如何预防缓存雪崩：</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/17159472-fdd9687f5c71cc51.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/319/format/webp" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/17159472-fdd9687f5c71cc51.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/319/format/webp" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><p>缓存层设计成高可用，防止缓存大面积故障。即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务，例如 Redis Sentinel 和 Redis Cluster 都实现了高可用。</p><p><em>2.缓存降级</em></p><p>可以利用ehcache等本地缓存(暂时支持)，但主要还是对源服务访问进行<strong>限流</strong>、<strong>资源隔离（熔断）</strong>、<strong>降级</strong>等。</p><p>当访问量剧增、服务出现问题仍然需要保证服务还是可用的。系统可以根据一些关键数据进行<strong>自动降级</strong>，也可以配置开关实现<strong>人工降级</strong>，这里会涉及到运维的配合。</p><p><strong>降级的最终目的是保证核心服务可用，即使是有损的。</strong></p><p>比如推荐服务中，很多都是个性化的需求，假如个性化需求不能提供服务了，可以降级补充热点数据，不至于造成前端页面是个大空白。</p><p>在进行降级之前要对系统进行梳理，比如：哪些业务是核心(必须保证)，哪些业务可以容许暂时不提供服务(利用静态页面替换)等，以及配合服务器核心指标，来后设置整体预案，比如：</p><p>（1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</p><p>（2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；</p><p>（3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</p><p>（4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</p><p><em>3.Redis备份和快速预热</em></p><p>(1)Redis数据备份和恢复</p><p>(2)快速缓存预热</p><p><em>4.提前演练</em></p><p>最后，建议还是在项目上线前，演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，对高可用提前预演，提前发现问题。</p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>缓存穿透是指查询一个一不存在的数据。例如：从缓存redis没有命中，需要从mysql数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。</p><p>解决思路：</p><p>如果查询数据库也为空，直接设置一个默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库。设置一个过期时间或者当有值的时候将缓存中的值替换掉即可。</p><p>可以给key设置一些格式规则，然后查询之前先过滤掉不符合规则的Key。</p><h3 id="缓存并发"><a href="#缓存并发" class="headerlink" title="缓存并发"></a>缓存并发</h3><p>这里的并发指的是多个redis的client同时set key引起的并发问题。其实redis自身就是单线程操作，多个client并发操作，按照先到先执行的原则，先到的先执行，其余的阻塞。当然，另外的解决方案是把redis.set操作放在队列中使其串行化，必须的一个一个执行。</p><h3 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h3><p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。</p><p>这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！</p><p>解决思路：</p><ol><li><p>直接写个缓存刷新页面，上线时手工操作下；</p></li><li><p>数据量不大，可以在项目启动的时候自动进行加载；</p></li></ol><p>目的就是在系统上线前，将数据加载到缓存中。</p><h2 id="二、Redis为什么是单线程，高并发快的3大原因详解"><a href="#二、Redis为什么是单线程，高并发快的3大原因详解" class="headerlink" title="二、Redis为什么是单线程，高并发快的3大原因详解"></a>二、Redis为什么是单线程，高并发快的3大原因详解</h2><p><strong>Redis的高并发和快速原因</strong></p><ol><li>redis是基于内存的，内存的读写速度非常快；</li><li>redis是单线程的，省去了很多上下文切换线程的时间；</li><li>redis使用多路复用技术，可以处理并发的连接。非阻塞IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间。</li></ol><p>下面重点介绍单线程设计和IO多路复用核心设计快的原因。</p><p><img src="https://upload-images.jianshu.io/upload_images/17159472-e285b5446cc61293.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/357/format/webp" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/17159472-e285b5446cc61293.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/357/format/webp" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><h3 id="为什么Redis是单线程的？"><a href="#为什么Redis是单线程的？" class="headerlink" title="为什么Redis是单线程的？"></a>为什么Redis是单线程的？</h3><p><strong>1.官方答案</strong></p><p>因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。</p><p><strong>2.性能指标</strong></p><p>关于redis的性能，官方网站也有，普通笔记本轻松处理每秒几十万的请求。</p><p><strong>3.详细原因</strong></p><p><em>1.不需要各种锁的性能消耗</em></p><p>Redis的数据结构并不全是简单的Key-Value，还有list，hash等复杂的结构，这些结构有可能会进行很细粒度的操作，比如在很长的列表后面添加一个元素，在hash当中添加或者删除一个对象。这些操作可能就需要加非常多的锁，导致的结果是同步开销大大增加。</p><p>总之，在单线程的情况下，就不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。</p><p><em>2.单线程多进程集群方案</em></p><p>单线程的威力实际上非常强大，每核心效率也非常高，多线程自然是可以比单线程有更高的性能上限，但是在今天的计算环境中，即使是单机多线程的上限也往往不能满足需要了，需要进一步摸索的是多服务器集群化的方案，这些方案中多线程的技术照样是用不上的。</p><p><strong>所以单线程、多进程的集群不失为一个时髦的解决方案。</strong></p><p><em>3.CPU消耗</em></p><p>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU。但是如果CPU成为Redis瓶颈，或者不想让服务器其他CUP核闲置，那怎么办？</p><p>可以考虑多起几个Redis进程，Redis是key-value数据库，不是关系数据库，数据之间没有约束。只要客户端分清哪些key放在哪个Redis进程上就可以了。</p><h3 id="Redis单线程的优劣势"><a href="#Redis单线程的优劣势" class="headerlink" title="Redis单线程的优劣势"></a>Redis单线程的优劣势</h3><p><strong>单进程单线程优势</strong></p><p>代码更清晰，处理逻辑更简单不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗不存在多进程或者多线程导致的切换而消耗CPU</p><p><strong>单进程单线程弊端</strong></p><p>无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来完善；</p><p><strong>IO多路复用技术</strong></p><p>redis 采用网络IO多路复用技术来保证在多连接的时候， 系统的高吞吐量。</p><p>多路-指的是多个socket连接，复用-指的是复用一个线程。多路复用主要有三种技术：select，poll，epoll。epoll是最新的也是目前最好的多路复用技术。</p><p>这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。</p><p><img src="https://upload-images.jianshu.io/upload_images/17159472-2afda1de5c2baf72?imageMogr2/auto-orient/strip%7CimageView2/2/w/609/format/webp" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/17159472-2afda1de5c2baf72?imageMogr2/auto-orient/strip%7CimageView2/2/w/609/format/webp" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><h3 id="Redis高并发快总结"><a href="#Redis高并发快总结" class="headerlink" title="Redis高并发快总结"></a>Redis高并发快总结</h3><p><img src="https://upload-images.jianshu.io/upload_images/17159472-4d45192c932b93aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/309/format/webp" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/17159472-4d45192c932b93aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/309/format/webp" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><ol><li><p>Redis是纯内存数据库，一般都是简单的存取操作，线程占用的时间很多，时间的花费主要集中在IO上，所以读取速度快。</p></li><li><p>再说一下IO，Redis使用的是非阻塞IO，IO多路复用，使用了单线程来轮询描述符，将数据库的开、关、读、写都转换成了事件，减少了线程切换时上下文的切换和竞争。</p></li><li><p>Redis采用了单线程的模型，保证了每个操作的原子性，也减少了线程的上下文切换和竞争。</p></li><li><p>另外，数据结构也帮了不少忙，Redis全程使用hash结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化，如<strong>压缩表</strong>，对短数据进行压缩存储，再如，<strong>跳表</strong>，使用有序的数据结构加快读取的速度。</p></li><li><p>还有一点，Redis采用自己实现的事件分离器，效率比较高，内部采用非阻塞的执行方式，吞吐能力比较大。</p></li></ol><h2 id="三、Redis缓存和MySQL数据一致性方案详解"><a href="#三、Redis缓存和MySQL数据一致性方案详解" class="headerlink" title="三、Redis缓存和MySQL数据一致性方案详解"></a>三、Redis缓存和MySQL数据一致性方案详解</h2><p>  <strong>需求起因</strong></p><p>  在高并发的业务场景下，数据库大多数情况都是用户并发访问最薄弱的环节。所以，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问MySQL等数据库。<br><img src="https://upload-images.jianshu.io/upload_images/17159472-28d0f809a85eb6cc?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/17159472-28d0f809a85eb6cc?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><p>  这个业务场景，主要是解决读数据从Redis缓存，一般都是按照下图的流程来进行业务操作。</p><p><img src="https://upload-images.jianshu.io/upload_images/17159472-77b45a8af9a60cc1?imageMogr2/auto-orient/strip%7CimageView2/2/w/553/format/webp" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/17159472-77b45a8af9a60cc1?imageMogr2/auto-orient/strip%7CimageView2/2/w/553/format/webp" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><p>  读取缓存步骤一般没有什么问题，但是一旦涉及到数据更新：数据库和缓存更新，就容易出现<strong>缓存(Redis)和数据库（MySQL）间的数据一致性问题</strong>。</p><p>  不管是先写MySQL数据库，再删除Redis缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况。举一个例子：</p><ol><li><p>如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。</p></li><li><p>如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。</p></li></ol><p><strong>因为写和读是并发的，没法保证顺序,就会出现缓存和数据库的数据不一致的问题。</strong></p><p>如来解决？这里给出两个解决方案，先易后难，结合业务和技术代价选择使用。</p><h3 id="缓存和数据库一致性解决方案"><a href="#缓存和数据库一致性解决方案" class="headerlink" title="缓存和数据库一致性解决方案"></a>缓存和数据库一致性解决方案</h3><p><strong>1.第一种方案：采用延时双删策略</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/17159472-10b548391418138d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/617/format/webp" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/17159472-10b548391418138d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/617/format/webp" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="img"></p><p>  在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。</p><p>  伪代码如下：</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String key,Object data)</span></span>&#123;</span><br><span class="line">    redis.delKey(key);</span><br><span class="line">    db.updateData(data);</span><br><span class="line">    Thread.sleep(<span class="number">500</span>);</span><br><span class="line">    redis.delKey(key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  <strong>具体的步骤就是：</strong></p><p>  <em>先删除缓存；再写数据库；休眠500毫秒；再次删除缓存。</em></p><p><strong>那么，这个500毫秒怎么确定的，具体该休眠多久呢？</strong></p><p>  需要评估自己的项目的读数据业务逻辑的耗时。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。</p><p>  当然这种策略还要考虑redis和数据库主从同步的耗时。最后的的写数据的休眠时间：则在读数据业务逻辑的耗时基础上，加几百ms即可。比如：休眠1秒。</p><p>  <strong>设置缓存过期时间</strong></p><p>  从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。</p><p> <strong>该方案的弊端</strong></p><p>  结合双删策略+缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致，而且又增加了写请求的耗时。</p><p>  <strong>2、第二种方案：<em>异步更新缓存</em>(基于订阅binlog的同步机制)</strong></p><p>  <strong>技术整体思路：</strong></p><p>  MySQL binlog增量订阅消费+消息队列+增量数据更新到redis</p><p>  <strong>读Redis</strong>：热数据基本都在Redis</p><p>  <strong>写MySQL</strong>:增删改都是操作MySQL</p><p>  <strong>更新Redis数据</strong>：MySQL的数据操作binlog，来更新到Redis</p><p>  <strong>Redis更新</strong></p><p>  <strong>1）数据操作主要分为两大块：</strong></p><p>  一个是全量(将全部数据一次写入到redis)一个是增量（实时更新）</p><p>  这里说的是增量,指的是mysql的update、insert、delate变更数据。</p><p>  <strong>2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。</strong></p><p>  这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。</p><p>  其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。</p><p>  这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。</p><p>  当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ等来实现推送更新Redis。</p>]]></content>
      
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库索引模块</title>
      <link href="/2020/07/15/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E6%A8%A1%E5%9D%97/"/>
      <url>/2020/07/15/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E6%A8%A1%E5%9D%97/</url>
      
        <content type="html"><![CDATA[<h2 id="如何设计一个关系型数据库"><a href="#如何设计一个关系型数据库" class="headerlink" title="如何设计一个关系型数据库"></a>如何设计一个关系型数据库</h2><h4 id="程序实例："><a href="#程序实例：" class="headerlink" title="程序实例："></a>程序实例：</h4><ol><li><p>存储管理</p></li><li><p>减少对数据的访问，提供缓存机制（全页缓存）</p></li><li><p>SQL解析</p></li><li><p>日志管理：缓存不易过大，提供淘汰策略，在数据库修改之后及时修改缓存，进行主从同步和灾难恢复</p></li><li><p>权限划分</p></li><li><p>容灾机制</p></li><li><p>索引管理</p></li><li><p>锁管理</p></li></ol><blockquote><p>影响数据的运行瓶颈就是IO</p></blockquote><h4 id="存储（文件系统）"><a href="#存储（文件系统）" class="headerlink" title="存储（文件系统）"></a>存储（文件系统）</h4><h2 id="索引模块"><a href="#索引模块" class="headerlink" title="索引模块"></a>索引模块</h2><h3 id="为什么使用索引"><a href="#为什么使用索引" class="headerlink" title="为什么使用索引"></a>为什么使用索引</h3><p>原始数据的查询方法就是将全表放入内存中，全表扫描轮询找到需要查找的数据，少量数据可以，大量数据严重影响性能。</p><h3 id="什么样的信息能成为索引"><a href="#什么样的信息能成为索引" class="headerlink" title="什么样的信息能成为索引"></a>什么样的信息能成为索引</h3><p>主键：唯一键以及普通键</p><h3 id="索引的数据结构"><a href="#索引的数据结构" class="headerlink" title="索引的数据结构"></a>索引的数据结构</h3><h5 id="生成索引，建立二叉查找树进行二分查找（二叉树–平衡二叉树–红黑树）"><a href="#生成索引，建立二叉查找树进行二分查找（二叉树–平衡二叉树–红黑树）" class="headerlink" title="生成索引，建立二叉查找树进行二分查找（二叉树–平衡二叉树–红黑树）"></a>生成索引，建立二叉查找树进行二分查找（二叉树–平衡二叉树–红黑树）</h5><p>因为是二分查找，时间复杂度为O(logn)</p><h5 id="生成索引，建立B-Tree结构进行查找"><a href="#生成索引，建立B-Tree结构进行查找" class="headerlink" title="生成索引，建立B-Tree结构进行查找"></a>生成索引，建立B-Tree结构进行查找</h5><p>因为添加结点导致二叉树的深度增加，虽然进行旋转可以使其继续维持平衡，但是增加了IO，降低了性能，因此提供了B-Tree结构（平衡多路查找树）。</p><p><strong>每个结点最多有m个孩子，这个结点就是M阶B树</strong></p><p>每个存储块包括关键字和指向结点的指针，最多有几个孩子取决于存储块的容量和数据库的相关配置</p><p>生成索引，建立B+-Tree结构进行查找</p><p>生成索引，建立Hash结构进行查找</p><h3 id="密集索引和稀疏索引的区别"><a href="#密集索引和稀疏索引的区别" class="headerlink" title="密集索引和稀疏索引的区别"></a>密集索引和稀疏索引的区别</h3><h4 id="密集索引"><a href="#密集索引" class="headerlink" title="密集索引"></a>密集索引</h4><p>密集索引文件中每一个<code>搜索码值</code>都对应一个<code>索引值</code>，就是叶子节点保存的不只是键值，还保存了位于同一行记录里的其他列信息，由于密集索引决定了表的物理排列顺序，一个表只有一个物理排列顺序，所以一个表只能创建一个密集索引。</p><h4 id="稀疏索引"><a href="#稀疏索引" class="headerlink" title="稀疏索引"></a>稀疏索引</h4><p>稀疏索引文件只为<code>索引码</code>的某些值建立<code>索引项</code>，比如InnoDB的其他索引只存了键位信息和主键，MyISAM的所有索引都是稀疏索引。</p><p> <img src="../%E8%B5%84%E6%96%99/2019073008040666.png" class="lazyload" data-srcset="../%E8%B5%84%E6%96%99/2019073008040666.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="密集索引和稀疏索引的区别"> </p><blockquote><p> MyISAM–》 主键索引，唯一键索引，还是普通索引 —都是 稀疏索引</p></blockquote><h4 id="额外知识"><a href="#额外知识" class="headerlink" title="额外知识"></a>额外知识</h4><h5 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h5><ul><li>若一个主键被定义，该主键则作为密集索引</li><li>若没有主键被定义，该表的第一个唯一非空索引则作为密集索引</li><li>若不满足以上条件，InnoDB内部会生成一个隐藏主键（密集索引）</li><li>非主键索引存储相关键位和其对应的主键值，包含两次查找</li></ul><p> <img src="../%E8%B5%84%E6%96%99/20190223185851371.png" class="lazyload" data-srcset="../%E8%B5%84%E6%96%99/20190223185851371.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="在这里插入图片描述"> </p><h5 id="InnoDB聚簇表分布"><a href="#InnoDB聚簇表分布" class="headerlink" title="InnoDB聚簇表分布"></a>InnoDB聚簇表分布</h5><p>myisam在磁盘存储上有三个文件，每个文件名以表名开头，扩展名指出文件类型。<br>.frm 用于存储表的定义<br>.MYD 用于存放数据<br>.MYI 用于存放表索引<br><img src="../%E8%B5%84%E6%96%99/20190223190406636.png" class="lazyload" data-srcset="../%E8%B5%84%E6%96%99/20190223190406636.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="在这里插入图片描述"></p><p><strong>可以看到—–》 Innodb索引与数据放在一起</strong></p><h2 id="慢查询-索引"><a href="#慢查询-索引" class="headerlink" title="慢查询/索引"></a>慢查询/索引</h2><p><strong>101.数据库索引的实现(B+树介绍、和B树、R树区别)</strong></p><p>参考文章：<br><a href="https://link.zhihu.com/?target=http://blog.csdn.net/kennyrose/article/details/7532032">数据库索引的实现原理 - 辉仔 の专栏 - 博客频道 - CSDN.NET</a><br><a href="https://link.zhihu.com/?target=http://www.xuebuyuan.com/2216918.html">由浅入深理解数据库中索引的底层实现 | 学步园</a></p><p><strong>102.SQL性能优化</strong></p><p>参考文章：<br><a href="https://link.zhihu.com/?target=http://database.51cto.com/art/200904/118526.htm">高手详解SQL性能优化十条经验 - 51CTO.COM</a><br><a href="https://link.zhihu.com/?target=http://www.cnblogs.com/rootq/archive/2008/11/17/1334727.html">Oracle SQL性能优化 - 一江水 - 博客园</a></p><p><strong>103.数据库索引的优缺点以及什么时候数据库索引失效</strong></p><p>参考文章：<br><a href="https://link.zhihu.com/?target=http://www.cnblogs.com/mxmbk/articles/5226344.html">数据库索引的作用和优点缺点以及索引的11中用法 - 技术与人生 - 博客园</a><br><a href="https://link.zhihu.com/?target=http://www.cnblogs.com/simplefrog/archive/2012/07/15/2592527.html">正确高效使用数据库不可不知的索引失效问题 - simplefrog - 博客园</a><br><a href="https://link.zhihu.com/?target=http://www.open-open.com/lib/view/open1418476492792.html">SQL优化避免索引失效 - OPEN 开发经验库</a><br><a href="https://link.zhihu.com/?target=http://blog.csdn.net/colin_liu2009/article/details/7301089">Colin Lau Oracle</a><br><a href="https://link.zhihu.com/?target=http://www.cnblogs.com/hongfei/archive/2012/10/20/2732589.html">哪些情况下索引会失效？ - 曾是土木人 - 博客园</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>索引的使用和含义</title>
      <link href="/2020/07/15/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E9%AB%98%E7%BA%A7SQL/"/>
      <url>/2020/07/15/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E9%AB%98%E7%BA%A7SQL/</url>
      
        <content type="html"><![CDATA[<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>索引（Index）是帮助MySQL高效获取数据的数据结构。我们可以简单理解为：快速查找排好序的一种数据结构。MySQL索引主要有两种结构：B+Tree索引和Hash索引。我们平常所说的索引，如果没有特殊指明，一般都是B树结构组织的索引（B+Tree索引）</p><h3 id="索引是什么"><a href="#索引是什么" class="headerlink" title="索引是什么?"></a>索引是什么?</h3><p>索引是帮助MySQL高效获取数据的数据结构。</p><h3 id="索引能干什么"><a href="#索引能干什么" class="headerlink" title="索引能干什么?"></a>索引能干什么?</h3><p>提高数据查询的效率。</p><p>索引：排好序的快速查找数据结构！索引会影响where后面的查找，和order by 后面的排序。公众号：Java后端 发布过几十篇 MySQL 文章，其中包括索引的文章，可以关注后后台回复 666 获取。</p><p>一、索引的分类</p><ol><li><p>从存储结构上来划分：BTree索引（B-Tree或B+Tree索引），Hash索引，full-index全文索引，R-Tree索引。</p></li><li><p>从应用层次来分：普通索引，唯一索引，复合索引。</p></li><li><p>根据中数据的物理顺序与键值的逻辑（索引）顺序关系：聚集索引，非聚集索引。</p></li></ol><p>1 中所描述的是索引存储时保存的形式，2 是索引使用过程中进行的分类，两者是不同层次上的划分。不过平时讲的索引类型一般是指在应用层次的划分。</p><p>就像手机分类，安卓手机，IOS手机 与 华为手机，苹果手机，OPPO手机一样。</p><p>普通索引：即一个索引只包含单个列，一个表可以有多个单列索引<br>唯一索引：索引列的值必须唯一，但允许有空值<br>复合索引：即一个索引包含多个列<br>聚簇索引(聚集索引)：并不是一种单独的索引类型，而是一种数据存储方式。具体细节取决于不同的实现，InnoDB的聚簇索引其实就是在同一个结构中保存了B-Tree索引(技术上来说是B+Tree)和数据行。<br>非聚簇索引：不是聚簇索引，就是非聚簇索引（认真脸）。<br>二、索引的底层实现</p><p>mysql默认存储引擎innodb只显式支持B-Tree( 从技术上来说是B+Tree)索引，对于频繁访问的表，innodb会透明建立自适应hash索引，即在B树索引基础上建立hash索引，可以显著提高查找效率，对于客户端是透明的，不可控制的，隐式的。<br>不谈存储引擎，只讨论实现(抽象)<br>Hash索引</p><p>基于哈希表实现，只有精确匹配索引所有列的查询才有效，对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（hash code），并且Hash索引将所有的哈希码存储在索引中，同时在索引表中保存指向每个数据行的指针。</p><p>B-Tree能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，数据分布在各个节点之中。</p><p>是B-Tree的改进版本，同时也是数据库索引索引所采用的存储结构。数据都在叶子节点上，并且增加了顺序访问指针，每个叶子节点都指向相邻的叶子节点的地址。相比B-Tree来说，进行范围查找时只需要查找两个节点，进行遍历即可。而B-Tree需要获取所有节点，相比之下B+Tree效率更高。</p><p>案例：假设有一张学生表，id为主键</p><p>在MyISAM引擎中的实现（二级索引也是这样实现的）</p><p>在InnoDB中的实现</p><p>三、问题</p><p>问：为什么索引结构默认使用B-Tree，而不是hash，二叉树，红黑树？<br>hash：虽然可以快速定位，但是没有顺序，IO复杂度高。<br>二叉树：树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。<br>红黑树：树的高度随着数据量增加而增加，IO代价高。<br>问：为什么官方建议使用自增长主键作为索引。<br>结合B+Tree的特点，自增主键是连续的，在插入过程中尽量减少页分裂，即使要进行页分裂，也只会分裂很少一部分。并且能减少数据的移动，每次插入都是插入到最后。总之就是减少分裂和移动的频率。<br>插入连续的数据：</p><p>插入非连续的数据</p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h2><h2 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h2><h2 id="count-1-、count-和count-字段-区别"><a href="#count-1-、count-和count-字段-区别" class="headerlink" title="count(1)、count(*)和count(字段)区别"></a>count(1)、count(*)和count(字段)区别</h2><p><a href="https://zhuanlan.zhihu.com/p/28397595">https://zhuanlan.zhihu.com/p/28397595</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>缓存雪崩、缓存击穿和缓存穿透</title>
      <link href="/2020/07/15/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E5%92%8C%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/"/>
      <url>/2020/07/15/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E5%92%8C%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/</url>
      
        <content type="html"><![CDATA[<h2 id="缓存雪崩、缓存穿透和缓存击穿的区别是什么，各自有什么解决方案"><a href="#缓存雪崩、缓存穿透和缓存击穿的区别是什么，各自有什么解决方案" class="headerlink" title="缓存雪崩、缓存穿透和缓存击穿的区别是什么，各自有什么解决方案"></a>缓存雪崩、缓存穿透和缓存击穿的区别是什么，各自有什么解决方案</h2><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>一般的缓存系统，都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统查找（比如DB）。一些恶意的请求会故意查询不存在的Key，请求量很大，就会对后端系统造成很大的压力，这就叫做缓存穿透。</p><h4 id="如何避免"><a href="#如何避免" class="headerlink" title="如何避免"></a>如何避免</h4><ol><li>对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该key对应的数据Insert了之后清理缓存。</li><li>对一定不存在的key进行过滤，可以把所有的可能存在的key放到一个大的bitmap中，查询时通过该bitmap过滤。</li></ol><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，会给后端系统带来很大压力，导致系统崩溃。</p><h4 id="如何避免-1"><a href="#如何避免-1" class="headerlink" title="如何避免"></a>如何避免</h4><ol><li>在缓存失效后，通过加锁或者队列来控制数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。</li><li>做二级缓存，A1为原始数据，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期</li><li>不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀</li></ol><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>对于设置了过期时间的key，缓存在某个时间点过期的时候，恰好这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把DB压垮。</p><h4 id="如何避免-2"><a href="#如何避免-2" class="headerlink" title="如何避免"></a>如何避免</h4><ol><li>使用互斥锁，当缓存失效时，不立即去load DB，先使用如Redis的setnx去设置一个互斥锁，当操作成功返回时在进行Load DB的操作并回设缓存，否则重试get缓存的方法</li><li>永远不过期：物理不过期，但逻辑过期（后台异步线程去刷新）</li></ol><h2 id="使用了大量缓存，那么就存在缓存击穿和缓存雪崩以及缓存一致性等问题？"><a href="#使用了大量缓存，那么就存在缓存击穿和缓存雪崩以及缓存一致性等问题？" class="headerlink" title="使用了大量缓存，那么就存在缓存击穿和缓存雪崩以及缓存一致性等问题？"></a>使用了大量缓存，那么就存在缓存击穿和缓存雪崩以及缓存一致性等问题？</h2><p>缓存穿透指的是对某个一定不存在的数据进行请求，该请求将会穿透缓存到达数据库。<br>解决方案：对这些不存在的数据缓存一个空数据，对这类请求进行过滤。</p><p>缓存雪崩指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。<br>解决方案：<br>为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现；<br>为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。<br>也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。<br>例如：首先针对不同的缓存设置不同的过期时间，比如session缓存，在userKey这个前缀中，设置是30分钟过期，并且每次用户响应的话更新缓存时间。这样每次取session,都会延长30分钟，相对来说，就减少了缓存过期的几率</p><p>缓存一致性要求数据更新的同时缓存数据也能够实时更新。</p><p>解决方案：<br>在数据更新的同时立即去更新缓存，首先尝试从缓存读取，读到数据则直接返回；如果读不到，就读数据库，并将数据会写到缓存，并返回。<br>在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新，需要更新数据时，先更新数据库，然后把缓存里对应的数据失效掉（删掉）。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
